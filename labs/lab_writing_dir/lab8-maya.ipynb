{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unexpected-basics",
   "metadata": {},
   "source": [
    "# Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-liabilities",
   "metadata": {},
   "source": [
    "## Morphological segmentation\n",
    "### morphological segmentation inside-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forced-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maya1/Documents/school/2021W/ling242/git/labs/lab8\n"
     ]
    }
   ],
   "source": [
    "cd /Users/Maya1/Documents/school/2021W/ling242/git/labs/lab8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3039e162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling with { -path => ../lab8/morphological-treebank-corrected-v2.train -out => mtb.gr -treebank => SINGLEFILE }\n",
      "Loading trees from ../lab8/morphological-treebank-corrected-v2.train and using language SINGLEFILE\n",
      "Will remove sentences with more than 10000 words.\n",
      "Using horizontal=0 and vertical=1 markovization.\n",
      "Using RIGHT binarization.\n",
      "Using a randomness value of 1.0\n",
      "Using grammar output file mtb.gr.\n",
      "Random number generator seeded at 2.\n",
      "I will do at least 50 iterations.\n",
      "Using smoothing parameters 0.5 and 0.1\n",
      "Loading data from single file!\n",
      "Loading trees from single file...done\n",
      "In training set we have # of words: 64871\n",
      "reducing number of training trees from 6699 to 6699\n",
      "Binarizing and annotating trees...done.\n",
      "Binarizing and annotating trees...done.\n",
      "There are 6699 trees in the training set.\n",
      "Will remove rules with prob under 1.0E-30.\n",
      "Even though only unlikely rules are pruned the training LL is not guaranteed to increase in every round anymore (especially when we are close to converging).\n",
      "Furthermore it increases the variance because 'good' rules can be pruned away in early stages.\n",
      "There are 28 observed categories.\n",
      "Will merge 50% of the splits in each round.\n",
      "The threshold for merging lexical and phrasal categories will be set separately: false\n",
      "Before splitting, we have a total of 28 substates.\n",
      "After splitting, we have a total of 55 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 1th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214265.13081888497\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214262.96417839063\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214262.8408576604\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214262.54078393782\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214261.72825584086\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214259.36351987455\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214252.03033897196\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214228.3343580285\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -214153.86412573257\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -213962.6319958868\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -213631.95012473615\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -213103.26341223993\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -211980.07785485443\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -209852.26683039605\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -206691.94449946913\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -202818.85753401316\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -199192.27823915964\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -196755.82605800816\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -195295.86243865525\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -194272.71630512268\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -193522.09407777118\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -193008.00205262558\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -192647.17502092975\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -192359.67061358443\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -192104.95974387598\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -191869.47900550495\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -191647.7640896821\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -191433.38399461817\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -191232.0974889989\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -191068.40181354043\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190957.40690696723\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190888.37866238068\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190843.81779945287\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190812.34755209569\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190788.074586806\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190768.1914191208\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190751.44033165273\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190737.22374481056\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190725.1697454066\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190714.95459349777\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190706.25123986983\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190698.73219476693\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190692.08617900836\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190686.04657005385\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190680.43516274475\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190675.19471522063\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190670.3531089769\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190665.9118977207\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190661.80595222936\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190657.97422904597\n",
      "Saving grammar to mtb.gr_1_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -190658.2092043919\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 1.9095425048844388.\n",
      "Merging 10 siblings and 0 other pairs.\n",
      "State ROOT.\n",
      "State S^g.\n",
      "State STEM^g. Merging pair (0,1) at cost 1.022414999253152.\n",
      "State @STEM^g.\n",
      "State C.\n",
      "State V.\n",
      "State SUFFIX^g.\n",
      "State PREFIX^g.\n",
      "State @SUFFIX^g.\n",
      "State @PREFIX^g.\n",
      "State identify. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State comprehend. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State PREFX^g. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State technic.\n",
      "State balance.\n",
      "State office. Merging pair (0,1) at cost 4.4408920985006257E-16.\n",
      "State rhythm. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State dogma.\n",
      "State racial.\n",
      "State ^g. Merging pair (0,1) at cost 1.9095425048844388.\n",
      "State prejudice. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State sad.\n",
      "State dis.\n",
      "State @S^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State offence. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State grow.\n",
      "State back.\n",
      "State heterosex.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State ROOT had 1 substates and now has 1.\n",
      "State S^g had 2 substates and now has 2.\n",
      "State STEM^g had 2 substates and now has 1.\n",
      "State @STEM^g had 2 substates and now has 2.\n",
      "State C had 2 substates and now has 2.\n",
      "State V had 2 substates and now has 2.\n",
      "State SUFFIX^g had 2 substates and now has 2.\n",
      "State PREFIX^g had 2 substates and now has 2.\n",
      "State @SUFFIX^g had 2 substates and now has 2.\n",
      "State @PREFIX^g had 2 substates and now has 2.\n",
      "State identify had 2 substates and now has 1.\n",
      "State comprehend had 2 substates and now has 1.\n",
      "State PREFX^g had 2 substates and now has 1.\n",
      "State technic had 2 substates and now has 2.\n",
      "State balance had 2 substates and now has 2.\n",
      "State office had 2 substates and now has 1.\n",
      "State rhythm had 2 substates and now has 1.\n",
      "State dogma had 2 substates and now has 2.\n",
      "State racial had 2 substates and now has 2.\n",
      "State ^g had 2 substates and now has 1.\n",
      "State prejudice had 2 substates and now has 1.\n",
      "State sad had 2 substates and now has 2.\n",
      "State dis had 2 substates and now has 2.\n",
      "State @S^g had 2 substates and now has 1.\n",
      "State offence had 2 substates and now has 1.\n",
      "State grow had 2 substates and now has 2.\n",
      "State back had 2 substates and now has 2.\n",
      "State heterosex had 2 substates and now has 2.\n",
      "Lexicon: [C : 2, heterosex : 2, V : 2, dogma : 2, back : 2, dis : 2, technic : 2, racial : 2, balance : 2, sad : 2, grow : 2, comprehend : 1, offence : 1, identify : 1, office : 1, rhythm : 1, prejudice : 1]\n",
      "Grammar: [S^g : 2, @STEM^g : 2, @PREFIX^g : 2, SUFFIX^g : 2, PREFIX^g : 2, @SUFFIX^g : 2, STEM^g : 1, ^g : 1, @S^g : 1, ROOT : 1, PREFX^g : 1]\n",
      "After merging in the 1th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190661.26793877917\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190657.75510877103\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190654.5777273633\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190651.5765800166\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190648.6731014981\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190645.79257221727\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190642.85667008488\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190639.77991836658\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190636.47003977938\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190632.81720316585\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190628.6266344999\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190623.61953687688\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190618.09466194033\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190612.38815176595\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190606.3497190868\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190599.91531544985\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190593.0729539049\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190585.82138416098\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190578.18316739373\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190570.2402969606\n",
      "Saving grammar to mtb.gr_1_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 1th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197404.1340635579\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197396.05995713826\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197388.11334702655\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197380.5887793893\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197373.7771066388\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197367.96303614546\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197363.3517411154\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197359.81952944113\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197356.63417188905\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -197353.27090793572\n",
      "Saving grammar to mtb.gr_1_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 45 substates.\n",
      "After splitting, we have a total of 89 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 2th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190519.37714133758\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190516.5892938675\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190514.78759094383\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190513.59908588516\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190512.57457413856\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190511.34740305122\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190509.3174075045\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190504.92230324383\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190493.69571748827\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190463.00086477725\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190378.78909762207\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -190150.92745809394\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -189589.00566816956\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -188513.6240103116\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -186977.1897508578\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -185288.34419380283\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training likelihood...done: -183656.93994500322\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -181942.80119144017\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -180264.94934467858\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -178926.9393522809\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -177933.2151232784\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -177148.89100305008\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -176416.81186006364\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -175667.03186972355\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -175041.4034213264\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -174576.20477080205\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -174176.03575612174\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173763.0592481534\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173316.38089721138\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -172850.18723268816\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -172392.18488601848\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171970.80899514197\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171597.34754201796\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171274.81904552167\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171008.2561989134\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170801.2820316333\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170644.7667717258\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170522.0364714927\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170421.09403599336\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170334.9641889799\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170259.12135237746\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170189.6346427066\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170123.83754195823\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170058.20035225115\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169986.7608832039\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169903.75822360444\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169813.22497253882\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169729.046636359\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169653.2065101827\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169601.34858528894\n",
      "Saving grammar to mtb.gr_2_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -169601.58356063455\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 2.812172433108725.\n",
      "Merging 16 siblings and 0 other pairs.\n",
      "State ROOT.\n",
      "State S^g. Merging pair (0,1) at cost -2.3977393412524024E-7.\n",
      "State STEM^g. Merging pair (0,1) at cost 2.812172433108725.\n",
      "State @STEM^g.\n",
      "State C.\n",
      "State V.\n",
      "State SUFFIX^g.\n",
      "State PREFIX^g.\n",
      "State @SUFFIX^g.\n",
      "State @PREFIX^g.\n",
      "State identify. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State comprehend. Merging pair (0,1) at cost -3.3306690738754696E-16.\n",
      "State PREFX^g.\n",
      "State technic. Merging pair (0,1) at cost -1.1102230246251565E-16.\n",
      "State balance. Merging pair (0,1) at cost -4.440892098500626E-16.\n",
      "State office. Merging pair (0,1) at cost 4.4408920985006257E-16.\n",
      "State rhythm. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State dogma. Merging pair (0,1) at cost 4.4408920985006257E-16. Merging pair (2,3) at cost 4.4408920985006257E-16.\n",
      "State racial.\n",
      "State ^g. Merging pair (0,1) at cost 1.9095425048844386.\n",
      "State prejudice.\n",
      "State sad.\n",
      "State dis.\n",
      "State @S^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State offence. Merging pair (0,1) at cost -1.1102230246251565E-16.\n",
      "State grow. Merging pair (2,3) at cost 4.4408920985006257E-16.\n",
      "State back.\n",
      "State heterosex. Merging pair (0,1) at cost -1.1102230246251565E-16. Merging pair (2,3) at cost -1.1102230246251565E-16.\n",
      "\n",
      "State ROOT had 1 substates and now has 1.\n",
      "State S^g had 4 substates and now has 3.\n",
      "State STEM^g had 2 substates and now has 1.\n",
      "State @STEM^g had 4 substates and now has 4.\n",
      "State C had 4 substates and now has 4.\n",
      "State V had 4 substates and now has 4.\n",
      "State SUFFIX^g had 4 substates and now has 4.\n",
      "State PREFIX^g had 4 substates and now has 4.\n",
      "State @SUFFIX^g had 4 substates and now has 4.\n",
      "State @PREFIX^g had 4 substates and now has 4.\n",
      "State identify had 2 substates and now has 1.\n",
      "State comprehend had 2 substates and now has 1.\n",
      "State PREFX^g had 2 substates and now has 2.\n",
      "State technic had 4 substates and now has 3.\n",
      "State balance had 4 substates and now has 3.\n",
      "State office had 2 substates and now has 1.\n",
      "State rhythm had 2 substates and now has 1.\n",
      "State dogma had 4 substates and now has 2.\n",
      "State racial had 4 substates and now has 4.\n",
      "State ^g had 2 substates and now has 1.\n",
      "State prejudice had 2 substates and now has 2.\n",
      "State sad had 4 substates and now has 4.\n",
      "State dis had 4 substates and now has 4.\n",
      "State @S^g had 2 substates and now has 1.\n",
      "State offence had 2 substates and now has 1.\n",
      "State grow had 4 substates and now has 3.\n",
      "State back had 4 substates and now has 4.\n",
      "State heterosex had 4 substates and now has 2.\n",
      "Lexicon: [C : 4, V : 4, back : 4, racial : 4, sad : 4, dis : 4, technic : 3, balance : 3, grow : 3, heterosex : 2, dogma : 2, prejudice : 2, offence : 1, identify : 1, comprehend : 1, rhythm : 1, office : 1]\n",
      "Grammar: [@STEM^g : 4, SUFFIX^g : 4, @PREFIX^g : 4, PREFIX^g : 4, @SUFFIX^g : 4, S^g : 3, PREFX^g : 2, ^g : 1, @S^g : 1, ROOT : 1, STEM^g : 1]\n",
      "After merging in the 2th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169604.36099223504\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169565.9774662016\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169534.99055027374\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169506.3864888098\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169477.17850145482\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169446.1845486381\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training likelihood...done: -169416.1107721988\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169390.6963779728\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169368.4284120426\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169346.89361647598\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169325.59573820975\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169303.53465728307\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169280.0267644758\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169256.04527479783\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169232.40024782775\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169209.7214947579\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169188.64562089788\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169169.66105104357\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169152.97119777894\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169138.5132736538\n",
      "Saving grammar to mtb.gr_2_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 2th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171594.0651706729\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -172630.8697217159\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173060.24742200712\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173249.4369799088\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173335.22412251082\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173374.56958893378\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173392.70789119316\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173401.19677381398\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173405.37893320125\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -173407.71283839934\n",
      "Saving grammar to mtb.gr_2_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 73 substates.\n",
      "After splitting, we have a total of 145 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 3th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171186.35349062755\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170409.63773949756\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170055.5667155546\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169858.4995537647\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169725.5360598524\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169619.15796895177\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169527.42650864692\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169446.03089170592\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169364.7745883032\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169249.84998224632\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169014.2505299247\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -168556.31264411614\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -167959.67352835523\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -167385.1910364937\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -166826.74452472094\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -166190.52867431595\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -165337.53549788918\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -164266.7141026434\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -163100.14078523015\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -161870.1511054827\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160604.4292625743\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -159498.488900776\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158654.46645973672\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157993.93935366976\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157444.2609983497\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -156963.41618667092\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -156538.95858707358\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -156172.50969093264\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -155856.25860336464\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -155568.59258968633\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -155304.07760608965\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -155064.9205684216\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -154848.80402947843\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -154650.31217799833\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -154464.58118106175\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training likelihood...done: -154289.33373492718\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -154121.83701050517\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153964.40080595828\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153826.41584662642\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153705.59688935458\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153596.85991795457\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153494.79004485413\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153390.69189491207\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153268.39116256658\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153108.24948787133\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152932.43463473604\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152794.704640867\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152699.85247443788\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152629.2625123316\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152570.9863718446\n",
      "Saving grammar to mtb.gr_3_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -152571.22134719053\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 4.460231612465973.\n",
      "Merging 22 siblings and 0 other pairs.\n",
      "State ROOT.\n",
      "State S^g. Merging pair (0,1) at cost 1.896455586386179E-4. Merging pair (4,5) at cost 0.028071575653730623.\n",
      "State STEM^g.\n",
      "State @STEM^g.\n",
      "State C.\n",
      "State V. Merging pair (2,3) at cost 1.223424563379353. Merging pair (4,5) at cost 2.365885265476208E-13. Merging pair (6,7) at cost 3.870803677582616E-11.\n",
      "State SUFFIX^g. Merging pair (4,5) at cost 4.378721681755032E-4. Merging pair (6,7) at cost 8.764157012407581E-5.\n",
      "State PREFIX^g. Merging pair (2,3) at cost 2.4381056353074912E-5. Merging pair (4,5) at cost 4.460231612465973. Merging pair (6,7) at cost 4.275345591637311.\n",
      "State @SUFFIX^g. Merging pair (0,1) at cost 0.03432536011187465.\n",
      "State @PREFIX^g. Merging pair (6,7) at cost 1.69764967374054.\n",
      "State identify. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State comprehend.\n",
      "State PREFX^g. Merging pair (0,1) at cost -1.1102230246251565E-16.\n",
      "State technic.\n",
      "State balance. Merging pair (2,3) at cost -4.440892098500626E-16.\n",
      "State office. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State rhythm.\n",
      "State dogma.\n",
      "State racial. Merging pair (6,7) at cost -2.220446049250313E-16.\n",
      "State ^g. Merging pair (0,1) at cost 1.909542504884439.\n",
      "State prejudice.\n",
      "State sad. Merging pair (2,3) at cost -2.220446049250313E-16.\n",
      "State dis.\n",
      "State @S^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State offence. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State grow. Merging pair (2,3) at cost 4.4408920985006257E-16.\n",
      "State back.\n",
      "State heterosex.\n",
      "\n",
      "State ROOT had 1 substates and now has 1.\n",
      "State S^g had 6 substates and now has 4.\n",
      "State STEM^g had 2 substates and now has 2.\n",
      "State @STEM^g had 8 substates and now has 8.\n",
      "State C had 8 substates and now has 8.\n",
      "State V had 8 substates and now has 5.\n",
      "State SUFFIX^g had 8 substates and now has 6.\n",
      "State PREFIX^g had 8 substates and now has 5.\n",
      "State @SUFFIX^g had 8 substates and now has 7.\n",
      "State @PREFIX^g had 8 substates and now has 7.\n",
      "State identify had 2 substates and now has 1.\n",
      "State comprehend had 2 substates and now has 2.\n",
      "State PREFX^g had 4 substates and now has 3.\n",
      "State technic had 6 substates and now has 6.\n",
      "State balance had 6 substates and now has 5.\n",
      "State office had 2 substates and now has 1.\n",
      "State rhythm had 2 substates and now has 2.\n",
      "State dogma had 4 substates and now has 4.\n",
      "State racial had 8 substates and now has 7.\n",
      "State ^g had 2 substates and now has 1.\n",
      "State prejudice had 4 substates and now has 4.\n",
      "State sad had 8 substates and now has 7.\n",
      "State dis had 8 substates and now has 8.\n",
      "State @S^g had 2 substates and now has 1.\n",
      "State offence had 2 substates and now has 1.\n",
      "State grow had 6 substates and now has 5.\n",
      "State back had 8 substates and now has 8.\n",
      "State heterosex had 4 substates and now has 4.\n",
      "Lexicon: [C : 8, back : 8, dis : 8, racial : 7, sad : 7, technic : 6, V : 5, balance : 5, grow : 5, heterosex : 4, dogma : 4, prejudice : 4, comprehend : 2, rhythm : 2, offence : 1, identify : 1, office : 1]\n",
      "Grammar: [@STEM^g : 8, @PREFIX^g : 7, @SUFFIX^g : 7, SUFFIX^g : 6, PREFIX^g : 5, S^g : 4, PREFX^g : 3, STEM^g : 2, ^g : 1, @S^g : 1, ROOT : 1]\n",
      "After merging in the 3th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152580.2907147097\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152531.00223744975\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152486.1324870971\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152444.07822668814\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152404.1336358483\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152366.190843982\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152329.99040048695\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152295.24687875898\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152261.79328351913\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152229.61933501074\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152198.81514958944\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152169.58513851164\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152142.190038589\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152116.77942805554\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152093.37789139972\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152072.0439392709\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152052.81280662227\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152035.4214250173\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152019.44420574777\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152004.44775390078\n",
      "Saving grammar to mtb.gr_3_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 3th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -155138.8349943481\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training likelihood...done: -156284.46647961347\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -156752.7040228696\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -156974.68980707982\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157090.74786551765\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157154.66022585356\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157191.3766168793\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157213.14232869947\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157226.23758759513\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157234.0939252764\n",
      "Saving grammar to mtb.gr_3_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 123 substates.\n",
      "After splitting, we have a total of 245 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 4th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -154275.66136729287\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153353.04672374544\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152909.1192593048\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152616.26957030297\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152404.0057923938\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152250.03185226434\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152138.76540275125\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152055.04082104043\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151991.93145300096\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151940.86533492705\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151886.14989999597\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151805.1483424249\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151659.0168487056\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151395.60505169583\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151006.41151377896\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -150463.32592430394\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149701.3006532662\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148806.5004230382\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -147961.32286773415\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -147244.15160041043\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -146644.78668194273\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -146149.75418435596\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -145735.88057682308\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -145364.16845441874\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -144994.45696609752\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -144596.50060360017\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -144161.95942271187\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143703.1290406858\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143245.2270847793\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142812.42693671148\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142414.1464387238\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142046.28442712777\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141705.36995158895\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141391.37661687593\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141106.47647685214\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140852.69581435504\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140629.26683855083\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140432.75190182467\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140258.69115825498\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140102.5897351618\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139960.93788211994\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139830.77794565234\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139708.65178044463\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139593.9210717076\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139487.78082878445\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139389.05818832092\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139296.72139880736\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139209.78936855184\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139128.46985599527\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139053.92240840333\n",
      "Saving grammar to mtb.gr_4_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -139054.15473511597\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 2.08625635649841.\n",
      "Merging 34 siblings and 0 other pairs.\n",
      "State ROOT.\n",
      "State S^g. Merging pair (0,1) at cost 0.02589286304853394. Merging pair (4,5) at cost 0.03792333593667634. Merging pair (6,7) at cost 0.6629120248135697.\n",
      "State STEM^g.\n",
      "State @STEM^g.\n",
      "State C. Merging pair (0,1) at cost 0.02181999412019232. Merging pair (4,5) at cost 1.0402789740737715E-12. Merging pair (6,7) at cost 6.892075227265518E-8.\n",
      "State V. Merging pair (2,3) at cost 4.5451442672624634E-4. Merging pair (6,7) at cost 8.073941515348268E-11. Merging pair (8,9) at cost 6.806777363976834E-13.\n",
      "State SUFFIX^g. Merging pair (2,3) at cost 0.8276555508273095. Merging pair (8,9) at cost 0.0012094379439924446. Merging pair (10,11) at cost 2.969905255189159E-5.\n",
      "State PREFIX^g. Merging pair (2,3) at cost 4.193900909591874E-6. Merging pair (4,5) at cost 1.9943995580598204E-4.\n",
      "State @SUFFIX^g. Merging pair (4,5) at cost 0.7753206712793831.\n",
      "State @PREFIX^g. Merging pair (4,5) at cost 1.0769400145658816. Merging pair (6,7) at cost 1.90954250488441. Merging pair (10,11) at cost 0.4279901605612207. Merging pair (12,13) at cost 2.08625635649841.\n",
      "State identify. Merging pair (0,1) at cost -1.1102230246251565E-16.\n",
      "State comprehend. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State PREFX^g. Merging pair (0,1) at cost -9.456735395211031E-11. Merging pair (2,3) at cost -1.920168468856398E-10. Merging pair (4,5) at cost -7.018448047422699E-10.\n",
      "State technic. Merging pair (6,7) at cost 2.2204460492503128E-16.\n",
      "State balance.\n",
      "State office. Merging pair (0,1) at cost 4.4408920985006257E-16.\n",
      "State rhythm.\n",
      "State dogma. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State racial.\n",
      "State ^g. Merging pair (0,1) at cost 1.9095425048844388.\n",
      "State prejudice.\n",
      "State sad.\n",
      "State dis.\n",
      "State @S^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State offence. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State grow. Merging pair (4,5) at cost -4.440892098500626E-16.\n",
      "State back. Merging pair (14,15) at cost 4.4408920985006257E-16.\n",
      "State heterosex. Merging pair (0,1) at cost -2.220446049250313E-16. Merging pair (6,7) at cost -2.220446049250313E-16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State ROOT had 1 substates and now has 1.\n",
      "State S^g had 8 substates and now has 5.\n",
      "State STEM^g had 4 substates and now has 4.\n",
      "State @STEM^g had 16 substates and now has 16.\n",
      "State C had 16 substates and now has 13.\n",
      "State V had 10 substates and now has 7.\n",
      "State SUFFIX^g had 12 substates and now has 9.\n",
      "State PREFIX^g had 10 substates and now has 8.\n",
      "State @SUFFIX^g had 14 substates and now has 13.\n",
      "State @PREFIX^g had 14 substates and now has 10.\n",
      "State identify had 2 substates and now has 1.\n",
      "State comprehend had 4 substates and now has 3.\n",
      "State PREFX^g had 6 substates and now has 3.\n",
      "State technic had 12 substates and now has 11.\n",
      "State balance had 10 substates and now has 10.\n",
      "State office had 2 substates and now has 1.\n",
      "State rhythm had 4 substates and now has 4.\n",
      "State dogma had 8 substates and now has 7.\n",
      "State racial had 14 substates and now has 14.\n",
      "State ^g had 2 substates and now has 1.\n",
      "State prejudice had 8 substates and now has 8.\n",
      "State sad had 14 substates and now has 14.\n",
      "State dis had 16 substates and now has 16.\n",
      "State @S^g had 2 substates and now has 1.\n",
      "State offence had 2 substates and now has 1.\n",
      "State grow had 10 substates and now has 9.\n",
      "State back had 16 substates and now has 15.\n",
      "State heterosex had 8 substates and now has 6.\n",
      "Lexicon: [dis : 16, back : 15, racial : 14, sad : 14, C : 13, technic : 11, balance : 10, grow : 9, prejudice : 8, dogma : 7, V : 7, heterosex : 6, rhythm : 4, comprehend : 3, office : 1, identify : 1, offence : 1]\n",
      "Grammar: [@STEM^g : 16, @SUFFIX^g : 13, @PREFIX^g : 10, SUFFIX^g : 9, PREFIX^g : 8, S^g : 5, STEM^g : 4, PREFX^g : 3, @S^g : 1, ROOT : 1, ^g : 1]\n",
      "After merging in the 4th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139061.22819099954\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138992.26937731716\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138928.5891217214\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138868.91495668524\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138813.0603457654\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138760.91891385807\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138712.2183696397\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138666.9372456725\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138623.7414950397\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138582.8863066915\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138544.5489915613\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138507.30089107426\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138470.49851202298\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138433.39997052445\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138395.20362018727\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138355.15356738286\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138313.06100156362\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138269.6343283042\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138224.98521382952\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138178.65048383962\n",
      "Saving grammar to mtb.gr_4_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 4th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141831.09381727196\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142959.79966202375\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143341.67878001562\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143494.55345553838\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143557.58336615178\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143581.86752284417\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143587.57759948508\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143583.65343816185\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143574.42108781243\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143562.0443290269\n",
      "Saving grammar to mtb.gr_4_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 211 substates.\n",
      "After splitting, we have a total of 421 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 5th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140171.0918523011\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139118.54567876767\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138617.1589398197\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138305.8410255949\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138097.22990208506\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137949.40504223248\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137837.0967709874\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137747.08302937713\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137669.37088104076\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137597.08605776247\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137520.26372905672\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137418.39813625035\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137250.51503366628\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136990.8000378649\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136694.86426793347\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136435.6760161404\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training likelihood...done: -136212.27210117204\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135986.22830756273\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135694.9117415276\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135297.7357314971\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -134794.8001389749\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -134218.7306156248\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -133616.70846642926\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -133025.95668328815\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -132454.99762560558\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -131889.7168913815\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -131325.19692101417\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130775.57339399355\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130264.46411020914\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129807.16882940957\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129404.29357826439\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129045.19313344399\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128716.83392017687\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128416.95713802824\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128153.47198525966\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127920.72847233315\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127711.95366485244\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127522.96111791303\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127348.3636419887\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127183.75360705779\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127025.35645056487\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126871.14883691444\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126721.7660839079\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126572.7382039817\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126419.71717288389\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126265.27738271713\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126115.82339741768\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125973.28091709239\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125833.57284441772\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125687.71267783131\n",
      "Saving grammar to mtb.gr_5_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -125688.00272174765\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 2.6444166500823103.\n",
      "Merging 55 siblings and 0 other pairs.\n",
      "State ROOT.\n",
      "State S^g. Merging pair (0,1) at cost 8.488735839814179E-5.\n",
      "State STEM^g.\n",
      "State @STEM^g.\n",
      "State C. Merging pair (0,1) at cost 0.15530081299953233. Merging pair (2,3) at cost 0.019839297634605. Merging pair (4,5) at cost 3.967937090010309E-13. Merging pair (6,7) at cost 7.505107646466057E-14. Merging pair (8,9) at cost -1.6561986896454233E-7. Merging pair (14,15) at cost 0.6991738890311631.\n",
      "State V. Merging pair (0,1) at cost 3.5349950738796463E-9. Merging pair (2,3) at cost 2.2415402867181908E-13. Merging pair (4,5) at cost 0.7055454088483365. Merging pair (10,11) at cost 8.830713937865623E-13. Merging pair (12,13) at cost -8.913980664715382E-13.\n",
      "State SUFFIX^g. Merging pair (4,5) at cost 1.0959252481650927. Merging pair (6,7) at cost 0.04455953762386954. Merging pair (8,9) at cost 2.48619486832549E-4. Merging pair (14,15) at cost 7.248170387092467E-5. Merging pair (16,17) at cost 4.3930600630040864E-4.\n",
      "State PREFIX^g. Merging pair (0,1) at cost 0.7714337572008385. Merging pair (4,5) at cost 0.4985226132153417. Merging pair (6,7) at cost 7.055879660767338E-5.\n",
      "State @SUFFIX^g. Merging pair (0,1) at cost 1.3747744247581639E-8. Merging pair (8,9) at cost 0.781194866962336. Merging pair (12,13) at cost 6.061159733839131E-8. Merging pair (18,19) at cost 0.3762263774535628.\n",
      "State @PREFIX^g. Merging pair (2,3) at cost 1.3862943611198908. Merging pair (4,5) at cost -2.220446049250313E-16. Merging pair (6,7) at cost 1.0164987221569746. Merging pair (8,9) at cost 2.5471261574117756. Merging pair (10,11) at cost 1.9095425048844386. Merging pair (14,15) at cost 0.1818935486345839. Merging pair (18,19) at cost 2.6444166500823103.\n",
      "State identify. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State comprehend.\n",
      "State PREFX^g. Merging pair (0,1) at cost -5.218048215738249E-15. Merging pair (2,3) at cost -2.5535129566378632E-15. Merging pair (4,5) at cost -2.220446049250313E-16.\n",
      "State technic. Merging pair (16,17) at cost -2.220446049250313E-16. Merging pair (18,19) at cost -2.220446049250313E-16.\n",
      "State balance.\n",
      "State office. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State rhythm. Merging pair (4,5) at cost -2.220446049250313E-16.\n",
      "State dogma. Merging pair (2,3) at cost 4.4408920985006257E-16. Merging pair (8,9) at cost 4.4408920985006257E-16. Merging pair (10,11) at cost -2.220446049250313E-16.\n",
      "State racial.\n",
      "State ^g. Merging pair (0,1) at cost 1.9095425048844386.\n",
      "State prejudice. Merging pair (8,9) at cost -4.440892098500626E-16.\n",
      "State sad. Merging pair (12,13) at cost 2.2204460492503128E-16. Merging pair (18,19) at cost -1.1102230246251565E-16.\n",
      "State dis. Merging pair (10,11) at cost 2.2204460492503128E-16. Merging pair (16,17) at cost 2.2204460492503128E-16. Merging pair (28,29) at cost 2.2204460492503128E-16.\n",
      "State @S^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State offence.\n",
      "State grow. Merging pair (14,15) at cost 4.4408920985006257E-16.\n",
      "State back. Merging pair (0,1) at cost 4.4408920985006257E-16. Merging pair (18,19) at cost 4.4408920985006257E-16. Merging pair (24,25) at cost 4.4408920985006257E-16. Merging pair (28,29) at cost 4.4408920985006257E-16.\n",
      "State heterosex.\n",
      "\n",
      "State ROOT had 1 substates and now has 1.\n",
      "State S^g had 10 substates and now has 9.\n",
      "State STEM^g had 8 substates and now has 8.\n",
      "State @STEM^g had 32 substates and now has 32.\n",
      "State C had 26 substates and now has 20.\n",
      "State V had 14 substates and now has 9.\n",
      "State SUFFIX^g had 18 substates and now has 13.\n",
      "State PREFIX^g had 16 substates and now has 13.\n",
      "State @SUFFIX^g had 26 substates and now has 22.\n",
      "State @PREFIX^g had 20 substates and now has 13.\n",
      "State identify had 2 substates and now has 1.\n",
      "State comprehend had 6 substates and now has 6.\n",
      "State PREFX^g had 6 substates and now has 3.\n",
      "State technic had 22 substates and now has 20.\n",
      "State balance had 20 substates and now has 20.\n",
      "State office had 2 substates and now has 1.\n",
      "State rhythm had 8 substates and now has 7.\n",
      "State dogma had 14 substates and now has 11.\n",
      "State racial had 28 substates and now has 28.\n",
      "State ^g had 2 substates and now has 1.\n",
      "State prejudice had 16 substates and now has 15.\n",
      "State sad had 28 substates and now has 26.\n",
      "State dis had 32 substates and now has 29.\n",
      "State @S^g had 2 substates and now has 1.\n",
      "State offence had 2 substates and now has 2.\n",
      "State grow had 18 substates and now has 17.\n",
      "State back had 30 substates and now has 26.\n",
      "State heterosex had 12 substates and now has 12.\n",
      "Lexicon: [dis : 29, racial : 28, back : 26, sad : 26, C : 20, technic : 20, balance : 20, grow : 17, prejudice : 15, heterosex : 12, dogma : 11, V : 9, rhythm : 7, comprehend : 6, offence : 2, office : 1, identify : 1]\n",
      "Grammar: [@STEM^g : 32, @SUFFIX^g : 22, SUFFIX^g : 13, @PREFIX^g : 13, PREFIX^g : 13, S^g : 9, STEM^g : 8, PREFX^g : 3, @S^g : 1, ROOT : 1, ^g : 1]\n",
      "After merging in the 5th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training likelihood...done: -125689.14669241584\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125517.66204305702\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125345.28426949734\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125198.35289235396\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125088.90952997409\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125004.81048651857\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124929.79220323899\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124853.5234311177\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124777.44678027523\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124710.3584804756\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124639.79990120073\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124562.87465019795\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124501.91258681021\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124450.883714986\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124402.9674279271\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124354.36236754403\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124304.50589474042\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124255.1390793292\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124208.26192622918\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124166.21063661194\n",
      "Saving grammar to mtb.gr_5_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 5th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128798.90552270939\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129856.10340428386\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130144.85057924889\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130249.10308970364\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130288.70945092254\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130297.45908650664\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130291.34111860197\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130279.51357797383\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130264.25545517918\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130246.54564792439\n",
      "Saving grammar to mtb.gr_5_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 366 substates.\n",
      "After splitting, we have a total of 731 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 6th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125938.35630271047\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124799.37472620458\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124346.38100559294\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124089.45657415027\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123920.03527844598\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123798.8976618739\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123702.87800849526\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123623.8899128958\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123558.88169565113\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123493.21502294097\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123402.79174974166\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123249.40764169482\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123030.8941962144\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122816.34359250935\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122616.90049589468\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122380.89164898309\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122066.75331795894\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121666.66337433307\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121210.9848586437\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120734.72921545632\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120266.14764775746\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -119823.60536496165\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -119411.85057177223\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -119033.79670495373\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -118692.70990855126\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -118376.62223557195\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -118071.52276564021\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -117772.88946832\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -117486.47366693328\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training likelihood...done: -117217.78941765432\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -116970.41387411434\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -116743.5872541229\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -116536.62221202151\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -116351.80577298209\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -116186.98664819331\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -116033.17677496969\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115886.55486347967\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115747.37446717215\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115616.86208115256\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115495.83036555682\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115385.52122003667\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115285.62841669323\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115191.94193483089\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115101.8952278024\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -115017.23215439403\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114940.53098840377\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114870.0542899501\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114805.15178385835\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114741.07614596802\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114677.87812485179\n",
      "Saving grammar to mtb.gr_6_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -114678.17730051921\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 1.9095414956243433.\n",
      "Merging 87 siblings and 0 other pairs.\n",
      "State ROOT.\n",
      "State S^g. Merging pair (0,1) at cost 2.7538920404540906E-4. Merging pair (14,15) at cost 0.002077889326361121.\n",
      "State STEM^g.\n",
      "State @STEM^g.\n",
      "State C. Merging pair (0,1) at cost 0.5271294278171765. Merging pair (2,3) at cost 8.437694987151188E-14. Merging pair (4,5) at cost -5.355715870791755E-13. Merging pair (6,7) at cost 4.2210679396248447E-13. Merging pair (8,9) at cost 3.508304757815494E-14. Merging pair (12,13) at cost 5.974110095507966E-13. Merging pair (14,15) at cost 1.6490686240236995E-5. Merging pair (18,19) at cost 0.7256333661668593. Merging pair (20,21) at cost -1.9706458687096529E-13. Merging pair (22,23) at cost -6.328271240363392E-14. Merging pair (24,25) at cost 3.387290448131352E-13. Merging pair (30,31) at cost 0.0034755633607641283.\n",
      "State V. Merging pair (0,1) at cost 4.169312671137297E-10. Merging pair (2,3) at cost 3.6748382115092675E-14. Merging pair (4,5) at cost 0.7049814376479557. Merging pair (6,7) at cost -1.1834977442504169E-13. Merging pair (10,11) at cost 0.9952358299594646. Merging pair (12,13) at cost 2.359223927328457E-13. Merging pair (14,15) at cost 2.393640841091837E-13. Merging pair (16,17) at cost 1.2967404927621826E-13.\n",
      "State SUFFIX^g. Merging pair (2,3) at cost 0.006164302291918666. Merging pair (4,5) at cost 3.7397227304676047E-4. Merging pair (10,11) at cost 0.25588308449609787. Merging pair (12,13) at cost 8.074496477256992E-5. Merging pair (24,25) at cost 0.016043188021541775.\n",
      "State PREFIX^g. Merging pair (8,9) at cost 1.3729848731857925. Merging pair (10,11) at cost 1.9095414956243433. Merging pair (12,13) at cost 0.491510672087443. Merging pair (14,15) at cost 1.9061069451518358. Merging pair (16,17) at cost 0.03665121932843406. Merging pair (20,21) at cost 1.44059436834177.\n",
      "State @SUFFIX^g. Merging pair (0,1) at cost -1.5876189252139757E-14. Merging pair (2,3) at cost 0.9163617065785277. Merging pair (4,5) at cost -5.540012892879531E-14. Merging pair (10,11) at cost 0.6493678380863777. Merging pair (14,15) at cost 1.3857487039260836. Merging pair (16,17) at cost 0.05223120587189263. Merging pair (18,19) at cost -9.496025955776022E-9. Merging pair (20,21) at cost -9.332459930580949E-8. Merging pair (26,27) at cost -9.725202656297811E-11. Merging pair (30,31) at cost 0.09423611425655773. Merging pair (32,33) at cost 0.8792927077451127. Merging pair (36,37) at cost 3.761446709511271E-11. Merging pair (38,39) at cost 0.0011749464739885455. Merging pair (40,41) at cost 1.011045184446238E-7. Merging pair (42,43) at cost 0.7889194557539393.\n",
      "State @PREFIX^g. Merging pair (0,1) at cost 0.9452285697883404. Merging pair (2,3) at cost -3.1666518325881316E-9. Merging pair (4,5) at cost 1.3862943611198906. Merging pair (6,7) at cost 2.2204460492503126E-16. Merging pair (16,17) at cost -1.0964340546653229E-11. Merging pair (20,21) at cost -3.166651388516722E-9. Merging pair (22,23) at cost -9.631276683733013E-11.\n",
      "State identify. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State comprehend. Merging pair (0,1) at cost -1.1102230246251565E-16. Merging pair (6,7) at cost -1.1102230246251565E-16. Merging pair (8,9) at cost -1.1102230246251565E-16. Merging pair (10,11) at cost 2.2204460492503128E-16.\n",
      "State PREFX^g. Merging pair (4,5) at cost 2.2204460492503128E-16.\n",
      "State technic. Merging pair (12,13) at cost -2.220446049250313E-16. Merging pair (22,23) at cost -2.220446049250313E-16.\n",
      "State balance. Merging pair (24,25) at cost 4.4408920985006257E-16. Merging pair (34,35) at cost 4.4408920985006257E-16.\n",
      "State office.\n",
      "State rhythm.\n",
      "State dogma.\n",
      "State racial. Merging pair (30,31) at cost -2.220446049250313E-16. Merging pair (32,33) at cost -2.220446049250313E-16. Merging pair (38,39) at cost -2.220446049250313E-16. Merging pair (42,43) at cost -2.220446049250313E-16.\n",
      "State ^g.\n",
      "State prejudice. Merging pair (18,19) at cost -4.440892098500626E-16.\n",
      "State sad.\n",
      "State dis. Merging pair (32,33) at cost -2.220446049250313E-16. Merging pair (34,35) at cost -2.220446049250313E-16. Merging pair (50,51) at cost -2.220446049250313E-16. Merging pair (54,55) at cost -2.220446049250313E-16.\n",
      "State @S^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State offence. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State grow. Merging pair (10,11) at cost 4.4408920985006257E-16. Merging pair (12,13) at cost 4.4408920985006257E-16. Merging pair (30,31) at cost 4.4408920985006257E-16. Merging pair (32,33) at cost 4.4408920985006257E-16.\n",
      "State back. Merging pair (30,31) at cost 4.4408920985006257E-16. Merging pair (32,33) at cost 4.4408920985006257E-16. Merging pair (40,41) at cost 4.4408920985006257E-16. Merging pair (42,43) at cost 4.4408920985006257E-16. Merging pair (50,51) at cost 4.4408920985006257E-16.\n",
      "State heterosex. Merging pair (14,15) at cost 2.2204460492503128E-16. Merging pair (22,23) at cost 2.2204460492503128E-16.\n",
      "\n",
      "State ROOT had 1 substates and now has 1.\n",
      "State S^g had 18 substates and now has 16.\n",
      "State STEM^g had 16 substates and now has 16.\n",
      "State @STEM^g had 64 substates and now has 64.\n",
      "State C had 40 substates and now has 28.\n",
      "State V had 18 substates and now has 10.\n",
      "State SUFFIX^g had 26 substates and now has 21.\n",
      "State PREFIX^g had 26 substates and now has 20.\n",
      "State @SUFFIX^g had 44 substates and now has 29.\n",
      "State @PREFIX^g had 26 substates and now has 19.\n",
      "State identify had 2 substates and now has 1.\n",
      "State comprehend had 12 substates and now has 8.\n",
      "State PREFX^g had 6 substates and now has 5.\n",
      "State technic had 40 substates and now has 38.\n",
      "State balance had 40 substates and now has 38.\n",
      "State office had 2 substates and now has 2.\n",
      "State rhythm had 14 substates and now has 14.\n",
      "State dogma had 22 substates and now has 22.\n",
      "State racial had 56 substates and now has 52.\n",
      "State ^g had 2 substates and now has 2.\n",
      "State prejudice had 30 substates and now has 29.\n",
      "State sad had 52 substates and now has 52.\n",
      "State dis had 58 substates and now has 54.\n",
      "State @S^g had 2 substates and now has 1.\n",
      "State offence had 4 substates and now has 3.\n",
      "State grow had 34 substates and now has 30.\n",
      "State back had 52 substates and now has 47.\n",
      "State heterosex had 24 substates and now has 22.\n",
      "Lexicon: [dis : 54, racial : 52, sad : 52, back : 47, technic : 38, balance : 38, grow : 30, prejudice : 29, C : 28, dogma : 22, heterosex : 22, rhythm : 14, V : 10, comprehend : 8, offence : 3, office : 2, identify : 1]\n",
      "Grammar: [@STEM^g : 64, @SUFFIX^g : 29, SUFFIX^g : 21, PREFIX^g : 20, @PREFIX^g : 19, S^g : 16, STEM^g : 16, PREFX^g : 5, ^g : 2, @S^g : 1, ROOT : 1]\n",
      "After merging in the 6th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114696.05880909257\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114639.60075548085\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114588.5627208953\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114540.15774707941\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114491.78692452553\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114442.14190452837\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114390.05964470576\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114342.78615019955\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114298.35580669211\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114255.71632997169\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114215.6305814695\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114177.50717018616\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114139.37201440702\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114100.54946691977\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114062.19434117181\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -114025.83102741705\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -113990.7202586568\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -113955.01671462358\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -113921.85140468596\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -113891.69085008847\n",
      "Saving grammar to mtb.gr_6_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 6th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -119246.24193216198\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120155.32064935211\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120339.16674484097\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120389.36039054299\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120397.18787807718\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120385.91127877835\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120364.34670834306\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120337.04466467527\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120307.01629431355\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120276.9212422663\n",
      "Saving grammar to mtb.gr_6_smoothing.gr.\n",
      "Saving successful.\n",
      "Calculating last validation likelihood...done.\n",
      "  Iteration 10 (final) gives validation likelihood 0.0\n",
      "Saving grammar to mtb.gr.\n",
      "It gives a validation data log likelihood of: 0.0\n",
      "Saving successful.\n"
     ]
    }
   ],
   "source": [
    "!java -cp ../lab5_6/BerkeleyParser-1.7.jar edu.berkeley.nlp.PCFGLA.GrammarTrainer -path ../lab8/morphological-treebank-corrected-v2.train -out mtb.gr -treebank SINGLEFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b2563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -jar ../lab5_6/BerkeleyParser-1.7.jar -gr mtb.gr < morphological-treebank.test_input > morphological-treebank.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b40fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maya1/Documents/school/2021W/ling242/git/labs/lab5_6/EVALB\n"
     ]
    }
   ],
   "source": [
    "cd ../lab5_6/EVALB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d0d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for `all'.\r\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ced0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sent.                        Matched  Bracket   Cross        Correct Tag\r\n",
      " ID  Len.  Stat. Recal  Prec.  Bracket gold test Bracket Words  Tags Accracy\r\n",
      "============================================================================\r\n",
      "   1   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "   2   17    0  100.00  87.50     7      7    8      0     17    17   100.00\r\n",
      "   3    9    0   66.67  33.33     2      3    6      0      9     8    88.89\r\n",
      "   4    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "   5    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      "   6   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "   7    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "   8   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "   9    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  10    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "  11   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      "  12   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  13    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  14   11    0   57.14  66.67     4      7    6      1     11    11   100.00\r\n",
      "  15   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      "  16   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      "  17   13    0   66.67  33.33     2      3    6      0     13    13   100.00\r\n",
      "  18   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      "  19    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      "  20   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "  21    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      "  22   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  23   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      "  24    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      "  25   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      "  26   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "  27    6    0  100.00  83.33     5      5    6      0      6     6   100.00\r\n",
      "  28    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      "  29   12    0  100.00  87.50     7      7    8      0     12    12   100.00\r\n",
      "  30    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  31   15    0   85.71  75.00     6      7    8      0     15    15   100.00\r\n",
      "  32    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      "  33    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  34    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      "  35    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  36    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      "  37    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      "  38   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      "  39   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      "  40    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "  41    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  42   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  43   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      "  44   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      "  45   11    0   57.14  66.67     4      7    6      0     11    11   100.00\r\n",
      "  46   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  47    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "  48    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  49   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  50   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      "  51   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      "  52   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  53    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      "  54   12    0  100.00  87.50     7      7    8      0     12    12   100.00\r\n",
      "  55    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  56    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  57   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      "  58   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      "  59    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  60    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      "  61    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  62    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  63    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  64   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "  65    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  66    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  67    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      "  68   15    0  100.00  83.33     5      5    6      0     15    15   100.00\r\n",
      "  69    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  70   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "  71   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      "  72    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  73    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  74   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      "  75   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      "  76   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      "  77   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  78   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      "  79   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      "  80   16    0   80.00  50.00     4      5    8      0     16    16   100.00\r\n",
      "  81   16    0   57.14  66.67     4      7    6      0     16    16   100.00\r\n",
      "  82    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "  83    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "  84   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      "  85   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      "  86    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      "  87    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      "  88   10    0   66.67  33.33     2      3    6      0     10    10   100.00\r\n",
      "  89   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      "  90    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  91   16    0  100.00  83.33     5      5    6      0     16    16   100.00\r\n",
      "  92    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  93    9    0   66.67  33.33     2      3    6      0      9     9   100.00\r\n",
      "  94    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      "  95    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "  96   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      "  97    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "  98    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      "  99   17    0  100.00  87.50     7      7    8      0     17    17   100.00\r\n",
      " 100   10    0   60.00  50.00     3      5    6      1     10    10   100.00\r\n",
      " 101   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 102   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 103   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 104    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 105   10    0   40.00  50.00     2      5    4      0     10    10   100.00\r\n",
      " 106    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 107    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 108   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 109   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 110    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 111   15    0   80.00  50.00     4      5    8      0     15    15   100.00\r\n",
      " 112    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 113   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 114   15    0   66.67  33.33     2      3    6      0     15    15   100.00\r\n",
      " 115   15    0  100.00  83.33     5      5    6      0     15    15   100.00\r\n",
      " 116    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 117   12    0  100.00  87.50     7      7    8      0     12    12   100.00\r\n",
      " 118   11    0   40.00  50.00     2      5    4      0     11    11   100.00\r\n",
      " 119   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 120   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 121   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 122    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 123    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 124    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 125   15    0   85.71  60.00     6      7   10      1     15    15   100.00\r\n",
      " 126    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 127    7    0  100.00  83.33     5      5    6      0      7     7   100.00\r\n",
      " 128   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 129    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 130    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 131    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 132   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 133   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 134    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 135   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 136   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 137   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 138    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 139   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 140   10    0   66.67  33.33     2      3    6      1     10    10   100.00\r\n",
      " 141   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 142   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 143    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 144   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 145   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 146   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 147    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 148    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 149   17    0  100.00  87.50     7      7    8      0     17    17   100.00\r\n",
      " 150   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 151    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 152   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 153   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 154    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 155    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 156    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 157    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 158   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 159   12    0   40.00  50.00     2      5    4      0     12    12   100.00\r\n",
      " 160   14    0   66.67  33.33     2      3    6      0     14    14   100.00\r\n",
      " 161    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 162   11    0   66.67  33.33     2      3    6      1     11    11   100.00\r\n",
      " 163    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 164    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 165    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 166   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 167   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 168    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 169    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 170   11    0   66.67  33.33     2      3    6      0     11    11   100.00\r\n",
      " 171   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 172    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 173    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 174    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 175   12    0   40.00  50.00     2      5    4      0     12    12   100.00\r\n",
      " 176    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 177   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 178    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 179    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 180   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 181   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 182    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 183   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 184   13    0   57.14  66.67     4      7    6      1     13    13   100.00\r\n",
      " 185   14    0   80.00  50.00     4      5    8      0     14    14   100.00\r\n",
      " 186    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 187    7    0  100.00  83.33     5      5    6      0      7     7   100.00\r\n",
      " 188   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 189   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 190   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 191    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 192   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 193   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 194   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 195   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 196   16    0  100.00  75.00     3      3    4      0     16    16   100.00\r\n",
      " 197   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 198   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 199    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 200    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 201    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 202    8    0   57.14  66.67     4      7    6      0      8     8   100.00\r\n",
      " 203    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 204    9    0   40.00  50.00     2      5    4      0      9     9   100.00\r\n",
      " 205    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 206   10    0   40.00  50.00     2      5    4      0     10    10   100.00\r\n",
      " 207   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 208    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 209    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 210    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 211   10    0   66.67  33.33     2      3    6      0     10    10   100.00\r\n",
      " 212    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 213   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 214    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 215   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 216    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 217    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 218    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 219    9    0   66.67  33.33     2      3    6      0      9     9   100.00\r\n",
      " 220   14    0   40.00  50.00     2      5    4      0     14    14   100.00\r\n",
      " 221    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 222    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 223   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 224    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 225    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 226    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 227    7    0  100.00  83.33     5      5    6      0      7     7   100.00\r\n",
      " 228   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 229   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 230    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 231   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 232   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 233    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 234    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 235   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 236    6    0   40.00  50.00     2      5    4      1      6     5    83.33\r\n",
      " 237   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 238    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 239    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 240   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 241    9    0   66.67  33.33     2      3    6      0      9     9   100.00\r\n",
      " 242   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 243   10    0   60.00  50.00     3      5    6      1     10    10   100.00\r\n",
      " 244    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 245   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 246    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 247   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 248    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 249    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 250   12    0   66.67  33.33     2      3    6      0     12    12   100.00\r\n",
      " 251   10    0  100.00  75.00     3      3    4      0     10     9    90.00\r\n",
      " 252    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 253   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 254   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 255    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 256   17    0  100.00  75.00     3      3    4      0     17    17   100.00\r\n",
      " 257    9    0   33.33  25.00     1      3    4      1      9     9   100.00\r\n",
      " 258    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 259    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 260   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 261    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 262   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 263    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 264    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 265    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 266    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 267   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 268    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 269   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 270   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 271    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 272    7    0  100.00  83.33     5      5    6      0      7     7   100.00\r\n",
      " 273    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 274    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 275    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 276   11    0   66.67  33.33     2      3    6      0     11    11   100.00\r\n",
      " 277   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 278    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 279   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 280   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 281   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 282    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 283   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 284   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 285   15    0  100.00  83.33     5      5    6      0     15    15   100.00\r\n",
      " 286   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 287   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 288    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 289   14    0   66.67  33.33     2      3    6      0     14    13    92.86\r\n",
      " 290   13    0   66.67  33.33     2      3    6      0     13    13   100.00\r\n",
      " 291    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 292   12    0   66.67  33.33     2      3    6      0     12    12   100.00\r\n",
      " 293   14    0   66.67  33.33     2      3    6      0     14    14   100.00\r\n",
      " 294    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 295    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 296    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 297   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 298    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 299   13    0  100.00  87.50     7      7    8      0     13    13   100.00\r\n",
      " 300   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 301   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 302   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 303   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 304    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 305   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 306    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 307   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 308   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 309   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 310    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 311    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 312   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 313   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 314    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 315    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 316   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 317   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 318   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 319   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 320   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 321   10    0   66.67  33.33     2      3    6      1     10    10   100.00\r\n",
      " 322   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 323    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 324   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 325    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 326   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 327    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 328   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 329    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 330   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 331    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 332   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 333    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 334    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 335    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 336   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 337   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 338   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 339    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 340   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 341   12    0  100.00  87.50     7      7    8      0     12    12   100.00\r\n",
      " 342   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 343    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 344   14    0   40.00  50.00     2      5    4      0     14    14   100.00\r\n",
      " 345    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 346   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      " 347    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 348   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 349    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 350   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 351   12    0   40.00  50.00     2      5    4      0     12    12   100.00\r\n",
      " 352    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 353   15    0  100.00  83.33     5      5    6      0     15    15   100.00\r\n",
      " 354    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 355    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 356   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 357   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 358    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 359   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 360    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 361    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 362    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 363    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 364   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 365   10    0   40.00  50.00     2      5    4      0     10    10   100.00\r\n",
      " 366   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 367   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 368    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 369    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 370    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 371   10    0   66.67  33.33     2      3    6      0     10    10   100.00\r\n",
      " 372   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 373    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 374   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 375   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 376    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 377    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 378   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 379   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 380   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 381   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 382    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 383    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "384 : Length unmatch (18|2)\r\n",
      " 384   18    1    0.00   0.00     0      0    0      0      0     0     0.00\r\n",
      " 385   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 386   12    0   66.67  33.33     2      3    6      1     12    12   100.00\r\n",
      " 387    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 388   12    0   66.67  33.33     2      3    6      0     12    12   100.00\r\n",
      " 389    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 390    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 391   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 392   13    0   66.67  33.33     2      3    6      0     13    13   100.00\r\n",
      " 393    8    0   66.67  33.33     2      3    6      0      8     8   100.00\r\n",
      " 394    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 395   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 396    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 397    8    0   66.67  33.33     2      3    6      0      8     8   100.00\r\n",
      " 398    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 399    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 400   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 401    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 402    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 403   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 404   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 405   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 406   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 407    9    0   66.67  33.33     2      3    6      0      9     8    88.89\r\n",
      " 408    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 409   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 410    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 411    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 412   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 413   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 414    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 415    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 416   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 417    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 418   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 419   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 420    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 421    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 422    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 423    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 424    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 425   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 426    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 427    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 428    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 429    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 430   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 431   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 432    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 433    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 434    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 435    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 436    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 437    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 438   16    0  100.00  87.50     7      7    8      0     16    16   100.00\r\n",
      " 439    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 440   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      " 441    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 442   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 443   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 444   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 445    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 446    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 447    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 448   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 449   11    0   66.67  33.33     2      3    6      0     11    11   100.00\r\n",
      " 450   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 451   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 452   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 453   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 454   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 455    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 456   13    0   66.67  33.33     2      3    6      0     13    13   100.00\r\n",
      " 457   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 458    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 459   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 460    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 461   10    0   66.67  33.33     2      3    6      0     10    10   100.00\r\n",
      " 462    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 463    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 464   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 465    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 466   13    0   66.67  33.33     2      3    6      0     13    13   100.00\r\n",
      " 467   16    0  100.00  87.50     7      7    8      0     16    16   100.00\r\n",
      " 468    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 469   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 470   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      " 471   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 472   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 473    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 474    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 475    7    0  100.00  83.33     5      5    6      0      7     7   100.00\r\n",
      " 476    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 477    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 478   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      " 479    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 480   10    0   66.67  33.33     2      3    6      0     10    10   100.00\r\n",
      " 481   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 482   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 483    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 484   14    0   66.67  33.33     2      3    6      0     14    14   100.00\r\n",
      " 485   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 486   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 487   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 488   15    0  100.00  83.33     5      5    6      0     15    15   100.00\r\n",
      " 489   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 490   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 491    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 492    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 493   14    0   66.67  33.33     2      3    6      0     14    14   100.00\r\n",
      " 494   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 495   15    0   80.00  50.00     4      5    8      0     15    15   100.00\r\n",
      " 496    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 497   18    0   71.43  62.50     5      7    8      1     18    18   100.00\r\n",
      " 498   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 499    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 500    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 501   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 502   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 503    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 504   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 505    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 506   12    0  100.00  87.50     7      7    8      0     12    12   100.00\r\n",
      " 507    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 508    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 509   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 510    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 511    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 512    8    0   66.67  33.33     2      3    6      0      8     8   100.00\r\n",
      " 513   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 514    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 515    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 516   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 517    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 518   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 519    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 520   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 521    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 522   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 523   13    0  100.00  87.50     7      7    8      0     13    13   100.00\r\n",
      " 524    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 525    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 526   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 527    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 528   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 529   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 530    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 531    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 532   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 533    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 534    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 535   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 536    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 537   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 538    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 539   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 540   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 541    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 542   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 543    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 544   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 545    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 546   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 547    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 548    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 549    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 550    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 551   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 552    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 553    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 554    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 555    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 556    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 557   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 558    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 559   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 560   12    0   57.14  66.67     4      7    6      0     12    12   100.00\r\n",
      " 561   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 562    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 563    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 564    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 565   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 566   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 567    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 568    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 569    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 570   16    0  100.00  83.33     5      5    6      0     16    16   100.00\r\n",
      " 571   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 572   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 573   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 574    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 575    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 576   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 577    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 578   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 579    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 580   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 581    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 582    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 583    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 584    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 585   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 586    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 587   16    0   66.67  25.00     2      3    8      0     16    16   100.00\r\n",
      " 588    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 589    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 590    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 591    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 592    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 593   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 594    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 595   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 596   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 597   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 598    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 599   17    0  100.00  75.00     3      3    4      0     17    17   100.00\r\n",
      " 600    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 601   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 602   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 603   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 604    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 605   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 606   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 607    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 608    7    0  100.00  83.33     5      5    6      0      7     7   100.00\r\n",
      " 609   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 610    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 611   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 612   15    0  100.00  87.50     7      7    8      0     15    15   100.00\r\n",
      " 613    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 614    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 615   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 616    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 617    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 618   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 619    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 620   15    0   40.00  50.00     2      5    4      0     15    15   100.00\r\n",
      " 621    9    0   66.67  33.33     2      3    6      0      9     9   100.00\r\n",
      " 622    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 623    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 624   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 625    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 626    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 627    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 628   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 629   13    0   57.14  50.00     4      7    8      2     13    13   100.00\r\n",
      " 630    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 631   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 632    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 633    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 634   12    0   66.67  33.33     2      3    6      0     12    12   100.00\r\n",
      " 635    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 636    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 637    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 638    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 639    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 640    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 641    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 642    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 643    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 644   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 645   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 646   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 647    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 648    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 649   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 650   15    0  100.00  87.50     7      7    8      0     15    15   100.00\r\n",
      " 651   12    0   66.67  33.33     2      3    6      0     12    12   100.00\r\n",
      " 652    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 653    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 654   11    0  100.00  83.33     5      5    6      0     11    11   100.00\r\n",
      " 655    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 656   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      " 657   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 658    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 659   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 660    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 661   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 662   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 663   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 664   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 665   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 666    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 667    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 668   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 669    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 670   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 671    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 672    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 673   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 674    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 675   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 676   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      " 677    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 678   15    0  100.00  83.33     5      5    6      0     15    15   100.00\r\n",
      " 679   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 680    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 681   15    0  100.00  75.00     3      3    4      0     15    15   100.00\r\n",
      " 682    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 683    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 684    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 685    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 686   15    0  100.00  83.33     5      5    6      0     15    15   100.00\r\n",
      " 687   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 688    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 689    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 690    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 691   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 692   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 693   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 694    8    0   40.00  50.00     2      5    4      0      8     8   100.00\r\n",
      " 695   14    0  100.00  87.50     7      7    8      0     14    14   100.00\r\n",
      " 696   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 697    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 698    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 699    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 700    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 701   13    0  100.00  75.00     3      3    4      0     13    13   100.00\r\n",
      " 702    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 703   14    0  100.00  83.33     5      5    6      0     14    14   100.00\r\n",
      " 704   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 705   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 706    8    0  100.00  83.33     5      5    6      0      8     8   100.00\r\n",
      " 707    9    0  100.00  83.33     5      5    6      0      9     9   100.00\r\n",
      " 708    6    0  100.00  75.00     3      3    4      0      6     6   100.00\r\n",
      " 709   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 710   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 711    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 712    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 713   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 714   13    0  100.00  83.33     5      5    6      0     13    13   100.00\r\n",
      " 715    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 716    4    0  100.00  75.00     3      3    4      0      4     4   100.00\r\n",
      " 717    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 718   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 719   10    0   57.14  66.67     4      7    6      1     10     9    90.00\r\n",
      " 720   15    0  100.00  87.50     7      7    8      0     15    15   100.00\r\n",
      " 721    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 722    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 723   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 724    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 725    9    0   66.67  33.33     2      3    6      1      9     9   100.00\r\n",
      " 726   10    0  100.00  83.33     5      5    6      0     10    10   100.00\r\n",
      " 727   10    0  100.00  75.00     3      3    4      0     10    10   100.00\r\n",
      " 728   11    0  100.00  75.00     3      3    4      0     11    11   100.00\r\n",
      " 729    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 730    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 731   12    0  100.00  83.33     5      5    6      0     12    12   100.00\r\n",
      " 732   14    0  100.00  75.00     3      3    4      0     14    14   100.00\r\n",
      " 733    9    0  100.00  75.00     3      3    4      0      9     9   100.00\r\n",
      " 734    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 735    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      " 736    8    0  100.00  75.00     3      3    4      0      8     8   100.00\r\n",
      " 737    5    0  100.00  75.00     3      3    4      0      5     5   100.00\r\n",
      " 738   12    0  100.00  75.00     3      3    4      0     12    12   100.00\r\n",
      " 739    7    0  100.00  75.00     3      3    4      0      7     7   100.00\r\n",
      "============================================================================\r\n",
      "                 95.71  74.10   2586  2702  3490     16   7161  7155    99.92\r\n",
      "=== Summary ===\r\n",
      "\r\n",
      "-- All --\r\n",
      "Number of sentence        =    739\r\n",
      "Number of Error sentence  =      1\r\n",
      "Number of Skip  sentence  =      0\r\n",
      "Number of Valid sentence  =    738\r\n",
      "Bracketing Recall         =  95.71\r\n",
      "Bracketing Precision      =  74.10\r\n",
      "Bracketing FMeasure       =  83.53\r\n",
      "Complete match            =   0.00\r\n",
      "Average crossing          =   0.02\r\n",
      "No crossing               =  97.97\r\n",
      "2 or less crossing        = 100.00\r\n",
      "Tagging accuracy          =  99.92\r\n",
      "\r\n",
      "-- len<=40 --\r\n",
      "Number of sentence        =    739\r\n",
      "Number of Error sentence  =      1\r\n",
      "Number of Skip  sentence  =      0\r\n",
      "Number of Valid sentence  =    738\r\n",
      "Bracketing Recall         =  95.71\r\n",
      "Bracketing Precision      =  74.10\r\n",
      "Bracketing FMeasure       =  83.53\r\n",
      "Complete match            =   0.00\r\n",
      "Average crossing          =   0.02\r\n",
      "No crossing               =  97.97\r\n",
      "2 or less crossing        = 100.00\r\n",
      "Tagging accuracy          =  99.92\r\n"
     ]
    }
   ],
   "source": [
    "!./evalb -p COLLINS.prm ../../lab8/morphological-treebank.test_gold ../../lab8/morphological-treebank.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3db842",
   "metadata": {},
   "source": [
    "### unsupervised discovery of morphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f976f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maya1/Documents/school/2021W/ling242/git/labs/lab8/morfessor-2.0.6\n"
     ]
    }
   ],
   "source": [
    "cd ../../lab8/morfessor-2.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4b1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d ../fin.train.lowered.tok.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd66caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1000 ../fin.train.lowered.tok > ../fin.train.lowered.tok.1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f5a673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus from '../fin.train.lowered.tok.1K'...\n",
      "Detected utf-8 encoding\n",
      "Done.\n",
      "Compounds in training data: 7094 types / 7094 tokens\n",
      "Starting batch training\n",
      "Epochs: 0\tCost: 217463.83166851214\n",
      "...........................................................\n",
      "Epochs: 1\tCost: 192838.2146249141\n",
      "...........................................................\n",
      "Epochs: 2\tCost: 177323.88595777942\n",
      "...........................................................\n",
      "Epochs: 3\tCost: 173387.95493578643\n",
      "...........................................................\n",
      "Epochs: 4\tCost: 172394.85587225377\n",
      "...........................................................\n",
      "Epochs: 5\tCost: 172145.25881820754\n",
      "...........................................................\n",
      "Epochs: 6\tCost: 171981.3045386062\n",
      "...........................................................\n",
      "Epochs: 7\tCost: 171922.1985146227\n",
      "...........................................................\n",
      "Epochs: 8\tCost: 171848.5437810697\n",
      "...........................................................\n",
      "Epochs: 9\tCost: 171837.87289303323\n",
      "Done.\n",
      "Epochs: 9\n",
      "Final cost: 171837.87289303323\n",
      "Training time: 36.264s\n",
      "Saving model to 'model_1K.bin'...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!./scripts/morfessor-train ../fin.train.lowered.tok.1K -s model_1K.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e13e4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from 'model_1K.bin'...\n",
      "Done.\n",
      "No training data files specified.\n",
      "Segmenting test data...\n",
      "Reading corpus from '../fin.test'...\n",
      "Detected utf-8 encoding\n",
      "Done.\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!./scripts/morfessor-segment -l model_1K.bin ../fin.test > ../fin.test.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[?47h\u001b[?1h\u001b=\r",
      "a-oikeuksia     a - oik e uksia a oikea_A +DA-US +PL +PTV\r\n",
      "a-rajan a - raja n      a raja_N +GEN\r\n",
      "aataminomenaan  aa ta min o men a an    aatami_N +GEN omena_N +ILL\r\n",
      "aikoneet        ai ko neet      aikoa_V +PCP2 +PL\r\n",
      "aiottuja        aio ttu ja      aikoa_V +PSSPCP2 +PL +PTV\r\n",
      "ajanmukaisuudesta       ajan m ukais uudesta    aika_N +GEN mukainen_A +DA-UUS + \bELA\r\n",
      "alakanttiin     ala kan ttiin   ala_N kantti_N +ILL, ala_PFX kantti_N +ILL\r\n",
      "alaspinkin     ala s pin kin  alanen_N pin_ADV kin_CLI, alas pin_ADV kin_CLI \b, alas_ADV pin_ADV kin_CLI\r\n",
      "alttonsa        al tto nsa      altto_N +3SGPL\r\n",
      "alttoviulistien al tto vi ul is tien    altto_N viulisti_N +PL +GEN\r\n",
      "aluemyynnin     alu em y y nni n        alue_N myyd_V +DV-NTI +GEN\r\n",
      "alushame        alus ha me      alunen_N hame_N, alus_N hame_N\r\n",
      "alusyksikk     alus yksi k k  alunen_N yksikk_N, alus_N yksikk_N\r\n",
      "amatriorkesteri       a ma t  ri or ke st eri       amatri_N orkesteri_N\r\n",
      "amerikkalaiskuluttajan  amerikka lais kulu ttaja n      amerikkalainen_A/N kulua \b_V +DV-TTA +DV-JA +GEN\r\n",
      "amerikkalaisyhtit     amerikka lais yhti t  amerikkalainen_A/N yhti_N +PTV\r\n",
      "ammattiauttajia ammatti auttajia        ammatti_N auttaa_V +DV-JA +PL +PTV\r\n",
      "ammattitutkintolaki     ammatti tutki n to la ki        ammatti_N tutkinto_N lak \bi_N\r\n",
      "analysoidut     an a ly soi dut analysoida_V +DV-TU +SG2, analysoida_V +PSSPCP2  \b:\u001b[K"
     ]
    }
   ],
   "source": [
    "!paste ../fin.test  ../fin.test.result ../fin.test_gold| less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360cdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
