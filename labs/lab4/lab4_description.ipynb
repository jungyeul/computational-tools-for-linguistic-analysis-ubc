{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unexpected-basics",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "The **obejctive** of this lab is to to assign a syntactic structure to sentences by training and evaluating our: \n",
    "- constituent parsers (using PTB \"Penn Tree Bank\")\n",
    "- dependency parsers (using UD \"Universal Dependency\")\n",
    "\n",
    "The parse trees we are generating can be used in applications like grammar checkers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-liabilities",
   "metadata": {},
   "source": [
    "## Constituent parsing (Berkeley parser)\n",
    "### INSTALLATION\n",
    "**Constituent parsing** is when you divide a sentence into constituents (smaller phrases that belong to a specific grammar category). \n",
    "\n",
    "Make sure you're in the right directory before downloading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ced734-9ada-4e77-8612-43ca99e45a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabellepurnomo\n"
     ]
    }
   ],
   "source": [
    "# current directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ef0679-b7c6-4ec4-9247-8fab3d28c7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2\n"
     ]
    }
   ],
   "source": [
    "# moving to the folder I want to download my files into\n",
    "%cd /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13358e38-3aa4-4e47-b5cb-bae3a4144b95",
   "metadata": {},
   "source": [
    "First we will download Berkeley Parser, a parsing algorithm written by Slav Petrov & Dan Klein (2007)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5991ec50-2468-488b-8951-0fefd20616a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'berkeleyparser'...\n",
      "remote: Enumerating objects: 1399, done.\u001b[K\n",
      "remote: Total 1399 (delta 0), reused 0 (delta 0), pack-reused 1399\u001b[K\n",
      "Receiving objects: 100% (1399/1399), 90.05 MiB | 2.83 MiB/s, done.\n",
      "Resolving deltas: 100% (756/756), done.\n",
      "Updating files: 100% (331/331), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/slavpetrov/berkeleyparser.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a223ccef-83e6-4583-97db-98485bf947a3",
   "metadata": {},
   "source": [
    "Open the Berkeley Parser tarball (bundle of files, non-compressed) to get its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a3e3c-3c60-4c88-8236-0a7bd8eb967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvfz /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/UD_English-EWT.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86b22b-19d4-4d1b-a669-e64c68608785",
   "metadata": {},
   "source": [
    "``cd`` (change directory/move) to our berkeleyparser folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523d063a-4739-405c-b959-3bde4714a305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/berkeleyparser\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/berkeleyparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b4c00-e024-4856-acf7-1c1c9f36b309",
   "metadata": {},
   "source": [
    "### TRAINING\n",
    "To generate our trees, we input an annotated parsed text from Penn Tree Bank called \"02-21.10way_1Kclean\" which is a small file that contains 1K lines.  \n",
    "\n",
    "When training our language model with berkeley parser, it will do 6 iterations of  \n",
    "- **split** randomly to get CFG rules  \n",
    "- **merge** when the generated rules don't improve our parser \n",
    "- **smooth** to normalize our results \n",
    "\n",
    "There are intermediate files named \"ptb.gr_*_merging.gr\" generated after each iteration.\n",
    "\n",
    "We output our final grammar as a binary file called \"ptb.gr\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecfb90-5bb6-48cd-9bdb-3e00f138e998",
   "metadata": {},
   "source": [
    "First, let's learn grammar from trees contained in a SINGLEFILE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5633c884-4b9c-48cc-8949-dd859453f745",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling with { -path => /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/02-21.10way_1K.clean -out => ptb.gr -treebank => SINGLEFILE }\n",
      "Loading trees from /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/02-21.10way_1K.clean and using language SINGLEFILE\n",
      "Will remove sentences with more than 10000 words.\n",
      "Using horizontal=0 and vertical=1 markovization.\n",
      "Using RIGHT binarization.\n",
      "Using a randomness value of 1.0\n",
      "Using grammar output file ptb.gr.\n",
      "Random number generator seeded at 2.\n",
      "I will do at least 50 iterations.\n",
      "Using smoothing parameters 0.5 and 0.1\n",
      "Loading data from single file!\n",
      "Loading trees from single file...done\n",
      "In training set we have # of words: 24358\n",
      "reducing number of training trees from 1000 to 1000\n",
      "Binarizing and annotating trees...done.\n",
      "Binarizing and annotating trees...done.\n",
      "There are 1000 trees in the training set.\n",
      "Will remove rules with prob under 1.0E-30.\n",
      "Even though only unlikely rules are pruned the training LL is not guaranteed to increase in every round anymore (especially when we are close to converging).\n",
      "Furthermore it increases the variance because 'good' rules can be pruned away in early stages.\n",
      "There are 86 observed categories.\n",
      "Will merge 50% of the splits in each round.\n",
      "The threshold for merging lexical and phrasal categories will be set separately: false\n",
      "Before splitting, we have a total of 86 substates.\n",
      "After splitting, we have a total of 171 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 1th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171092.95385023655\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171043.6428426715\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171043.59197196498\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171043.42387440737\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171042.8430771287\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171040.78808786362\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171033.4032273202\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -171006.71346685727\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170911.94580750263\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -170601.1081185066\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -169774.96238168218\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -168294.94688194522\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -166571.0972721186\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -165052.59956119483\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -163837.25121229453\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -162824.47644236728\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -162032.0134063188\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -161449.14685111874\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160997.98219765702\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160603.7015716172\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160246.59045667524\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -159937.21318744277\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -159683.54378985765\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -159482.25919759032\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -159324.00588448986\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -159195.39149845843\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -159087.82836472153\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158994.07174725825\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158908.330685631\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158828.6368354939\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158751.21825457053\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158675.66930146478\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158604.95244407642\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158544.6094199764\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158497.52843711013\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158460.451709822\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158431.31239656184\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158410.5757886778\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158395.4363275762\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158382.82234785525\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158371.5001059659\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158361.2393877807\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158351.96332397015\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158343.35203028843\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158335.05432704504\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158326.80049105556\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158318.37787245587\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158309.70256142988\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158300.9009666423\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158292.22714954312\n",
      "Saving grammar to ptb.gr_1_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -158744.0576790166\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 16.25823931747699.\n",
      "Merging 42 siblings and 0 other pairs.\n",
      "State TOP.\n",
      "State S^g.\n",
      "State @S^g.\n",
      "State PP^g.\n",
      "State IN.\n",
      "State NP^g.\n",
      "State @NP^g.\n",
      "State DT.\n",
      "State NNP.\n",
      "State CD.\n",
      "State NN.\n",
      "State ``. Merging pair (0,1) at cost -7.105427357601002E-15.\n",
      "State ''. Merging pair (0,1) at cost -1.5654144647214707E-14.\n",
      "State POS. Merging pair (0,1) at cost 15.517910863541436.\n",
      "State PRN^g.\n",
      "State @PRN^g.\n",
      "State -LRB-. Merging pair (0,1) at cost 5.037739189169326.\n",
      "State JJ.\n",
      "State NNS.\n",
      "State VP^g.\n",
      "State @VP^g.\n",
      "State VBP.\n",
      "State ,. Merging pair (0,1) at cost 1.0769163338864017E-13.\n",
      "State CC.\n",
      "State -RRB-. Merging pair (0,1) at cost 0.001059501439946309.\n",
      "State VBN.\n",
      "State VBD.\n",
      "State ADVP^g.\n",
      "State RB.\n",
      "State TO. Merging pair (0,1) at cost 1.0268755622123236E-4.\n",
      "State ..\n",
      "State VBZ.\n",
      "State NNPS. Merging pair (0,1) at cost -3.1086244689504383E-15.\n",
      "State SBAR^g.\n",
      "State PRP. Merging pair (0,1) at cost 0.19324687322135875.\n",
      "State PRP$.\n",
      "State VB.\n",
      "State ADJP^g.\n",
      "State QP^g.\n",
      "State @PP^g.\n",
      "State MD.\n",
      "State UCP^g. Merging pair (0,1) at cost 13.862943611198906.\n",
      "State @UCP^g.\n",
      "State VBG. Merging pair (0,1) at cost 2.1538326677728034E-14.\n",
      "State @SBAR^g.\n",
      "State WHNP^g. Merging pair (0,1) at cost 8.647653662226897.\n",
      "State @ADVP^g. Merging pair (0,1) at cost 13.760809913962603.\n",
      "State RBR.\n",
      "State :.\n",
      "State SINV^g.\n",
      "State @SINV^g.\n",
      "State WP. Merging pair (0,1) at cost 4.848851090082077.\n",
      "State WDT. Merging pair (0,1) at cost 1.1840204176703861E-5.\n",
      "State JJR.\n",
      "State PDT. Merging pair (0,1) at cost 6.601771713886561.\n",
      "State RBS. Merging pair (0,1) at cost -3.3306690738754696E-16.\n",
      "State @QP^g.\n",
      "State @ADJP^g.\n",
      "State JJS. Merging pair (0,1) at cost -2.7755575615628914E-15.\n",
      "State FRAG^g. Merging pair (0,1) at cost 16.25823931747699.\n",
      "State NAC^g. Merging pair (0,1) at cost 5.27540444044443.\n",
      "State @NAC^g. Merging pair (0,1) at cost 8.977555278587353.\n",
      "State WHADVP^g. Merging pair (0,1) at cost 4.885439644297627.\n",
      "State WRB. Merging pair (0,1) at cost 6.106707246542899.\n",
      "State $. Merging pair (0,1) at cost 0.05565891893510773.\n",
      "State PRT^g. Merging pair (0,1) at cost 11.082687755828013.\n",
      "State RP. Merging pair (0,1) at cost 10.963197812356329.\n",
      "State NX^g.\n",
      "State @FRAG^g. Merging pair (0,1) at cost 12.028472597961697.\n",
      "State WHPP^g. Merging pair (0,1) at cost 1.9614439903158767.\n",
      "State SQ^g. Merging pair (0,1) at cost 5.004024235381879.\n",
      "State @SQ^g. Merging pair (0,1) at cost 13.201504035853224.\n",
      "State @NX^g. Merging pair (0,1) at cost 15.276340039075501.\n",
      "State SBARQ^g. Merging pair (0,1) at cost 1.9095425048844388.\n",
      "State @SBARQ^g. Merging pair (0,1) at cost -2.220446049250313E-16.\n",
      "State FW. Merging pair (0,1) at cost 0.7938244907154266.\n",
      "State EX. Merging pair (0,1) at cost -1.7763568394002505E-15.\n",
      "State CONJP^g. Merging pair (0,1) at cost 4.272981513476326.\n",
      "State WHADJP^g. Merging pair (0,1) at cost 0.8630462168705976.\n",
      "State #.\n",
      "State @CONJP^g.\n",
      "State @WHADJP^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State INTJ^g. Merging pair (0,1) at cost 1.3862501212754719.\n",
      "State WP$. Merging pair (0,1) at cost -1.1102230246251565E-16.\n",
      "State X^g. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State UH. Merging pair (0,1) at cost -1.1102230246251565E-16.\n",
      "\n",
      "State TOP had 1 substates and now has 1.\n",
      "State S^g had 2 substates and now has 2.\n",
      "State @S^g had 2 substates and now has 2.\n",
      "State PP^g had 2 substates and now has 2.\n",
      "State IN had 2 substates and now has 2.\n",
      "State NP^g had 2 substates and now has 2.\n",
      "State @NP^g had 2 substates and now has 2.\n",
      "State DT had 2 substates and now has 2.\n",
      "State NNP had 2 substates and now has 2.\n",
      "State CD had 2 substates and now has 2.\n",
      "State NN had 2 substates and now has 2.\n",
      "State `` had 2 substates and now has 1.\n",
      "State '' had 2 substates and now has 1.\n",
      "State POS had 2 substates and now has 1.\n",
      "State PRN^g had 2 substates and now has 2.\n",
      "State @PRN^g had 2 substates and now has 2.\n",
      "State -LRB- had 2 substates and now has 1.\n",
      "State JJ had 2 substates and now has 2.\n",
      "State NNS had 2 substates and now has 2.\n",
      "State VP^g had 2 substates and now has 2.\n",
      "State @VP^g had 2 substates and now has 2.\n",
      "State VBP had 2 substates and now has 2.\n",
      "State , had 2 substates and now has 1.\n",
      "State CC had 2 substates and now has 2.\n",
      "State -RRB- had 2 substates and now has 1.\n",
      "State VBN had 2 substates and now has 2.\n",
      "State VBD had 2 substates and now has 2.\n",
      "State ADVP^g had 2 substates and now has 2.\n",
      "State RB had 2 substates and now has 2.\n",
      "State TO had 2 substates and now has 1.\n",
      "State . had 2 substates and now has 2.\n",
      "State VBZ had 2 substates and now has 2.\n",
      "State NNPS had 2 substates and now has 1.\n",
      "State SBAR^g had 2 substates and now has 2.\n",
      "State PRP had 2 substates and now has 1.\n",
      "State PRP$ had 2 substates and now has 2.\n",
      "State VB had 2 substates and now has 2.\n",
      "State ADJP^g had 2 substates and now has 2.\n",
      "State QP^g had 2 substates and now has 2.\n",
      "State @PP^g had 2 substates and now has 2.\n",
      "State MD had 2 substates and now has 2.\n",
      "State UCP^g had 2 substates and now has 1.\n",
      "State @UCP^g had 2 substates and now has 2.\n",
      "State VBG had 2 substates and now has 1.\n",
      "State @SBAR^g had 2 substates and now has 2.\n",
      "State WHNP^g had 2 substates and now has 1.\n",
      "State @ADVP^g had 2 substates and now has 1.\n",
      "State RBR had 2 substates and now has 2.\n",
      "State : had 2 substates and now has 2.\n",
      "State SINV^g had 2 substates and now has 2.\n",
      "State @SINV^g had 2 substates and now has 2.\n",
      "State WP had 2 substates and now has 1.\n",
      "State WDT had 2 substates and now has 1.\n",
      "State JJR had 2 substates and now has 2.\n",
      "State PDT had 2 substates and now has 1.\n",
      "State RBS had 2 substates and now has 1.\n",
      "State @QP^g had 2 substates and now has 2.\n",
      "State @ADJP^g had 2 substates and now has 2.\n",
      "State JJS had 2 substates and now has 1.\n",
      "State FRAG^g had 2 substates and now has 1.\n",
      "State NAC^g had 2 substates and now has 1.\n",
      "State @NAC^g had 2 substates and now has 1.\n",
      "State WHADVP^g had 2 substates and now has 1.\n",
      "State WRB had 2 substates and now has 1.\n",
      "State $ had 2 substates and now has 1.\n",
      "State PRT^g had 2 substates and now has 1.\n",
      "State RP had 2 substates and now has 1.\n",
      "State NX^g had 2 substates and now has 2.\n",
      "State @FRAG^g had 2 substates and now has 1.\n",
      "State WHPP^g had 2 substates and now has 1.\n",
      "State SQ^g had 2 substates and now has 1.\n",
      "State @SQ^g had 2 substates and now has 1.\n",
      "State @NX^g had 2 substates and now has 1.\n",
      "State SBARQ^g had 2 substates and now has 1.\n",
      "State @SBARQ^g had 2 substates and now has 1.\n",
      "State FW had 2 substates and now has 1.\n",
      "State EX had 2 substates and now has 1.\n",
      "State CONJP^g had 2 substates and now has 1.\n",
      "State WHADJP^g had 2 substates and now has 1.\n",
      "State # had 2 substates and now has 2.\n",
      "State @CONJP^g had 2 substates and now has 2.\n",
      "State @WHADJP^g had 2 substates and now has 1.\n",
      "State INTJ^g had 2 substates and now has 1.\n",
      "State WP$ had 2 substates and now has 1.\n",
      "State X^g had 2 substates and now has 1.\n",
      "State UH had 2 substates and now has 1.\n",
      "Lexicon: [IN : 2, DT : 2, CD : 2, # : 2, VBN : 2, JJR : 2, VBD : 2, RB : 2, NN : 2, JJ : 2, . : 2, VBZ : 2, NNS : 2, NNP : 2, VBP : 2, : : 2, PRP$ : 2, VB : 2, MD : 2, CC : 2, RBR : 2, PRP : 1, NNPS : 1, WRB : 1, $ : 1, TO : 1, -LRB- : 1, WP$ : 1, UH : 1, -RRB- : 1, , : 1, '' : 1, WP : 1, RBS : 1, JJS : 1, FW : 1, EX : 1, WDT : 1, VBG : 1, PDT : 1, RP : 1, `` : 1, POS : 1]\n",
      "Grammar: [S^g : 2, PP^g : 2, @PRN^g : 2, @UCP^g : 2, VP^g : 2, @SBAR^g : 2, NP^g : 2, @VP^g : 2, @CONJP^g : 2, SINV^g : 2, ADVP^g : 2, @SINV^g : 2, @QP^g : 2, @S^g : 2, NX^g : 2, @NP^g : 2, SBAR^g : 2, @ADJP^g : 2, ADJP^g : 2, PRN^g : 2, QP^g : 2, @PP^g : 2, SBARQ^g : 1, CONJP^g : 1, WHADJP^g : 1, WHNP^g : 1, INTJ^g : 1, TOP : 1, UCP^g : 1, FRAG^g : 1, NAC^g : 1, WHADVP^g : 1, PRT^g : 1, @SQ^g : 1, @SBARQ^g : 1, @WHADJP^g : 1, X^g : 1, @FRAG^g : 1, @NAC^g : 1, SQ^g : 1, @ADVP^g : 1, @NX^g : 1, WHPP^g : 1]\n",
      "After merging in the 1th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158475.0104065781\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158465.61988412018\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158458.30037107522\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158451.7977229025\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158445.74040262043\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158441.268572243\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158438.3540325791\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158436.0952490091\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158434.0763631806\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158431.93075297098\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158429.42312007217\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158426.6654529488\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158424.08916312808\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158421.7309199018\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158419.62886917216\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158417.76748066832\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158416.02892689823\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158414.41024465105\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158412.89149172106\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158411.42930964372\n",
      "Saving grammar to ptb.gr_1_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 1th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160556.35868740542\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160554.9118014394\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160553.44359550864\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160551.91299798127\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160550.26656874502\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160548.42312248246\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160546.15895450235\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160542.77867018562\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160537.4403945948\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -160532.10080184616\n",
      "Saving grammar to ptb.gr_1_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 129 substates.\n",
      "After splitting, we have a total of 257 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 2th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158387.17142408423\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158384.5210435224\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158383.10884584364\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158381.79794092235\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158380.31836500898\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158378.18669344654\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158373.69897547233\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158360.7171855283\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158318.82624929442\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -158195.10268502124\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157907.6879892504\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -157409.49712907008\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -156695.60996136419\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -155748.7620697122\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -154715.65865896727\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -153751.21729745957\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152884.84337433305\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -152177.27082313722\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151600.55425044408\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -151129.9360320421\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -150764.4942542801\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -150481.28973316043\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -150252.46385844817\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -150068.89899233868\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149924.33023389723\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149811.9436411376\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149722.56641899934\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149647.3809639544\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149580.679164894\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149519.7013770715\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149463.0978854374\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149410.58043249196\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149362.16166486507\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149317.34197845988\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149274.10785420518\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149230.89296184687\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149187.5191769508\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149143.6210902325\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149101.8003286956\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149062.31320801025\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149024.26171278072\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148986.4466838566\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148949.25545525632\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148913.38955028064\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148879.6122762873\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148848.76547227835\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148820.86206814024\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148794.86216884808\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148770.02886581916\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148748.0012978939\n",
      "Saving grammar to ptb.gr_2_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -149199.9899141785\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 13.879286857894472.\n",
      "Merging 62 siblings and 0 other pairs.\n",
      "State TOP.\n",
      "State S^g. Merging pair (0,1) at cost 0.751490758827837.\n",
      "State @S^g.\n",
      "State PP^g.\n",
      "State IN.\n",
      "State NP^g.\n",
      "State @NP^g.\n",
      "State DT.\n",
      "State NNP.\n",
      "State CD.\n",
      "State NN.\n",
      "State ``. Merging pair (0,1) at cost -3.108624468950438E-14.\n",
      "State ''. Merging pair (0,1) at cost 3.663735981263016E-15.\n",
      "State POS. Merging pair (0,1) at cost 13.557618991742652.\n",
      "State PRN^g. Merging pair (0,1) at cost 8.60478879329414. Merging pair (2,3) at cost 13.879286857894472.\n",
      "State @PRN^g.\n",
      "State -LRB-. Merging pair (0,1) at cost 5.59974078640932.\n",
      "State JJ.\n",
      "State NNS. Merging pair (0,1) at cost 3.1241053156545022.\n",
      "State VP^g.\n",
      "State @VP^g.\n",
      "State VBP. Merging pair (0,1) at cost 9.543036862082625.\n",
      "State ,. Merging pair (0,1) at cost -7.205347429817266E-14.\n",
      "State CC.\n",
      "State -RRB-. Merging pair (0,1) at cost 0.14077992985678084.\n",
      "State VBN. Merging pair (2,3) at cost 8.871792189778499E-13.\n",
      "State VBD. Merging pair (2,3) at cost 6.557570762413646E-6.\n",
      "State ADVP^g.\n",
      "State RB.\n",
      "State TO. Merging pair (0,1) at cost 1.317212513679858.\n",
      "State .. Merging pair (0,1) at cost 2.442490654175342E-15. Merging pair (2,3) at cost 1.0325074129013954E-14.\n",
      "State VBZ.\n",
      "State NNPS. Merging pair (0,1) at cost 9.992007221626405E-16.\n",
      "State SBAR^g.\n",
      "State PRP. Merging pair (0,1) at cost 0.09410347578909328.\n",
      "State PRP$. Merging pair (0,1) at cost 11.320594819246441.\n",
      "State VB. Merging pair (2,3) at cost 11.393773662375072.\n",
      "State ADJP^g.\n",
      "State QP^g. Merging pair (2,3) at cost 11.201060184733711.\n",
      "State @PP^g.\n",
      "State MD. Merging pair (0,1) at cost 2.8519579836454394. Merging pair (2,3) at cost 3.491272405877531.\n",
      "State UCP^g. Merging pair (0,1) at cost 13.762776274271767.\n",
      "State @UCP^g. Merging pair (0,1) at cost 10.585011810527714. Merging pair (2,3) at cost 9.124591856417142.\n",
      "State VBG. Merging pair (0,1) at cost 7.771561172376094E-15.\n",
      "State @SBAR^g. Merging pair (0,1) at cost 6.073779156952326.\n",
      "State WHNP^g.\n",
      "State @ADVP^g.\n",
      "State RBR. Merging pair (0,1) at cost -1.5543122344752505E-15. Merging pair (2,3) at cost -1.1102230246251565E-15.\n",
      "State :. Merging pair (2,3) at cost 1.4432899320127033E-15.\n",
      "State SINV^g. Merging pair (0,1) at cost 7.638170019537754. Merging pair (2,3) at cost -4.3298697960381105E-15.\n",
      "State @SINV^g.\n",
      "State WP.\n",
      "State WDT. Merging pair (0,1) at cost 3.497949801738064E-6.\n",
      "State JJR. Merging pair (0,1) at cost 5.1070259132757035E-15. Merging pair (2,3) at cost 2.5535129566378596E-15.\n",
      "State PDT. Merging pair (0,1) at cost 7.231449523109667.\n",
      "State RBS. Merging pair (0,1) at cost -7.771561172376096E-16.\n",
      "State @QP^g.\n",
      "State @ADJP^g.\n",
      "State JJS. Merging pair (0,1) at cost -1.6653345369377348E-15.\n",
      "State FRAG^g.\n",
      "State NAC^g. Merging pair (0,1) at cost 6.631998509944516.\n",
      "State @NAC^g. Merging pair (0,1) at cost 8.708880644016691.\n",
      "State WHADVP^g. Merging pair (0,1) at cost 3.6253664242349806.\n",
      "State WRB. Merging pair (0,1) at cost 6.209082293795642.\n",
      "State $. Merging pair (0,1) at cost 0.035925675304033476.\n",
      "State PRT^g. Merging pair (0,1) at cost 13.78836329096323.\n",
      "State RP. Merging pair (0,1) at cost 13.380631595875352.\n",
      "State NX^g. Merging pair (0,1) at cost 5.915970623163652. Merging pair (2,3) at cost 9.293875480157073.\n",
      "State @FRAG^g. Merging pair (0,1) at cost 12.028472597961695.\n",
      "State WHPP^g. Merging pair (0,1) at cost 4.185273662415587.\n",
      "State SQ^g. Merging pair (0,1) at cost 5.004024235381878.\n",
      "State @SQ^g. Merging pair (0,1) at cost 9.360323492301406.\n",
      "State @NX^g.\n",
      "State SBARQ^g. Merging pair (0,1) at cost 1.9095425048844388.\n",
      "State @SBARQ^g.\n",
      "State FW. Merging pair (0,1) at cost 1.3170728571011052.\n",
      "State EX. Merging pair (0,1) at cost 1.7763568394002503E-15.\n",
      "State CONJP^g. Merging pair (0,1) at cost 4.796311581193066.\n",
      "State WHADJP^g. Merging pair (0,1) at cost 0.8630462155202099.\n",
      "State #.\n",
      "State @CONJP^g. Merging pair (0,1) at cost 2.2204460492503128E-16. Merging pair (2,3) at cost 2.2204460492503128E-16.\n",
      "State @WHADJP^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State INTJ^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State WP$. Merging pair (0,1) at cost -5.551115123125783E-16.\n",
      "State X^g.\n",
      "State UH.\n",
      "\n",
      "State TOP had 1 substates and now has 1.\n",
      "State S^g had 4 substates and now has 3.\n",
      "State @S^g had 4 substates and now has 4.\n",
      "State PP^g had 4 substates and now has 4.\n",
      "State IN had 4 substates and now has 4.\n",
      "State NP^g had 4 substates and now has 4.\n",
      "State @NP^g had 4 substates and now has 4.\n",
      "State DT had 4 substates and now has 4.\n",
      "State NNP had 4 substates and now has 4.\n",
      "State CD had 4 substates and now has 4.\n",
      "State NN had 4 substates and now has 4.\n",
      "State `` had 2 substates and now has 1.\n",
      "State '' had 2 substates and now has 1.\n",
      "State POS had 2 substates and now has 1.\n",
      "State PRN^g had 4 substates and now has 2.\n",
      "State @PRN^g had 4 substates and now has 4.\n",
      "State -LRB- had 2 substates and now has 1.\n",
      "State JJ had 4 substates and now has 4.\n",
      "State NNS had 4 substates and now has 3.\n",
      "State VP^g had 4 substates and now has 4.\n",
      "State @VP^g had 4 substates and now has 4.\n",
      "State VBP had 4 substates and now has 3.\n",
      "State , had 2 substates and now has 1.\n",
      "State CC had 4 substates and now has 4.\n",
      "State -RRB- had 2 substates and now has 1.\n",
      "State VBN had 4 substates and now has 3.\n",
      "State VBD had 4 substates and now has 3.\n",
      "State ADVP^g had 4 substates and now has 4.\n",
      "State RB had 4 substates and now has 4.\n",
      "State TO had 2 substates and now has 1.\n",
      "State . had 4 substates and now has 2.\n",
      "State VBZ had 4 substates and now has 4.\n",
      "State NNPS had 2 substates and now has 1.\n",
      "State SBAR^g had 4 substates and now has 4.\n",
      "State PRP had 2 substates and now has 1.\n",
      "State PRP$ had 4 substates and now has 3.\n",
      "State VB had 4 substates and now has 3.\n",
      "State ADJP^g had 4 substates and now has 4.\n",
      "State QP^g had 4 substates and now has 3.\n",
      "State @PP^g had 4 substates and now has 4.\n",
      "State MD had 4 substates and now has 2.\n",
      "State UCP^g had 2 substates and now has 1.\n",
      "State @UCP^g had 4 substates and now has 2.\n",
      "State VBG had 2 substates and now has 1.\n",
      "State @SBAR^g had 4 substates and now has 3.\n",
      "State WHNP^g had 2 substates and now has 2.\n",
      "State @ADVP^g had 2 substates and now has 2.\n",
      "State RBR had 4 substates and now has 2.\n",
      "State : had 4 substates and now has 3.\n",
      "State SINV^g had 4 substates and now has 2.\n",
      "State @SINV^g had 4 substates and now has 4.\n",
      "State WP had 2 substates and now has 2.\n",
      "State WDT had 2 substates and now has 1.\n",
      "State JJR had 4 substates and now has 2.\n",
      "State PDT had 2 substates and now has 1.\n",
      "State RBS had 2 substates and now has 1.\n",
      "State @QP^g had 4 substates and now has 4.\n",
      "State @ADJP^g had 4 substates and now has 4.\n",
      "State JJS had 2 substates and now has 1.\n",
      "State FRAG^g had 2 substates and now has 2.\n",
      "State NAC^g had 2 substates and now has 1.\n",
      "State @NAC^g had 2 substates and now has 1.\n",
      "State WHADVP^g had 2 substates and now has 1.\n",
      "State WRB had 2 substates and now has 1.\n",
      "State $ had 2 substates and now has 1.\n",
      "State PRT^g had 2 substates and now has 1.\n",
      "State RP had 2 substates and now has 1.\n",
      "State NX^g had 4 substates and now has 2.\n",
      "State @FRAG^g had 2 substates and now has 1.\n",
      "State WHPP^g had 2 substates and now has 1.\n",
      "State SQ^g had 2 substates and now has 1.\n",
      "State @SQ^g had 2 substates and now has 1.\n",
      "State @NX^g had 2 substates and now has 2.\n",
      "State SBARQ^g had 2 substates and now has 1.\n",
      "State @SBARQ^g had 2 substates and now has 2.\n",
      "State FW had 2 substates and now has 1.\n",
      "State EX had 2 substates and now has 1.\n",
      "State CONJP^g had 2 substates and now has 1.\n",
      "State WHADJP^g had 2 substates and now has 1.\n",
      "State # had 4 substates and now has 4.\n",
      "State @CONJP^g had 4 substates and now has 2.\n",
      "State @WHADJP^g had 2 substates and now has 1.\n",
      "State INTJ^g had 2 substates and now has 1.\n",
      "State WP$ had 2 substates and now has 1.\n",
      "State X^g had 2 substates and now has 2.\n",
      "State UH had 2 substates and now has 2.\n",
      "Lexicon: [IN : 4, DT : 4, CD : 4, RB : 4, NN : 4, JJ : 4, # : 4, VBZ : 4, NNP : 4, CC : 4, VBN : 3, VBD : 3, NNS : 3, VBP : 3, PRP$ : 3, VB : 3, : : 3, JJR : 2, UH : 2, . : 2, MD : 2, RBR : 2, WP : 2, EX : 1, FW : 1, TO : 1, -LRB- : 1, WP$ : 1, $ : 1, `` : 1, WRB : 1, -RRB- : 1, WDT : 1, RP : 1, PDT : 1, POS : 1, RBS : 1, PRP : 1, '' : 1, , : 1, VBG : 1, NNPS : 1, JJS : 1]\n",
      "Grammar: [@S^g : 4, PP^g : 4, @PRN^g : 4, VP^g : 4, NP^g : 4, @VP^g : 4, ADVP^g : 4, @SINV^g : 4, @QP^g : 4, @NP^g : 4, SBAR^g : 4, @ADJP^g : 4, ADJP^g : 4, @PP^g : 4, @SBAR^g : 3, S^g : 3, QP^g : 3, @UCP^g : 2, @NX^g : 2, X^g : 2, @SBARQ^g : 2, WHNP^g : 2, @ADVP^g : 2, @CONJP^g : 2, SINV^g : 2, FRAG^g : 2, PRN^g : 2, NX^g : 2, UCP^g : 1, NAC^g : 1, PRT^g : 1, @SQ^g : 1, @FRAG^g : 1, CONJP^g : 1, @WHADJP^g : 1, SQ^g : 1, WHPP^g : 1, @NAC^g : 1, WHADVP^g : 1, WHADJP^g : 1, TOP : 1, SBARQ^g : 1, INTJ^g : 1]\n",
      "After merging in the 2th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148999.058660242\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148979.83160826308\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148962.62647767316\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148946.11559492367\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148930.03867756668\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148913.7913637735\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148897.20099684343\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148880.5721458556\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148863.49249123325\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148846.59764178641\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148830.74568160562\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148816.20929804718\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148803.14242396923\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148790.5313812152\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148778.08081085057\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148765.4209869386\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148752.55221374074\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148740.65236426468\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148729.27447928727\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148717.65347707903\n",
      "Saving grammar to ptb.gr_2_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 2th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149613.6659367941\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149811.19508107106\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149847.73992307784\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149857.3381854202\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149856.16809446792\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149850.19733222979\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149841.15094686777\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149829.333176\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149818.67100048144\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -149809.80450372546\n",
      "Saving grammar to ptb.gr_2_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 195 substates.\n",
      "After splitting, we have a total of 389 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 3th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148951.30377469788\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148738.94206645974\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148675.39358234606\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148634.10105731286\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148604.28874015444\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148581.12724164833\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148561.51649594464\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148540.22217994402\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148502.21187784575\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148414.3021302043\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -148239.98526893032\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -147967.73687681957\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -147597.32564879177\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -147097.13913105184\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -146463.92052985737\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -145886.4120957283\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -145452.3172013055\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -145079.73921565322\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -144750.94649294787\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -144465.01961950547\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -144217.748098711\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -144010.9946688207\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143835.26175644057\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143686.00090063972\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143559.79233208462\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143444.1586629349\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143332.7912133146\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143224.85798849448\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143120.36927517978\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143019.39370403535\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142922.11428893995\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142830.61341562562\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142745.52715952435\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142666.4670567828\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142593.88842030568\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142527.10230730084\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142465.26647578477\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142407.4245676454\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142351.5466911442\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142296.64735250274\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142244.3102869459\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142195.21984623093\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142147.77020573092\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142101.1181661284\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142056.622393217\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142015.8522985167\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141978.6984820475\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141943.58645186038\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141909.5444341491\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141877.87798632003\n",
      "Saving grammar to ptb.gr_3_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -142329.9784322319\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 8.868760207653029.\n",
      "Merging 94 siblings and 0 other pairs.\n",
      "State TOP.\n",
      "State S^g. Merging pair (0,1) at cost 0.7454625733175844.\n",
      "State @S^g.\n",
      "State PP^g.\n",
      "State IN.\n",
      "State NP^g.\n",
      "State @NP^g.\n",
      "State DT. Merging pair (0,1) at cost 3.2499203254376847.\n",
      "State NNP. Merging pair (0,1) at cost 7.557612415145483. Merging pair (2,3) at cost 2.343749837518759E-4.\n",
      "State CD. Merging pair (0,1) at cost 3.3018811233661124E-10. Merging pair (2,3) at cost 0.28387847650668224.\n",
      "State NN. Merging pair (4,5) at cost 0.9986486628354792. Merging pair (6,7) at cost 5.890114205436979.\n",
      "State ``. Merging pair (0,1) at cost -7.105427357601002E-15.\n",
      "State ''. Merging pair (0,1) at cost -3.808064974464287E-14.\n",
      "State POS.\n",
      "State PRN^g. Merging pair (0,1) at cost 7.221921628448045.\n",
      "State @PRN^g. Merging pair (0,1) at cost 1.231445950677334. Merging pair (2,3) at cost 6.7480217354256995.\n",
      "State -LRB-.\n",
      "State JJ. Merging pair (0,1) at cost -8.881784197001252E-16. Merging pair (2,3) at cost 1.5309975509574767E-13. Merging pair (4,5) at cost 1.3966050538260854E-11.\n",
      "State NNS. Merging pair (0,1) at cost 6.227867097211989. Merging pair (2,3) at cost 1.3129488267090923.\n",
      "State VP^g.\n",
      "State @VP^g.\n",
      "State VBP. Merging pair (2,3) at cost 1.0661780110036795E-8. Merging pair (4,5) at cost 6.317169010117066E-14.\n",
      "State ,. Merging pair (0,1) at cost 1.924016501675396E-13.\n",
      "State CC. Merging pair (4,5) at cost 0.016223262998502432. Merging pair (6,7) at cost 6.823581089739111.\n",
      "State -RRB-. Merging pair (0,1) at cost 0.018678776414586963.\n",
      "State VBN. Merging pair (0,1) at cost 3.818980592048935. Merging pair (2,3) at cost 3.5527136788005005E-15. Merging pair (4,5) at cost 1.6502355038011832E-12.\n",
      "State VBD. Merging pair (2,3) at cost 3.277022367403361E-8. Merging pair (4,5) at cost 2.3187584295710395E-4.\n",
      "State ADVP^g. Merging pair (2,3) at cost 6.482862226016595.\n",
      "State RB.\n",
      "State TO. Merging pair (0,1) at cost 1.6309348721945305.\n",
      "State .. Merging pair (0,1) at cost 3.5527136788004946E-15. Merging pair (2,3) at cost 7.871481244592359E-14.\n",
      "State VBZ. Merging pair (0,1) at cost 0.0020349306915968196. Merging pair (2,3) at cost 5.561662241852753E-12. Merging pair (4,5) at cost 0.007684630049087195.\n",
      "State NNPS. Merging pair (0,1) at cost 3.4416913763379845E-15.\n",
      "State SBAR^g. Merging pair (6,7) at cost 1.0198933320822998.\n",
      "State PRP.\n",
      "State PRP$. Merging pair (2,3) at cost 8.575027803532734E-7. Merging pair (4,5) at cost 0.12291247423923997.\n",
      "State VB. Merging pair (0,1) at cost 6.967117361496977. Merging pair (2,3) at cost 0.0010644021103734186.\n",
      "State ADJP^g.\n",
      "State QP^g.\n",
      "State @PP^g. Merging pair (0,1) at cost 3.933313610537716. Merging pair (6,7) at cost 8.868760207653029.\n",
      "State MD. Merging pair (0,1) at cost 4.052389919009657. Merging pair (2,3) at cost 7.019218931090973.\n",
      "State UCP^g.\n",
      "State @UCP^g.\n",
      "State VBG. Merging pair (0,1) at cost 1.0214051826551439E-14.\n",
      "State @SBAR^g. Merging pair (0,1) at cost 6.182654189375909. Merging pair (4,5) at cost 6.154667420542587.\n",
      "State WHNP^g. Merging pair (2,3) at cost 0.3743541519990738.\n",
      "State @ADVP^g. Merging pair (0,1) at cost 6.108643020548935. Merging pair (2,3) at cost 8.150319191898307.\n",
      "State RBR. Merging pair (0,1) at cost 3.497202527568954E-14. Merging pair (2,3) at cost 1.1102230246251563E-15.\n",
      "State :. Merging pair (0,1) at cost 6.835950359813455. Merging pair (2,3) at cost 3.996802888650563E-15. Merging pair (4,5) at cost 1.6653345369377346E-15.\n",
      "State SINV^g. Merging pair (0,1) at cost 7.638170019113075. Merging pair (2,3) at cost -5.551115123179993E-16.\n",
      "State @SINV^g.\n",
      "State WP. Merging pair (0,1) at cost 2.4424906541752522E-14. Merging pair (2,3) at cost 4.551914400963141E-15.\n",
      "State WDT. Merging pair (0,1) at cost 4.4256300546014736E-5.\n",
      "State JJR. Merging pair (0,1) at cost 5.884182030512969E-14. Merging pair (2,3) at cost 5.440092820663266E-15.\n",
      "State PDT. Merging pair (0,1) at cost 7.207608887069033.\n",
      "State RBS. Merging pair (0,1) at cost 7.771561172376095E-16.\n",
      "State @QP^g. Merging pair (6,7) at cost 8.688848123578278.\n",
      "State @ADJP^g. Merging pair (0,1) at cost 4.1588830833596715. Merging pair (2,3) at cost 8.762756503716256. Merging pair (4,5) at cost 7.651160963586678. Merging pair (6,7) at cost 6.108643020548926.\n",
      "State JJS. Merging pair (0,1) at cost -4.6629367034256575E-15.\n",
      "State FRAG^g. Merging pair (2,3) at cost 6.931471805599453.\n",
      "State NAC^g. Merging pair (0,1) at cost 6.674260672659951.\n",
      "State @NAC^g.\n",
      "State WHADVP^g. Merging pair (0,1) at cost 4.336464418205948.\n",
      "State WRB. Merging pair (0,1) at cost 7.901605995292247.\n",
      "State $. Merging pair (0,1) at cost 0.0011335099503456912.\n",
      "State PRT^g.\n",
      "State RP.\n",
      "State NX^g. Merging pair (0,1) at cost 7.506036352923728.\n",
      "State @FRAG^g.\n",
      "State WHPP^g. Merging pair (0,1) at cost 4.30865749559718.\n",
      "State SQ^g. Merging pair (0,1) at cost 6.108643020548935.\n",
      "State @SQ^g.\n",
      "State @NX^g. Merging pair (2,3) at cost 7.579101623243243.\n",
      "State SBARQ^g. Merging pair (0,1) at cost 1.909542504884439.\n",
      "State @SBARQ^g.\n",
      "State FW. Merging pair (0,1) at cost 1.3170728565205572.\n",
      "State EX. Merging pair (0,1) at cost -1.7763568394002505E-15.\n",
      "State CONJP^g. Merging pair (0,1) at cost 4.767339482209557.\n",
      "State WHADJP^g. Merging pair (0,1) at cost 1.5718034316445024.\n",
      "State #. Merging pair (2,3) at cost -1.1102230246251565E-16. Merging pair (4,5) at cost -1.1102230246251565E-16.\n",
      "State @CONJP^g. Merging pair (0,1) at cost -4.314018032002692E-10. Merging pair (2,3) at cost -6.7769221422314796E-9.\n",
      "State @WHADJP^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State INTJ^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State WP$. Merging pair (0,1) at cost 8.881784197001251E-16.\n",
      "State X^g.\n",
      "State UH. Merging pair (2,3) at cost 2.2204460492503128E-16.\n",
      "\n",
      "State TOP had 1 substates and now has 1.\n",
      "State S^g had 6 substates and now has 5.\n",
      "State @S^g had 8 substates and now has 8.\n",
      "State PP^g had 8 substates and now has 8.\n",
      "State IN had 8 substates and now has 8.\n",
      "State NP^g had 8 substates and now has 8.\n",
      "State @NP^g had 8 substates and now has 8.\n",
      "State DT had 8 substates and now has 7.\n",
      "State NNP had 8 substates and now has 6.\n",
      "State CD had 8 substates and now has 6.\n",
      "State NN had 8 substates and now has 6.\n",
      "State `` had 2 substates and now has 1.\n",
      "State '' had 2 substates and now has 1.\n",
      "State POS had 2 substates and now has 2.\n",
      "State PRN^g had 4 substates and now has 3.\n",
      "State @PRN^g had 8 substates and now has 6.\n",
      "State -LRB- had 2 substates and now has 2.\n",
      "State JJ had 8 substates and now has 5.\n",
      "State NNS had 6 substates and now has 4.\n",
      "State VP^g had 8 substates and now has 8.\n",
      "State @VP^g had 8 substates and now has 8.\n",
      "State VBP had 6 substates and now has 4.\n",
      "State , had 2 substates and now has 1.\n",
      "State CC had 8 substates and now has 6.\n",
      "State -RRB- had 2 substates and now has 1.\n",
      "State VBN had 6 substates and now has 3.\n",
      "State VBD had 6 substates and now has 4.\n",
      "State ADVP^g had 8 substates and now has 7.\n",
      "State RB had 8 substates and now has 8.\n",
      "State TO had 2 substates and now has 1.\n",
      "State . had 4 substates and now has 2.\n",
      "State VBZ had 8 substates and now has 5.\n",
      "State NNPS had 2 substates and now has 1.\n",
      "State SBAR^g had 8 substates and now has 7.\n",
      "State PRP had 2 substates and now has 2.\n",
      "State PRP$ had 6 substates and now has 4.\n",
      "State VB had 6 substates and now has 4.\n",
      "State ADJP^g had 8 substates and now has 8.\n",
      "State QP^g had 6 substates and now has 6.\n",
      "State @PP^g had 8 substates and now has 6.\n",
      "State MD had 4 substates and now has 2.\n",
      "State UCP^g had 2 substates and now has 2.\n",
      "State @UCP^g had 4 substates and now has 4.\n",
      "State VBG had 2 substates and now has 1.\n",
      "State @SBAR^g had 6 substates and now has 4.\n",
      "State WHNP^g had 4 substates and now has 3.\n",
      "State @ADVP^g had 4 substates and now has 2.\n",
      "State RBR had 4 substates and now has 2.\n",
      "State : had 6 substates and now has 3.\n",
      "State SINV^g had 4 substates and now has 2.\n",
      "State @SINV^g had 8 substates and now has 8.\n",
      "State WP had 4 substates and now has 2.\n",
      "State WDT had 2 substates and now has 1.\n",
      "State JJR had 4 substates and now has 2.\n",
      "State PDT had 2 substates and now has 1.\n",
      "State RBS had 2 substates and now has 1.\n",
      "State @QP^g had 8 substates and now has 7.\n",
      "State @ADJP^g had 8 substates and now has 4.\n",
      "State JJS had 2 substates and now has 1.\n",
      "State FRAG^g had 4 substates and now has 3.\n",
      "State NAC^g had 2 substates and now has 1.\n",
      "State @NAC^g had 2 substates and now has 2.\n",
      "State WHADVP^g had 2 substates and now has 1.\n",
      "State WRB had 2 substates and now has 1.\n",
      "State $ had 2 substates and now has 1.\n",
      "State PRT^g had 2 substates and now has 2.\n",
      "State RP had 2 substates and now has 2.\n",
      "State NX^g had 4 substates and now has 3.\n",
      "State @FRAG^g had 2 substates and now has 2.\n",
      "State WHPP^g had 2 substates and now has 1.\n",
      "State SQ^g had 2 substates and now has 1.\n",
      "State @SQ^g had 2 substates and now has 2.\n",
      "State @NX^g had 4 substates and now has 3.\n",
      "State SBARQ^g had 2 substates and now has 1.\n",
      "State @SBARQ^g had 4 substates and now has 4.\n",
      "State FW had 2 substates and now has 1.\n",
      "State EX had 2 substates and now has 1.\n",
      "State CONJP^g had 2 substates and now has 1.\n",
      "State WHADJP^g had 2 substates and now has 1.\n",
      "State # had 8 substates and now has 6.\n",
      "State @CONJP^g had 4 substates and now has 2.\n",
      "State @WHADJP^g had 2 substates and now has 1.\n",
      "State INTJ^g had 2 substates and now has 1.\n",
      "State WP$ had 2 substates and now has 1.\n",
      "State X^g had 4 substates and now has 4.\n",
      "State UH had 4 substates and now has 3.\n",
      "Lexicon: [IN : 8, RB : 8, DT : 7, CD : 6, NN : 6, # : 6, NNP : 6, CC : 6, JJ : 5, VBZ : 5, VBD : 4, NNS : 4, VBP : 4, PRP$ : 4, VB : 4, VBN : 3, UH : 3, : : 3, POS : 2, JJR : 2, -LRB- : 2, RP : 2, . : 2, PRP : 2, MD : 2, RBR : 2, WP : 2, WP$ : 1, TO : 1, FW : 1, -RRB- : 1, WDT : 1, JJS : 1, WRB : 1, RBS : 1, $ : 1, '' : 1, , : 1, VBG : 1, NNPS : 1, `` : 1, PDT : 1, EX : 1]\n",
      "Grammar: [@S^g : 8, PP^g : 8, VP^g : 8, NP^g : 8, @VP^g : 8, @SINV^g : 8, @NP^g : 8, ADJP^g : 8, ADVP^g : 7, @QP^g : 7, SBAR^g : 7, @PRN^g : 6, QP^g : 6, @PP^g : 6, S^g : 5, @UCP^g : 4, @SBAR^g : 4, @SBARQ^g : 4, X^g : 4, @ADJP^g : 4, @NX^g : 3, WHNP^g : 3, FRAG^g : 3, PRN^g : 3, NX^g : 3, SINV^g : 2, UCP^g : 2, @ADVP^g : 2, @CONJP^g : 2, @FRAG^g : 2, @SQ^g : 2, @NAC^g : 2, PRT^g : 2, SQ^g : 1, CONJP^g : 1, NAC^g : 1, WHADJP^g : 1, @WHADJP^g : 1, INTJ^g : 1, WHADVP^g : 1, WHPP^g : 1, SBARQ^g : 1, TOP : 1]\n",
      "After merging in the 3th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142110.32469382038\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142083.98855798482\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142061.51782517644\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142041.0264914349\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142022.0026088464\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142003.93213219967\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141985.53827628063\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141967.3214326784\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141950.7373965482\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141934.60502737897\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141917.86224113507\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141900.23903389473\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141882.08213415273\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141863.56653237005\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141844.79055609202\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141826.05456970196\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141807.52934841797\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141789.24866884205\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141772.0498646148\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141756.01804563522\n",
      "Saving grammar to ptb.gr_3_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 3th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142775.61147574728\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142999.68863738087\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143040.60579091983\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143050.77851895566\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143049.52052852057\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143043.04890006298\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143033.07815364163\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143020.82297401497\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -143007.50573794113\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142994.1524855992\n",
      "Saving grammar to ptb.gr_3_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 295 substates.\n",
      "After splitting, we have a total of 589 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 4th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -142030.77452097114\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141779.27497980755\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141700.4335240759\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141651.56108479667\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141616.85061529305\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141590.69688687884\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141568.66624857957\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141546.5325640035\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141514.5657920056\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141450.51072676483\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141334.4308408056\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -141161.27335650928\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140921.54252476856\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140611.61360891888\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -140256.5720469634\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139900.575076127\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139577.03541715068\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139292.04884593654\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -139036.87478774038\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138800.67718300017\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138576.37968686997\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138363.3306566447\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -138160.21498404164\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137965.55175087377\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137779.59720764536\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137601.5322941203\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137431.1478968626\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137269.5846384173\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -137116.8020101512\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136975.51482333368\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136845.73042552985\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136728.0444354803\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136622.7120780243\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136524.9462388056\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136432.34977399206\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136347.7005848893\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136270.61894048564\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136199.04161128483\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136132.84395536943\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136071.13725538304\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136013.17675480482\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135958.40984675247\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135905.76767732558\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135856.7319592687\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135809.73413553069\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135765.9315869108\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135725.38791323785\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135687.02430699798\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135648.97106680792\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135611.1264173291\n",
      "Saving grammar to ptb.gr_4_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -136063.34731820787\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 4.780356732903302.\n",
      "Merging 143 siblings and 0 other pairs.\n",
      "State TOP.\n",
      "State S^g. Merging pair (0,1) at cost 0.7412374474891654.\n",
      "State @S^g. Merging pair (14,15) at cost 2.69761273768693.\n",
      "State PP^g.\n",
      "State IN. Merging pair (2,3) at cost 0.03176332046343206.\n",
      "State NP^g.\n",
      "State @NP^g.\n",
      "State DT. Merging pair (4,5) at cost 0.30889451142712016. Merging pair (6,7) at cost 3.1583057248312493E-9. Merging pair (8,9) at cost 2.6679769504745722E-12.\n",
      "State NNP. Merging pair (2,3) at cost 8.88951123763747E-4. Merging pair (6,7) at cost 3.072203246677643. Merging pair (8,9) at cost 0.31020690850398286.\n",
      "State CD. Merging pair (0,1) at cost 1.9909869016337067E-10. Merging pair (2,3) at cost 1.7053648710570848. Merging pair (4,5) at cost 5.2402526762299323E-14. Merging pair (6,7) at cost -1.1102230246251568E-16. Merging pair (8,9) at cost 3.6437519668193407E-13. Merging pair (10,11) at cost 2.5950265920740763.\n",
      "State NN. Merging pair (8,9) at cost 2.782318817379596E-9.\n",
      "State ``. Merging pair (0,1) at cost 1.4654943925052063E-14.\n",
      "State ''. Merging pair (0,1) at cost -1.8540724511240114E-14.\n",
      "State POS. Merging pair (0,1) at cost -9.547918011776346E-15. Merging pair (2,3) at cost 0.0016866983862465297.\n",
      "State PRN^g. Merging pair (2,3) at cost 4.6986953848254505. Merging pair (4,5) at cost 1.1102230246251563E-15.\n",
      "State @PRN^g. Merging pair (0,1) at cost -4.437542127598428E-11. Merging pair (6,7) at cost 8.451310689421927E-5. Merging pair (8,9) at cost 2.2493405784752336. Merging pair (10,11) at cost 3.525461849543973.\n",
      "State -LRB-. Merging pair (0,1) at cost -3.3306690738754696E-16. Merging pair (2,3) at cost 1.6875389974301985E-14.\n",
      "State JJ. Merging pair (0,1) at cost -4.440892098500626E-16. Merging pair (2,3) at cost -2.7755575615628914E-15. Merging pair (4,5) at cost 6.4304117586255665E-12.\n",
      "State NNS. Merging pair (2,3) at cost 0.5269284078387578. Merging pair (6,7) at cost 1.7584864022884277.\n",
      "State VP^g.\n",
      "State @VP^g.\n",
      "State VBP. Merging pair (0,1) at cost 1.3376055923466565. Merging pair (2,3) at cost 5.062616992289877E-14. Merging pair (4,5) at cost 2.9838798098537504E-11. Merging pair (6,7) at cost 2.109423746787797E-15.\n",
      "State ,. Merging pair (0,1) at cost 1.008082506359642E-13.\n",
      "State CC. Merging pair (0,1) at cost -1.887379141862766E-15. Merging pair (2,3) at cost 6.88338275267597E-15. Merging pair (4,5) at cost -1.4791141972893971E-31. Merging pair (6,7) at cost 8.537615059366992E-14. Merging pair (8,9) at cost 0.03910714102304846.\n",
      "State -RRB-. Merging pair (0,1) at cost 0.08645812173328092.\n",
      "State VBN. Merging pair (0,1) at cost 3.8190252077155273. Merging pair (2,3) at cost -6.661338147750939E-16. Merging pair (4,5) at cost 1.247890679678495E-13.\n",
      "State VBD. Merging pair (2,3) at cost 4.545575027233297E-11. Merging pair (4,5) at cost 1.6797674362575943E-13. Merging pair (6,7) at cost 1.231914324817422E-4.\n",
      "State ADVP^g.\n",
      "State RB. Merging pair (0,1) at cost 5.551115123125782E-15. Merging pair (2,3) at cost 9.65894031423886E-15. Merging pair (6,7) at cost 8.881784197001251E-16. Merging pair (12,13) at cost 6.151590667501737E-4. Merging pair (14,15) at cost 1.9036941642144771.\n",
      "State TO. Merging pair (0,1) at cost 1.892718886599042.\n",
      "State .. Merging pair (0,1) at cost 3.1086244689504182E-15. Merging pair (2,3) at cost 7.405187574249793E-14.\n",
      "State VBZ. Merging pair (0,1) at cost 3.0924321862305176E-8. Merging pair (2,3) at cost 1.4666046155298015E-13. Merging pair (4,5) at cost 0.20682266507785999. Merging pair (6,7) at cost -6.772360450213455E-15. Merging pair (8,9) at cost -4.9960036108132044E-15.\n",
      "State NNPS. Merging pair (0,1) at cost -4.773959005888173E-15.\n",
      "State SBAR^g. Merging pair (12,13) at cost 1.0722640943473907.\n",
      "State PRP. Merging pair (0,1) at cost 0.4681794174085495. Merging pair (2,3) at cost 0.3497118092440993.\n",
      "State PRP$. Merging pair (0,1) at cost 5.7557625330078305E-11. Merging pair (2,3) at cost 7.475808858969988E-11. Merging pair (4,5) at cost 3.592504071680255E-11. Merging pair (6,7) at cost 1.5039898052273742E-6.\n",
      "State VB. Merging pair (2,3) at cost -1.176836406102666E-14. Merging pair (4,5) at cost 2.7656453273515003. Merging pair (6,7) at cost 2.4834910386844204.\n",
      "State ADJP^g.\n",
      "State QP^g. Merging pair (0,1) at cost 1.9038660896854414E-5. Merging pair (10,11) at cost 3.8190850097688767.\n",
      "State @PP^g. Merging pair (0,1) at cost 3.933313610665011. Merging pair (2,3) at cost 4.780356732903302.\n",
      "State MD.\n",
      "State UCP^g. Merging pair (0,1) at cost 2.249340578475233.\n",
      "State @UCP^g. Merging pair (0,1) at cost 3.365058335046282. Merging pair (4,5) at cost 4.498680903263567. Merging pair (6,7) at cost 4.158883083359672.\n",
      "State VBG. Merging pair (0,1) at cost -3.5083047578154947E-14.\n",
      "State @SBAR^g. Merging pair (2,3) at cost 3.8175340838173577. Merging pair (4,5) at cost 4.460853346328351. Merging pair (6,7) at cost 4.767355791518893.\n",
      "State WHNP^g. Merging pair (0,1) at cost 1.6566253484771063. Merging pair (2,3) at cost 3.479437946152865. Merging pair (4,5) at cost 0.2313248335159821.\n",
      "State @ADVP^g.\n",
      "State RBR. Merging pair (0,1) at cost 6.661338147750938E-16. Merging pair (2,3) at cost 1.8873791418627657E-15.\n",
      "State :. Merging pair (2,3) at cost 4.440892098500625E-16. Merging pair (4,5) at cost -2.220446049250313E-15.\n",
      "State SINV^g. Merging pair (2,3) at cost -5.90742639781278E-9.\n",
      "State @SINV^g. Merging pair (0,1) at cost 4.1072615791965426. Merging pair (4,5) at cost -6.769542888920344E-8. Merging pair (6,7) at cost 2.8708142280188635. Merging pair (10,11) at cost 1.2883248906444902E-5. Merging pair (12,13) at cost 1.909542504884439. Merging pair (14,15) at cost 0.2423706905210303.\n",
      "State WP. Merging pair (0,1) at cost -3.1086244689504383E-15. Merging pair (2,3) at cost -3.3306690738754706E-16.\n",
      "State WDT. Merging pair (0,1) at cost 1.7851998754071627E-9.\n",
      "State JJR. Merging pair (0,1) at cost 2.5535129566378005E-15. Merging pair (2,3) at cost -2.9976021664879227E-15.\n",
      "State PDT.\n",
      "State RBS. Merging pair (0,1) at cost -1.1102230246251568E-16.\n",
      "State @QP^g. Merging pair (0,1) at cost 1.9274441984034374. Merging pair (2,3) at cost 2.5254484488334343. Merging pair (4,5) at cost 4.780356732903301. Merging pair (8,9) at cost 0.00737286579826935. Merging pair (10,11) at cost 2.3447459518311328E-9.\n",
      "State @ADJP^g. Merging pair (0,1) at cost 3.8190850097688775.\n",
      "State JJS. Merging pair (0,1) at cost 6.661338147750937E-16.\n",
      "State FRAG^g. Merging pair (0,1) at cost -1.171160375019181E-10. Merging pair (2,3) at cost 2.249340578475233.\n",
      "State NAC^g.\n",
      "State @NAC^g. Merging pair (0,1) at cost 4.498681156950466. Merging pair (2,3) at cost 2.870814228018863.\n",
      "State WHADVP^g.\n",
      "State WRB.\n",
      "State $. Merging pair (0,1) at cost 0.05126548482283485.\n",
      "State PRT^g. Merging pair (0,1) at cost 4.767355762324094.\n",
      "State RP. Merging pair (0,1) at cost 1.560793165948052. Merging pair (2,3) at cost 3.0248736604349267.\n",
      "State NX^g. Merging pair (2,3) at cost 1.0464962875282782.\n",
      "State @FRAG^g. Merging pair (2,3) at cost 4.780356732903301.\n",
      "State WHPP^g. Merging pair (0,1) at cost 4.539684170968365.\n",
      "State SQ^g.\n",
      "State @SQ^g. Merging pair (2,3) at cost 3.8190850097688767.\n",
      "State @NX^g. Merging pair (0,1) at cost 4.1588830833596715. Merging pair (2,3) at cost -1.6353981788184777E-11.\n",
      "State SBARQ^g. Merging pair (0,1) at cost 1.9095425048844386.\n",
      "State @SBARQ^g. Merging pair (0,1) at cost -9.846568005402937E-13. Merging pair (2,3) at cost -1.71307412699669E-13. Merging pair (4,5) at cost -4.884981308350695E-15. Merging pair (6,7) at cost -5.2402526762308077E-14.\n",
      "State FW. Merging pair (0,1) at cost 1.3170728570922638.\n",
      "State EX. Merging pair (0,1) at cost 8.881784197001251E-16.\n",
      "State CONJP^g.\n",
      "State WHADJP^g. Merging pair (0,1) at cost 2.211905640606556.\n",
      "State #. Merging pair (4,5) at cost -2.220446049250313E-16.\n",
      "State @CONJP^g. Merging pair (0,1) at cost -5.750955267558862E-13. Merging pair (2,3) at cost -6.252776074689533E-13.\n",
      "State @WHADJP^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State INTJ^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State WP$. Merging pair (0,1) at cost 4.4408920985006257E-16.\n",
      "State X^g. Merging pair (2,3) at cost -1.1102230246251565E-16. Merging pair (4,5) at cost 2.2204460492503128E-16.\n",
      "State UH.\n",
      "\n",
      "State TOP had 1 substates and now has 1.\n",
      "State S^g had 10 substates and now has 9.\n",
      "State @S^g had 16 substates and now has 15.\n",
      "State PP^g had 16 substates and now has 16.\n",
      "State IN had 16 substates and now has 15.\n",
      "State NP^g had 16 substates and now has 16.\n",
      "State @NP^g had 16 substates and now has 16.\n",
      "State DT had 14 substates and now has 11.\n",
      "State NNP had 12 substates and now has 9.\n",
      "State CD had 12 substates and now has 6.\n",
      "State NN had 12 substates and now has 11.\n",
      "State `` had 2 substates and now has 1.\n",
      "State '' had 2 substates and now has 1.\n",
      "State POS had 4 substates and now has 2.\n",
      "State PRN^g had 6 substates and now has 4.\n",
      "State @PRN^g had 12 substates and now has 8.\n",
      "State -LRB- had 4 substates and now has 2.\n",
      "State JJ had 10 substates and now has 7.\n",
      "State NNS had 8 substates and now has 6.\n",
      "State VP^g had 16 substates and now has 16.\n",
      "State @VP^g had 16 substates and now has 16.\n",
      "State VBP had 8 substates and now has 4.\n",
      "State , had 2 substates and now has 1.\n",
      "State CC had 12 substates and now has 7.\n",
      "State -RRB- had 2 substates and now has 1.\n",
      "State VBN had 6 substates and now has 3.\n",
      "State VBD had 8 substates and now has 5.\n",
      "State ADVP^g had 14 substates and now has 14.\n",
      "State RB had 16 substates and now has 11.\n",
      "State TO had 2 substates and now has 1.\n",
      "State . had 4 substates and now has 2.\n",
      "State VBZ had 10 substates and now has 5.\n",
      "State NNPS had 2 substates and now has 1.\n",
      "State SBAR^g had 14 substates and now has 13.\n",
      "State PRP had 4 substates and now has 2.\n",
      "State PRP$ had 8 substates and now has 4.\n",
      "State VB had 8 substates and now has 5.\n",
      "State ADJP^g had 16 substates and now has 16.\n",
      "State QP^g had 12 substates and now has 10.\n",
      "State @PP^g had 12 substates and now has 10.\n",
      "State MD had 4 substates and now has 4.\n",
      "State UCP^g had 4 substates and now has 3.\n",
      "State @UCP^g had 8 substates and now has 5.\n",
      "State VBG had 2 substates and now has 1.\n",
      "State @SBAR^g had 8 substates and now has 5.\n",
      "State WHNP^g had 6 substates and now has 3.\n",
      "State @ADVP^g had 4 substates and now has 4.\n",
      "State RBR had 4 substates and now has 2.\n",
      "State : had 6 substates and now has 4.\n",
      "State SINV^g had 4 substates and now has 3.\n",
      "State @SINV^g had 16 substates and now has 10.\n",
      "State WP had 4 substates and now has 2.\n",
      "State WDT had 2 substates and now has 1.\n",
      "State JJR had 4 substates and now has 2.\n",
      "State PDT had 2 substates and now has 2.\n",
      "State RBS had 2 substates and now has 1.\n",
      "State @QP^g had 14 substates and now has 9.\n",
      "State @ADJP^g had 8 substates and now has 7.\n",
      "State JJS had 2 substates and now has 1.\n",
      "State FRAG^g had 6 substates and now has 4.\n",
      "State NAC^g had 2 substates and now has 2.\n",
      "State @NAC^g had 4 substates and now has 2.\n",
      "State WHADVP^g had 2 substates and now has 2.\n",
      "State WRB had 2 substates and now has 2.\n",
      "State $ had 2 substates and now has 1.\n",
      "State PRT^g had 4 substates and now has 3.\n",
      "State RP had 4 substates and now has 2.\n",
      "State NX^g had 6 substates and now has 5.\n",
      "State @FRAG^g had 4 substates and now has 3.\n",
      "State WHPP^g had 2 substates and now has 1.\n",
      "State SQ^g had 2 substates and now has 2.\n",
      "State @SQ^g had 4 substates and now has 3.\n",
      "State @NX^g had 6 substates and now has 4.\n",
      "State SBARQ^g had 2 substates and now has 1.\n",
      "State @SBARQ^g had 8 substates and now has 4.\n",
      "State FW had 2 substates and now has 1.\n",
      "State EX had 2 substates and now has 1.\n",
      "State CONJP^g had 2 substates and now has 2.\n",
      "State WHADJP^g had 2 substates and now has 1.\n",
      "State # had 12 substates and now has 11.\n",
      "State @CONJP^g had 4 substates and now has 2.\n",
      "State @WHADJP^g had 2 substates and now has 1.\n",
      "State INTJ^g had 2 substates and now has 1.\n",
      "State WP$ had 2 substates and now has 1.\n",
      "State X^g had 8 substates and now has 6.\n",
      "State UH had 6 substates and now has 6.\n",
      "Lexicon: [IN : 15, DT : 11, RB : 11, NN : 11, # : 11, NNP : 9, JJ : 7, CC : 7, CD : 6, UH : 6, NNS : 6, VBD : 5, VBZ : 5, VB : 5, VBP : 4, PRP$ : 4, MD : 4, : : 4, VBN : 3, JJR : 2, PDT : 2, PRP : 2, POS : 2, -LRB- : 2, RP : 2, . : 2, WRB : 2, RBR : 2, WP : 2, VBG : 1, '' : 1, -RRB- : 1, WDT : 1, EX : 1, JJS : 1, NNPS : 1, $ : 1, TO : 1, FW : 1, `` : 1, WP$ : 1, , : 1, RBS : 1]\n",
      "Grammar: [PP^g : 16, NP^g : 16, VP^g : 16, @VP^g : 16, @NP^g : 16, ADJP^g : 16, @S^g : 15, ADVP^g : 14, SBAR^g : 13, @SINV^g : 10, QP^g : 10, @PP^g : 10, @QP^g : 9, S^g : 9, @PRN^g : 8, @ADJP^g : 7, X^g : 6, @UCP^g : 5, @SBAR^g : 5, NX^g : 5, @NX^g : 4, @SBARQ^g : 4, @ADVP^g : 4, FRAG^g : 4, PRN^g : 4, WHNP^g : 3, UCP^g : 3, SINV^g : 3, @FRAG^g : 3, PRT^g : 3, @SQ^g : 3, @NAC^g : 2, SQ^g : 2, NAC^g : 2, WHADVP^g : 2, CONJP^g : 2, @CONJP^g : 2, @WHADJP^g : 1, INTJ^g : 1, WHADJP^g : 1, TOP : 1, WHPP^g : 1, SBARQ^g : 1]\n",
      "After merging in the 4th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135761.71353274456\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135726.4812631362\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135694.76281391943\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135664.23304095407\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135636.20272641096\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135610.2196259586\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135585.27555977379\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135561.72653966382\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135538.53130980587\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135514.7789192399\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135492.9702316537\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135473.99794555674\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135457.0387608001\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135441.3980991029\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135426.55819045895\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135412.48185324468\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135399.67233370352\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135386.7014955974\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135372.53186754393\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135358.58111481008\n",
      "Saving grammar to ptb.gr_4_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 4th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136534.59271176372\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136790.9882886206\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136834.63441814185\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136850.4578172899\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136854.43348884286\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136851.86294963892\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136845.71080085135\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136837.5715610049\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136827.7932748055\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -136817.56768831267\n",
      "Saving grammar to ptb.gr_4_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 446 substates.\n",
      "After splitting, we have a total of 891 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 5th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135729.00164330026\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135424.7892624212\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135342.65182703515\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135295.6506989445\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135262.01413632787\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135235.09615065934\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135210.95072354245\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135184.35477378877\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135142.89695283162\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -135061.7908732749\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -134917.49950210078\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -134704.9554573968\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -134427.14343177876\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -134090.52866220527\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -133712.89291446874\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -133316.7467919889\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -132920.52613293024\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -132535.31776462425\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -132167.92593485318\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -131825.09297276373\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -131514.69643958932\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -131241.29658590042\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -131000.9423735969\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130786.62762572429\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130593.95966003099\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130420.34600911025\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130263.79549469099\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130122.05433451815\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129992.81457707348\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129873.90683711763\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129762.52930709413\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129657.00722361407\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129559.7213803319\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129469.25499887763\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129388.17760919326\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129313.9466078954\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129242.8616541312\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129173.58205816562\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129107.02511467521\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129044.31675418328\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128985.35118263541\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128930.43596382176\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128879.41787215335\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128830.28440317506\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128786.19875776468\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128745.94559633889\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128705.60688008764\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128664.17804559456\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128622.90446658822\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128581.34441380674\n",
      "Saving grammar to ptb.gr_5_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -129033.65091673969\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 3.4149097108985047.\n",
      "Merging 211 siblings and 0 other pairs.\n",
      "State TOP.\n",
      "State S^g. Merging pair (0,1) at cost 0.7333118673470209.\n",
      "State @S^g. Merging pair (24,25) at cost 0.0012958997708868414. Merging pair (28,29) at cost 3.4149097108985047.\n",
      "State PP^g.\n",
      "State IN. Merging pair (0,1) at cost 1.770139590461753E-12. Merging pair (2,3) at cost 0.4017588843883282. Merging pair (4,5) at cost 0.006968146233822158. Merging pair (14,15) at cost 4.773959005888172E-15. Merging pair (18,19) at cost 7.12868699207833E-7. Merging pair (24,25) at cost 1.6986412276764892E-14. Merging pair (28,29) at cost 2.1171976378735473.\n",
      "State NP^g.\n",
      "State @NP^g.\n",
      "State DT. Merging pair (0,1) at cost 0.006679060210361039. Merging pair (2,3) at cost 3.077529768622584E-7. Merging pair (4,5) at cost -2.742250871060436E-14. Merging pair (6,7) at cost 1.5654144647214502E-14. Merging pair (8,9) at cost 1.043269483216105E-6. Merging pair (10,11) at cost 7.294165271787277E-14. Merging pair (12,13) at cost 3.219646771412953E-15. Merging pair (14,15) at cost 2.5535129566378596E-15. Merging pair (16,17) at cost -4.440892098500626E-16. Merging pair (18,19) at cost 1.213695810519998E-12.\n",
      "State NNP. Merging pair (0,1) at cost 9.406585504326013E-10. Merging pair (2,3) at cost 2.484901173715003E-12. Merging pair (4,5) at cost 1.571276436705043E-4. Merging pair (8,9) at cost 2.46451967662781. Merging pair (10,11) at cost 1.4367094145982255. Merging pair (12,13) at cost 0.37840066408122636. Merging pair (14,15) at cost 1.3711191951378901E-5. Merging pair (16,17) at cost 3.578248808365572E-13.\n",
      "State CD. Merging pair (0,1) at cost 1.7692594709577524E-8. Merging pair (2,3) at cost 1.591566990920544. Merging pair (4,5) at cost 4.4408920985006257E-16. Merging pair (6,7) at cost -1.4791141972893971E-31. Merging pair (8,9) at cost 7.449596495233374E-13. Merging pair (10,11) at cost 3.290701044963883E-13.\n",
      "State NN. Merging pair (2,3) at cost 0.24591137482694475. Merging pair (12,13) at cost 1.2502221480292747E-11. Merging pair (16,17) at cost -5.773159728050814E-15. Merging pair (18,19) at cost 3.3911318194216974E-11. Merging pair (20,21) at cost 2.4713564528154904E-13.\n",
      "State ``. Merging pair (0,1) at cost 3.4416913763379846E-14.\n",
      "State ''. Merging pair (0,1) at cost 1.298960938811433E-14.\n",
      "State POS. Merging pair (0,1) at cost 2.7644553313166395E-14. Merging pair (2,3) at cost 0.2288765980098902.\n",
      "State PRN^g. Merging pair (0,1) at cost 7.881852322243686E-8. Merging pair (2,3) at cost 2.249340578475233. Merging pair (6,7) at cost 3.330669073875469E-16.\n",
      "State @PRN^g. Merging pair (0,1) at cost 7.876180565586815E-8. Merging pair (2,3) at cost 2.2493405784752336. Merging pair (4,5) at cost 3.0141612900514954. Merging pair (6,7) at cost 2.772588722239781. Merging pair (10,11) at cost 1.5878782461809544E-5. Merging pair (12,13) at cost 2.2493323085778187.\n",
      "State -LRB-. Merging pair (0,1) at cost -3.1086244689504383E-15. Merging pair (2,3) at cost 2.2204460492503128E-16.\n",
      "State JJ. Merging pair (0,1) at cost -2.3314683517128287E-15. Merging pair (2,3) at cost 7.327471962526032E-15. Merging pair (4,5) at cost 8.645306692754354E-13. Merging pair (6,7) at cost 3.649303081942127E-13. Merging pair (8,9) at cost 3.387361383750458E-9. Merging pair (10,11) at cost 0.26864938261169025. Merging pair (12,13) at cost 3.455447039495872E-11.\n",
      "State NNS. Merging pair (0,1) at cost 5.855094187243637E-12. Merging pair (4,5) at cost 2.7422508708239846E-14. Merging pair (6,7) at cost 3.0345482951786886. Merging pair (8,9) at cost 2.4717117241713403E-11. Merging pair (10,11) at cost 2.8231499748094597.\n",
      "State VP^g.\n",
      "State @VP^g.\n",
      "State VBP. Merging pair (2,3) at cost 8.026912468039626E-14. Merging pair (4,5) at cost 8.88178419700125E-16. Merging pair (6,7) at cost -1.3988810110276972E-14.\n",
      "State ,. Merging pair (0,1) at cost 1.0813572259849023E-13.\n",
      "State CC. Merging pair (0,1) at cost -3.219646771412954E-15. Merging pair (2,3) at cost -9.992007221626409E-15. Merging pair (4,5) at cost 9.992007221626407E-16. Merging pair (6,7) at cost 8.570921750105614E-14. Merging pair (10,11) at cost -3.907985046680551E-14. Merging pair (12,13) at cost 1.942300753258127.\n",
      "State -RRB-. Merging pair (0,1) at cost 0.03454907157527531.\n",
      "State VBN. Merging pair (2,3) at cost -2.1094237467877974E-15. Merging pair (4,5) at cost -1.1324274851176603E-14.\n",
      "State VBD. Merging pair (0,1) at cost -3.9968028886505635E-15. Merging pair (2,3) at cost 1.6653345369377346E-15. Merging pair (4,5) at cost 3.441691376337985E-15. Merging pair (6,7) at cost 2.8562707754500965E-12. Merging pair (8,9) at cost 0.0060129449359142195.\n",
      "State ADVP^g. Merging pair (0,1) at cost 1.3329320495754802. Merging pair (2,3) at cost -6.661338147750939E-16. Merging pair (6,7) at cost 1.453204541338987E-13. Merging pair (8,9) at cost 2.602524572991702.\n",
      "State RB. Merging pair (0,1) at cost -1.7763568394002505E-15. Merging pair (2,3) at cost 4.662936703425657E-15. Merging pair (4,5) at cost -6.661338147750939E-16. Merging pair (6,7) at cost 1.9095425048844386. Merging pair (8,9) at cost -7.771561172376096E-16. Merging pair (12,13) at cost -2.220446049250314E-16. Merging pair (14,15) at cost 1.4432899320127033E-15. Merging pair (18,19) at cost 0.7231822127845284.\n",
      "State TO. Merging pair (0,1) at cost 1.9188656147829493.\n",
      "State .. Merging pair (0,1) at cost 1.3655743202889203E-14. Merging pair (2,3) at cost -5.218048215738236E-14.\n",
      "State VBZ. Merging pair (0,1) at cost 1.832807239217944E-10. Merging pair (2,3) at cost 1.7241763572425483E-13. Merging pair (4,5) at cost -4.773959005888173E-15. Merging pair (6,7) at cost 1.2323475573339236E-14. Merging pair (8,9) at cost 2.3314683517128283E-15.\n",
      "State NNPS. Merging pair (0,1) at cost -5.329070518200751E-15.\n",
      "State SBAR^g. Merging pair (12,13) at cost 2.855702194747325. Merging pair (24,25) at cost 1.8515738585997465.\n",
      "State PRP. Merging pair (0,1) at cost 1.9499268639064564. Merging pair (2,3) at cost 0.13684110147134923.\n",
      "State PRP$. Merging pair (0,1) at cost 9.992007221626407E-16. Merging pair (2,3) at cost 3.2940317140619216E-13. Merging pair (4,5) at cost 1.1102230246251536E-16. Merging pair (6,7) at cost 7.152944902922415E-12.\n",
      "State VB. Merging pair (0,1) at cost 2.2204460492503128E-16. Merging pair (2,3) at cost -5.551115123125787E-16. Merging pair (4,5) at cost -4.440892098500626E-15. Merging pair (6,7) at cost 0.18618234207829984. Merging pair (8,9) at cost 3.2388819804138693.\n",
      "State ADJP^g. Merging pair (12,13) at cost 2.442943721188439.\n",
      "State QP^g. Merging pair (0,1) at cost 0.0016903504555898358. Merging pair (2,3) at cost 2.3464408736989735. Merging pair (4,5) at cost 2.2493405781075735. Merging pair (8,9) at cost 0.011424124642456398. Merging pair (16,17) at cost 0.0015534308753859813.\n",
      "State @PP^g. Merging pair (4,5) at cost 1.9095424898825089. Merging pair (10,11) at cost -5.500066027344891E-13. Merging pair (14,15) at cost 1.3862943611198906.\n",
      "State MD. Merging pair (2,3) at cost 1.6626775532271599E-9. Merging pair (6,7) at cost 3.5527136788005E-15.\n",
      "State UCP^g. Merging pair (0,1) at cost 2.772588722239781.\n",
      "State @UCP^g. Merging pair (0,1) at cost 3.3650583350462826. Merging pair (2,3) at cost 2.5020121176909393.\n",
      "State VBG. Merging pair (0,1) at cost 4.996003610813204E-15.\n",
      "State @SBAR^g. Merging pair (0,1) at cost 2.7725887222397816. Merging pair (2,3) at cost 3.3650583350462813.\n",
      "State WHNP^g. Merging pair (4,5) at cost 2.9557345464281637.\n",
      "State @ADVP^g. Merging pair (0,1) at cost 1.3862943611198906. Merging pair (2,3) at cost 3.112386791909953. Merging pair (6,7) at cost 2.5020121176909393.\n",
      "State RBR. Merging pair (0,1) at cost 2.6645352591003753E-15. Merging pair (2,3) at cost 1.1102230246251563E-15.\n",
      "State :. Merging pair (0,1) at cost -1.9984014443252818E-15. Merging pair (2,3) at cost 8.881784197001223E-16. Merging pair (4,5) at cost -2.55351295663786E-15. Merging pair (6,7) at cost 3.885780586188047E-15.\n",
      "State SINV^g. Merging pair (0,1) at cost 2.772588722239781. Merging pair (4,5) at cost -7.272984168669917E-10.\n",
      "State @SINV^g. Merging pair (2,3) at cost 3.3650583350462817. Merging pair (6,7) at cost -1.8563051523257428E-6. Merging pair (8,9) at cost 2.870814228018864. Merging pair (10,11) at cost 1.5322724002508442E-9. Merging pair (12,13) at cost 1.3862943611198906. Merging pair (14,15) at cost 0.03814004160516997. Merging pair (16,17) at cost 1.9095425048844386. Merging pair (18,19) at cost 0.007189406232394249.\n",
      "State WP. Merging pair (0,1) at cost 4.662936703425657E-15. Merging pair (2,3) at cost 1.554312234475219E-15.\n",
      "State WDT. Merging pair (0,1) at cost 7.442830812715351E-5.\n",
      "State JJR. Merging pair (0,1) at cost 3.20854454116657E-14. Merging pair (2,3) at cost 3.996802888650563E-15.\n",
      "State PDT. Merging pair (0,1) at cost 1.9091582043855142. Merging pair (2,3) at cost 2.95331066177891E-7.\n",
      "State RBS. Merging pair (0,1) at cost -1.1102230246251568E-16.\n",
      "State @QP^g. Merging pair (6,7) at cost 3.36505833504628. Merging pair (8,9) at cost 1.9095425048844386. Merging pair (10,11) at cost 0.006902011011191626. Merging pair (12,13) at cost 8.881784197001251E-16.\n",
      "State @ADJP^g. Merging pair (2,3) at cost 1.9095425048844386. Merging pair (4,5) at cost 3.3644058145016214. Merging pair (8,9) at cost 2.5020121176909393. Merging pair (10,11) at cost 2.7033672531978277. Merging pair (12,13) at cost 2.772588722239781.\n",
      "State JJS. Merging pair (0,1) at cost 5.218048215738235E-15.\n",
      "State FRAG^g. Merging pair (0,1) at cost -1.6135654269936832E-10. Merging pair (2,3) at cost 2.7725887222397816. Merging pair (4,5) at cost 2.249340578475233.\n",
      "State NAC^g. Merging pair (0,1) at cost 2.772588722239781. Merging pair (2,3) at cost 2.5129531383656465.\n",
      "State @NAC^g. Merging pair (2,3) at cost 2.8708142280188635.\n",
      "State WHADVP^g. Merging pair (2,3) at cost 2.990050097000446.\n",
      "State WRB. Merging pair (0,1) at cost 4.776342653123435E-10. Merging pair (2,3) at cost 6.905587213167941E-14.\n",
      "State $. Merging pair (0,1) at cost 0.00946526513823861.\n",
      "State PRT^g. Merging pair (2,3) at cost 2.2510246447547857. Merging pair (4,5) at cost 2.5187803636102273.\n",
      "State RP. Merging pair (2,3) at cost 1.1102230246251563E-16.\n",
      "State NX^g. Merging pair (2,3) at cost 0.8630462396564927. Merging pair (4,5) at cost 1.0464962875241772. Merging pair (6,7) at cost 7.564254775182438E-8. Merging pair (8,9) at cost 1.5791771473557623.\n",
      "State @FRAG^g. Merging pair (0,1) at cost 1.317072892028261. Merging pair (2,3) at cost 3.3650583350462826.\n",
      "State WHPP^g.\n",
      "State SQ^g. Merging pair (0,1) at cost 3.3650583350462826. Merging pair (2,3) at cost 3.330669073875469E-16.\n",
      "State @SQ^g.\n",
      "State @NX^g. Merging pair (2,3) at cost 7.564231682553187E-8. Merging pair (4,5) at cost 2.142837841789102. Merging pair (6,7) at cost 1.893247555377746E-9.\n",
      "State SBARQ^g. Merging pair (0,1) at cost 1.9095425048844386.\n",
      "State @SBARQ^g. Merging pair (4,5) at cost -1.1102230246251565E-16.\n",
      "State FW. Merging pair (0,1) at cost 1.3170728579941877.\n",
      "State EX. Merging pair (0,1) at cost -5.551115123125784E-16.\n",
      "State CONJP^g. Merging pair (0,1) at cost 2.2493405784752336. Merging pair (2,3) at cost 3.3650583350462826.\n",
      "State WHADJP^g. Merging pair (0,1) at cost 2.2493405784581406.\n",
      "State #. Merging pair (18,19) at cost 2.2204460492503128E-16.\n",
      "State @CONJP^g. Merging pair (0,1) at cost -9.673928325086898E-12. Merging pair (2,3) at cost -1.0943024264540277E-11.\n",
      "State @WHADJP^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State INTJ^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State WP$. Merging pair (0,1) at cost -1.1102230246251568E-16.\n",
      "State X^g. Merging pair (0,1) at cost 2.2204460492503128E-16.\n",
      "State UH.\n",
      "\n",
      "State TOP had 1 substates and now has 1.\n",
      "State S^g had 18 substates and now has 17.\n",
      "State @S^g had 30 substates and now has 28.\n",
      "State PP^g had 32 substates and now has 32.\n",
      "State IN had 30 substates and now has 23.\n",
      "State NP^g had 32 substates and now has 32.\n",
      "State @NP^g had 32 substates and now has 32.\n",
      "State DT had 22 substates and now has 12.\n",
      "State NNP had 18 substates and now has 10.\n",
      "State CD had 12 substates and now has 6.\n",
      "State NN had 22 substates and now has 17.\n",
      "State `` had 2 substates and now has 1.\n",
      "State '' had 2 substates and now has 1.\n",
      "State POS had 4 substates and now has 2.\n",
      "State PRN^g had 8 substates and now has 5.\n",
      "State @PRN^g had 16 substates and now has 10.\n",
      "State -LRB- had 4 substates and now has 2.\n",
      "State JJ had 14 substates and now has 7.\n",
      "State NNS had 12 substates and now has 7.\n",
      "State VP^g had 32 substates and now has 32.\n",
      "State @VP^g had 32 substates and now has 32.\n",
      "State VBP had 8 substates and now has 5.\n",
      "State , had 2 substates and now has 1.\n",
      "State CC had 14 substates and now has 8.\n",
      "State -RRB- had 2 substates and now has 1.\n",
      "State VBN had 6 substates and now has 4.\n",
      "State VBD had 10 substates and now has 5.\n",
      "State ADVP^g had 28 substates and now has 24.\n",
      "State RB had 22 substates and now has 14.\n",
      "State TO had 2 substates and now has 1.\n",
      "State . had 4 substates and now has 2.\n",
      "State VBZ had 10 substates and now has 5.\n",
      "State NNPS had 2 substates and now has 1.\n",
      "State SBAR^g had 26 substates and now has 24.\n",
      "State PRP had 4 substates and now has 2.\n",
      "State PRP$ had 8 substates and now has 4.\n",
      "State VB had 10 substates and now has 5.\n",
      "State ADJP^g had 32 substates and now has 31.\n",
      "State QP^g had 20 substates and now has 15.\n",
      "State @PP^g had 20 substates and now has 17.\n",
      "State MD had 8 substates and now has 6.\n",
      "State UCP^g had 6 substates and now has 5.\n",
      "State @UCP^g had 10 substates and now has 8.\n",
      "State VBG had 2 substates and now has 1.\n",
      "State @SBAR^g had 10 substates and now has 8.\n",
      "State WHNP^g had 6 substates and now has 5.\n",
      "State @ADVP^g had 8 substates and now has 5.\n",
      "State RBR had 4 substates and now has 2.\n",
      "State : had 8 substates and now has 4.\n",
      "State SINV^g had 6 substates and now has 4.\n",
      "State @SINV^g had 20 substates and now has 12.\n",
      "State WP had 4 substates and now has 2.\n",
      "State WDT had 2 substates and now has 1.\n",
      "State JJR had 4 substates and now has 2.\n",
      "State PDT had 4 substates and now has 2.\n",
      "State RBS had 2 substates and now has 1.\n",
      "State @QP^g had 18 substates and now has 14.\n",
      "State @ADJP^g had 14 substates and now has 9.\n",
      "State JJS had 2 substates and now has 1.\n",
      "State FRAG^g had 8 substates and now has 5.\n",
      "State NAC^g had 4 substates and now has 2.\n",
      "State @NAC^g had 4 substates and now has 3.\n",
      "State WHADVP^g had 4 substates and now has 3.\n",
      "State WRB had 4 substates and now has 2.\n",
      "State $ had 2 substates and now has 1.\n",
      "State PRT^g had 6 substates and now has 4.\n",
      "State RP had 4 substates and now has 3.\n",
      "State NX^g had 10 substates and now has 6.\n",
      "State @FRAG^g had 6 substates and now has 4.\n",
      "State WHPP^g had 2 substates and now has 2.\n",
      "State SQ^g had 4 substates and now has 2.\n",
      "State @SQ^g had 6 substates and now has 6.\n",
      "State @NX^g had 8 substates and now has 5.\n",
      "State SBARQ^g had 2 substates and now has 1.\n",
      "State @SBARQ^g had 8 substates and now has 7.\n",
      "State FW had 2 substates and now has 1.\n",
      "State EX had 2 substates and now has 1.\n",
      "State CONJP^g had 4 substates and now has 2.\n",
      "State WHADJP^g had 2 substates and now has 1.\n",
      "State # had 22 substates and now has 21.\n",
      "State @CONJP^g had 4 substates and now has 2.\n",
      "State @WHADJP^g had 2 substates and now has 1.\n",
      "State INTJ^g had 2 substates and now has 1.\n",
      "State WP$ had 2 substates and now has 1.\n",
      "State X^g had 12 substates and now has 11.\n",
      "State UH had 12 substates and now has 12.\n",
      "Lexicon: [IN : 23, # : 21, NN : 17, RB : 14, DT : 12, UH : 12, NNP : 10, CC : 8, JJ : 7, NNS : 7, CD : 6, MD : 6, VBD : 5, VBZ : 5, VB : 5, VBP : 5, VBN : 4, PRP$ : 4, : : 4, RP : 3, POS : 2, JJR : 2, -LRB- : 2, WRB : 2, . : 2, PRP : 2, PDT : 2, RBR : 2, WP : 2, WDT : 1, VBG : 1, TO : 1, -RRB- : 1, EX : 1, NNPS : 1, `` : 1, $ : 1, JJS : 1, , : 1, RBS : 1, FW : 1, '' : 1, WP$ : 1]\n",
      "Grammar: [PP^g : 32, NP^g : 32, VP^g : 32, @VP^g : 32, @NP^g : 32, ADJP^g : 31, @S^g : 28, ADVP^g : 24, SBAR^g : 24, S^g : 17, @PP^g : 17, QP^g : 15, @QP^g : 14, @SINV^g : 12, X^g : 11, @PRN^g : 10, @ADJP^g : 9, @UCP^g : 8, @SBAR^g : 8, @SBARQ^g : 7, @SQ^g : 6, NX^g : 6, @NX^g : 5, WHNP^g : 5, @ADVP^g : 5, FRAG^g : 5, PRN^g : 5, UCP^g : 5, PRT^g : 4, @FRAG^g : 4, SINV^g : 4, @NAC^g : 3, WHADVP^g : 3, WHPP^g : 2, NAC^g : 2, CONJP^g : 2, @CONJP^g : 2, SQ^g : 2, TOP : 1, SBARQ^g : 1, INTJ^g : 1, @WHADJP^g : 1, WHADJP^g : 1]\n",
      "After merging in the 5th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128748.37409499007\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128710.65835484448\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128676.06843236141\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128641.82208001378\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128610.11501254652\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128583.0315526868\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128559.26779338342\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128537.80771156652\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128517.29407689138\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128495.20221006991\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128471.92203105112\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128451.4710474205\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128433.22212172222\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128416.53033798821\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128400.08413729901\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128383.14263495358\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128367.20020928908\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128352.93679599337\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128339.5070665744\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128325.9200683605\n",
      "Saving grammar to ptb.gr_5_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 5th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -129804.56614964818\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130095.51189896291\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130131.25518062926\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130136.46441475197\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130130.16399182059\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130118.08668951206\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130101.6357152269\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130084.2482782796\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130067.26622459861\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -130049.95997133735\n",
      "Saving grammar to ptb.gr_5_smoothing.gr.\n",
      "Saving successful.\n",
      "Before splitting, we have a total of 680 substates.\n",
      "After splitting, we have a total of 1359 substates.\n",
      "Rule probabilities are NOT normalized in the split, therefore the training LL is not guaranteed to improve between iteration 0 and 1!\n",
      "After splitting in the 6th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128675.09682504392\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128313.8307066981\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128224.85037929009\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128172.84246272301\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128135.43077811277\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128106.16945354642\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128081.20143038669\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128053.22326552021\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -128006.19485796255\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127905.66419346482\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127702.31028271458\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -127373.13606133465\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126936.74873103922\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -126433.36778740017\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125908.11951240146\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -125392.39220707145\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124900.29511877464\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124437.9411397532\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -124010.70527008787\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123623.66602201633\n",
      "Beginning iteration 20:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -123281.75999839517\n",
      "Beginning iteration 21:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122989.77471211638\n",
      "Beginning iteration 22:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122743.41443753672\n",
      "Beginning iteration 23:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122532.26457602976\n",
      "Beginning iteration 24:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122352.1188261528\n",
      "Beginning iteration 25:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122201.1646830763\n",
      "Beginning iteration 26:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122068.59795756255\n",
      "Beginning iteration 27:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121950.62284011111\n",
      "Beginning iteration 28:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121846.9237594817\n",
      "Beginning iteration 29:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121755.65899404396\n",
      "Beginning iteration 30:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121673.31981602893\n",
      "Beginning iteration 31:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121597.5237470383\n",
      "Beginning iteration 32:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121528.46819531513\n",
      "Beginning iteration 33:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121465.82416045482\n",
      "Beginning iteration 34:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121407.28755995483\n",
      "Beginning iteration 35:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121351.45789396812\n",
      "Beginning iteration 36:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121297.17397475832\n",
      "Beginning iteration 37:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121247.55038802793\n",
      "Beginning iteration 38:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121201.17165314585\n",
      "Beginning iteration 39:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121154.20414446578\n",
      "Beginning iteration 40:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121109.36282348681\n",
      "Beginning iteration 41:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121066.09323941081\n",
      "Beginning iteration 42:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121025.2670662529\n",
      "Beginning iteration 43:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120989.12393237563\n",
      "Beginning iteration 44:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120957.36858309642\n",
      "Beginning iteration 45:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120929.99105057742\n",
      "Beginning iteration 46:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120904.89029549184\n",
      "Beginning iteration 47:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120878.75025217986\n",
      "Beginning iteration 48:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120853.06152159226\n",
      "Beginning iteration 49:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120830.32195100951\n",
      "Saving grammar to ptb.gr_6_splitting.gr.\n",
      "Saving successful.\n",
      "The trainings LL before merging is -121282.6751608234\n",
      "Going to merge 50% of the substates siblings.\n",
      "Setting the threshold for siblings to 2.5020121176909393.\n",
      "Merging 319 siblings and 0 other pairs.\n",
      "State TOP.\n",
      "State S^g. Merging pair (0,1) at cost 0.738863885916956. Merging pair (26,27) at cost 0.006678872784245313. Merging pair (30,31) at cost 1.7762591939482864.\n",
      "State @S^g. Merging pair (40,41) at cost 1.9095425048844388. Merging pair (48,49) at cost 0.08445963452847326. Merging pair (50,51) at cost 1.5779820145306338. Merging pair (52,53) at cost 0.3797415874401414.\n",
      "State PP^g.\n",
      "State IN. Merging pair (0,1) at cost 2.5701663020071283E-13. Merging pair (2,3) at cost 1.9317204169571653. Merging pair (4,5) at cost -6.084022174945858E-14. Merging pair (6,7) at cost 4.4408920985006257E-16. Merging pair (8,9) at cost -8.215650382226158E-15. Merging pair (10,11) at cost 0.9243694643220657. Merging pair (12,13) at cost -4.39648317751562E-14. Merging pair (16,17) at cost 0.8733825807558155. Merging pair (18,19) at cost 3.108624468950438E-15. Merging pair (22,23) at cost 1.110223024625156E-16. Merging pair (24,25) at cost -1.4432899320127035E-15. Merging pair (26,27) at cost -1.1102230246251565E-16. Merging pair (28,29) at cost 0.0014680113366961206. Merging pair (30,31) at cost -2.220446049250313E-15. Merging pair (32,33) at cost 1.7763568394002503E-15. Merging pair (38,39) at cost 2.3314683517128284E-14. Merging pair (40,41) at cost 2.442490654175344E-15. Merging pair (42,43) at cost 0.9280586343621746. Merging pair (44,45) at cost 1.7728091506843309.\n",
      "State NP^g.\n",
      "State @NP^g. Merging pair (50,51) at cost 0.41505393573575133. Merging pair (54,55) at cost 2.2964959568695167.\n",
      "State DT. Merging pair (0,1) at cost 0.18193898521506405. Merging pair (2,3) at cost 2.2548629630131378E-13. Merging pair (4,5) at cost -7.771561172376127E-16. Merging pair (6,7) at cost -1.1102230246251588E-16. Merging pair (8,9) at cost 8.14493479587606E-9. Merging pair (10,11) at cost -4.2521541843143495E-14. Merging pair (12,13) at cost 3.097522238704186E-14. Merging pair (14,15) at cost -1.887379141862766E-15. Merging pair (16,17) at cost 1.9984014443252814E-15. Merging pair (18,19) at cost 3.559375016947387E-13. Merging pair (20,21) at cost -1.4432899320127035E-15. Merging pair (22,23) at cost -5.551115123125784E-16.\n",
      "State NNP. Merging pair (0,1) at cost 1.3100631690574976E-14. Merging pair (2,3) at cost 5.261346913696947E-13. Merging pair (4,5) at cost 1.2434497875801275E-14. Merging pair (6,7) at cost 2.040545510282735E-11. Merging pair (8,9) at cost 7.771561172375976E-15. Merging pair (10,11) at cost 1.3968715073444048E-11. Merging pair (12,13) at cost 1.473706766161458. Merging pair (14,15) at cost 0.4133194827494137. Merging pair (16,17) at cost -2.220446049250313E-15. Merging pair (18,19) at cost 1.8651746813702627E-14.\n",
      "State CD. Merging pair (0,1) at cost 8.38053048024963E-8. Merging pair (2,3) at cost 1.440218569708855. Merging pair (4,5) at cost 4.4408920985006257E-16. Merging pair (6,7) at cost -1.6653345369377348E-15. Merging pair (8,9) at cost 2.0180523918600173E-12. Merging pair (10,11) at cost 5.447864381821238E-13.\n",
      "State NN. Merging pair (0,1) at cost 2.8438297261719458E-9. Merging pair (2,3) at cost -3.330669073875472E-16. Merging pair (4,5) at cost 7.255973599466536E-12. Merging pair (8,9) at cost 1.9634868295869068. Merging pair (10,11) at cost 5.329070518149828E-15. Merging pair (12,13) at cost 8.881784197001251E-16. Merging pair (14,15) at cost 1.9949597529482806E-12. Merging pair (18,19) at cost 1.784726655776834. Merging pair (22,23) at cost 1.923083914332565E-11. Merging pair (24,25) at cost 0.055787398004579526. Merging pair (26,27) at cost 1.3048482059667834. Merging pair (28,29) at cost -3.8191672047105385E-14. Merging pair (30,31) at cost -2.220446049250313E-15. Merging pair (32,33) at cost 6.483702463810884E-14.\n",
      "State ``. Merging pair (0,1) at cost 3.885780586188047E-15.\n",
      "State ''. Merging pair (0,1) at cost -3.0309088572266774E-14.\n",
      "State POS. Merging pair (0,1) at cost -1.3100631690576847E-14. Merging pair (2,3) at cost 2.109423746787797E-15.\n",
      "State PRN^g. Merging pair (0,1) at cost -7.545472643529752E-8. Merging pair (2,3) at cost 2.249340578475233. Merging pair (4,5) at cost 2.2204460492503128E-16. Merging pair (6,7) at cost 4.521217534915899E-7. Merging pair (8,9) at cost 1.1102230246251563E-16.\n",
      "State @PRN^g. Merging pair (0,1) at cost -7.545574712538243E-8. Merging pair (2,3) at cost 2.2493405784752336. Merging pair (8,9) at cost 2.2204460492503128E-16. Merging pair (10,11) at cost 0.31620117030681827. Merging pair (12,13) at cost -6.615667812966342E-7. Merging pair (16,17) at cost 1.3862943611198906.\n",
      "State -LRB-. Merging pair (0,1) at cost -6.106226635438361E-15. Merging pair (2,3) at cost -1.1102230246251565E-16.\n",
      "State JJ. Merging pair (0,1) at cost 1.6653345369377346E-15. Merging pair (2,3) at cost -2.220446049250313E-15. Merging pair (4,5) at cost 6.976641486743936E-13. Merging pair (6,7) at cost 1.206812427767519E-13. Merging pair (8,9) at cost -3.1086244689504383E-15. Merging pair (10,11) at cost 8.153120685544969E-8. Merging pair (12,13) at cost 7.549516567451063E-15.\n",
      "State NNS. Merging pair (0,1) at cost 9.85656001262024E-13. Merging pair (2,3) at cost 2.178015839762002. Merging pair (4,5) at cost 6.559197629480895E-13. Merging pair (6,7) at cost 1.8873791418627657E-15. Merging pair (8,9) at cost -2.3314683517128287E-15. Merging pair (10,11) at cost 4.773959005888172E-15. Merging pair (12,13) at cost 1.8224476740220013.\n",
      "State VP^g. Merging pair (62,63) at cost 1.4365451891461383.\n",
      "State @VP^g. Merging pair (20,21) at cost 1.9095425048844388. Merging pair (24,25) at cost -2.958016197089614E-10.\n",
      "State VBP. Merging pair (0,1) at cost -4.440892098500626E-16. Merging pair (2,3) at cost -1.1102230246251565E-16. Merging pair (4,5) at cost -6.661338147751665E-16. Merging pair (6,7) at cost 2.2204460492503116E-16. Merging pair (8,9) at cost -4.9960036108132044E-15.\n",
      "State ,. Merging pair (0,1) at cost -6.861178292183467E-14.\n",
      "State CC. Merging pair (0,1) at cost -8.881784197001252E-16. Merging pair (2,3) at cost -2.7755575615628914E-15. Merging pair (4,5) at cost -2.220446049250313E-16. Merging pair (6,7) at cost 8.992806499463086E-15. Merging pair (8,9) at cost 2.9976021664879223E-15. Merging pair (10,11) at cost 9.071754458182856E-11. Merging pair (12,13) at cost -1.9761969838327786E-14.\n",
      "State -RRB-. Merging pair (0,1) at cost 0.023444511969095964.\n",
      "State VBN. Merging pair (0,1) at cost 2.2204460492503128E-16. Merging pair (2,3) at cost 4.4408920985006257E-16. Merging pair (4,5) at cost 8.215650382226157E-15. Merging pair (6,7) at cost -1.154631945610214E-14.\n",
      "State VBD. Merging pair (0,1) at cost 7.216449660063516E-15. Merging pair (2,3) at cost 1.1768364061026658E-14. Merging pair (4,5) at cost 6.88338275267597E-15. Merging pair (6,7) at cost 1.8529622280993694E-13. Merging pair (8,9) at cost 0.02756600138159886.\n",
      "State ADVP^g. Merging pair (0,1) at cost 1.2299435369107374. Merging pair (2,3) at cost -3.3306690738754696E-16. Merging pair (4,5) at cost 1.9095425048844388. Merging pair (8,9) at cost 6.94637236141194E-9. Merging pair (12,13) at cost 2.1447093020214259E-7. Merging pair (14,15) at cost 1.9095425048844383.\n",
      "State RB. Merging pair (0,1) at cost -1.887379141862766E-15. Merging pair (2,3) at cost -4.3298697960381105E-15. Merging pair (4,5) at cost 5.551115123125782E-16. Merging pair (6,7) at cost 1.909542504884438. Merging pair (8,9) at cost -5.551115123125783E-16. Merging pair (10,11) at cost 1.9094766149750857. Merging pair (12,13) at cost -3.3306690738754696E-16. Merging pair (14,15) at cost -2.55351295663786E-15. Merging pair (16,17) at cost 2.220446049250312E-16. Merging pair (18,19) at cost 2.249337832015799. Merging pair (20,21) at cost -7.771561172376096E-16. Merging pair (22,23) at cost 9.389965929621345E-4. Merging pair (24,25) at cost -2.220446049250313E-16. Merging pair (26,27) at cost 6.9463734716258E-9.\n",
      "State TO. Merging pair (0,1) at cost 1.9796680551996748.\n",
      "State .. Merging pair (0,1) at cost 9.76996261670127E-15. Merging pair (2,3) at cost 7.971401316808623E-14.\n",
      "State VBZ. Merging pair (0,1) at cost 1.0954503968039893E-9. Merging pair (2,3) at cost 9.769962616701008E-14. Merging pair (4,5) at cost -9.769962616701378E-15. Merging pair (6,7) at cost -6.661338147750939E-15. Merging pair (8,9) at cost -2.220446049250313E-16.\n",
      "State NNPS. Merging pair (0,1) at cost -1.7763568394002505E-15.\n",
      "State SBAR^g. Merging pair (12,13) at cost 0.003511141930632038. Merging pair (32,33) at cost 1.8177075828799263. Merging pair (44,45) at cost 5.502047551293616E-7.\n",
      "State PRP. Merging pair (0,1) at cost 0.5708061183210754. Merging pair (2,3) at cost 0.046366188135311716.\n",
      "State PRP$. Merging pair (0,1) at cost 1.4321877017664516E-14. Merging pair (2,3) at cost 1.562083795647412E-13. Merging pair (4,5) at cost -1.0547118733938987E-14. Merging pair (6,7) at cost -1.4432899320127035E-15.\n",
      "State VB. Merging pair (0,1) at cost 4.440892098500625E-16. Merging pair (2,3) at cost 1.9984014443252814E-15. Merging pair (4,5) at cost 1.498801083243961E-14.\n",
      "State ADJP^g. Merging pair (8,9) at cost 2.4093273155447528. Merging pair (16,17) at cost 2.24934057847523. Merging pair (20,21) at cost 1.909542504884439. Merging pair (24,25) at cost 2.4429437213908756. Merging pair (26,27) at cost 0.7938228234888156. Merging pair (28,29) at cost 1.1102230246251563E-16. Merging pair (30,31) at cost 2.2783446150271756. Merging pair (34,35) at cost 0.523248143640768. Merging pair (40,41) at cost 1.3862943611198906.\n",
      "State QP^g. Merging pair (0,1) at cost 2.1503929554061833E-4. Merging pair (4,5) at cost 2.2493405784752336. Merging pair (8,9) at cost 2.2204460492503126E-16. Merging pair (10,11) at cost 9.110249658621304E-6. Merging pair (20,21) at cost 1.909544934730705. Merging pair (22,23) at cost 1.3862943611198906. Merging pair (24,25) at cost 1.0147189834242804E-5. Merging pair (26,27) at cost 2.249340578475233. Merging pair (28,29) at cost -9.31057168319891E-12.\n",
      "State @PP^g. Merging pair (0,1) at cost 2.5020121069443713. Merging pair (2,3) at cost 0.8109300827967201. Merging pair (4,5) at cost 1.9095425048639885. Merging pair (8,9) at cost 1.909542504884438. Merging pair (14,15) at cost 2.5020121176909393. Merging pair (18,19) at cost -7.827127017492559E-14. Merging pair (20,21) at cost 1.909542504885374. Merging pair (24,25) at cost 1.3862943611198908. Merging pair (26,27) at cost 2.249340578475233. Merging pair (28,29) at cost 1.9095425048844388. Merging pair (30,31) at cost 1.3233557906684479.\n",
      "State MD. Merging pair (0,1) at cost 1.3322676295501877E-15. Merging pair (2,3) at cost 2.6495122918466886E-6. Merging pair (4,5) at cost -4.912736884012072E-13. Merging pair (6,7) at cost 1.0127225410905535E-4. Merging pair (8,9) at cost -2.711709361697228E-31. Merging pair (10,11) at cost 1.3322676295501877E-15.\n",
      "State UCP^g. Merging pair (4,5) at cost 1.3862943611198906. Merging pair (6,7) at cost 2.5020121176909393. Merging pair (8,9) at cost 3.380094307424389E-8.\n",
      "State @UCP^g. Merging pair (2,3) at cost 2.502012117690939. Merging pair (4,5) at cost -5.296930641357418E-10. Merging pair (6,7) at cost -5.36425415550288E-29. Merging pair (8,9) at cost 2.5020121176909393. Merging pair (10,11) at cost 1.9095425048844388. Merging pair (12,13) at cost 1.9095425048844388. Merging pair (14,15) at cost 1.9095425048844386.\n",
      "State VBG. Merging pair (0,1) at cost 2.3314683517128276E-15.\n",
      "State @SBAR^g. Merging pair (0,1) at cost 2.249340578475233. Merging pair (6,7) at cost 1.3862943611198904. Merging pair (10,11) at cost 0.03941783937176537. Merging pair (14,15) at cost 2.2493405784752327.\n",
      "State WHNP^g. Merging pair (0,1) at cost 1.3901764939294112. Merging pair (4,5) at cost 1.002019707642068E-5. Merging pair (6,7) at cost -7.771561172376096E-16.\n",
      "State @ADVP^g. Merging pair (0,1) at cost 1.3862943611198904. Merging pair (4,5) at cost 1.909542504884438. Merging pair (8,9) at cost 2.5020121176909393.\n",
      "State RBR. Merging pair (0,1) at cost 2.2204460492503123E-16. Merging pair (2,3) at cost 8.881784197001251E-16.\n",
      "State :. Merging pair (0,1) at cost 2.775557561562891E-15. Merging pair (2,3) at cost -5.551115123125783E-16. Merging pair (4,5) at cost -1.5543122344752192E-15. Merging pair (6,7) at cost 4.218847493575594E-15.\n",
      "State SINV^g. Merging pair (2,3) at cost 1.0464962874820976. Merging pair (4,5) at cost 1.3862943611198906. Merging pair (6,7) at cost -7.66918191798397E-9.\n",
      "State @SINV^g. Merging pair (0,1) at cost -9.832780148390361E-10. Merging pair (2,3) at cost -6.718484733244268E-10. Merging pair (6,7) at cost 2.2493405784752336. Merging pair (8,9) at cost 0.8630462156719833. Merging pair (10,11) at cost 1.634612766985435E-5. Merging pair (14,15) at cost 2.5341431144967615E-9. Merging pair (16,17) at cost 1.3862943611198906. Merging pair (18,19) at cost 6.144305375670127E-6. Merging pair (20,21) at cost 1.9095425048844383. Merging pair (22,23) at cost 0.24453859031398426.\n",
      "State WP. Merging pair (0,1) at cost 3.7747582837255314E-15. Merging pair (2,3) at cost -2.55351295663786E-15.\n",
      "State WDT. Merging pair (0,1) at cost 8.849981947940206E-5.\n",
      "State JJR. Merging pair (0,1) at cost 1.2212453270874363E-15. Merging pair (2,3) at cost 5.107025913275719E-15.\n",
      "State PDT. Merging pair (0,1) at cost 1.9095284056437167. Merging pair (2,3) at cost 1.554312234475219E-15.\n",
      "State RBS. Merging pair (0,1) at cost -2.465190328815662E-32.\n",
      "State @QP^g. Merging pair (0,1) at cost 8.570010576348028E-9. Merging pair (2,3) at cost -5.265417193920251E-10. Merging pair (4,5) at cost -3.41227046618833E-12. Merging pair (6,7) at cost 1.0614120391001413E-8. Merging pair (8,9) at cost -7.771561172376096E-16. Merging pair (10,11) at cost 1.9095425048844386. Merging pair (14,15) at cost 1.909542504884439. Merging pair (16,17) at cost 0.02527102173161295. Merging pair (18,19) at cost 8.656308641476287E-9. Merging pair (20,21) at cost 1.938549509226717. Merging pair (22,23) at cost 0.9350733888858791. Merging pair (24,25) at cost 1.7531921433172069. Merging pair (26,27) at cost 0.45400426358948176.\n",
      "State @ADJP^g. Merging pair (2,3) at cost 1.3862943611198906. Merging pair (4,5) at cost 1.9095425048844386. Merging pair (8,9) at cost 6.661338147750938E-16. Merging pair (10,11) at cost 2.0077670564320855. Merging pair (12,13) at cost 2.5020121176909393.\n",
      "State JJS. Merging pair (0,1) at cost 5.884182030513329E-15.\n",
      "State FRAG^g. Merging pair (0,1) at cost -2.793997182669136E-12. Merging pair (6,7) at cost 1.3862943611198906. Merging pair (8,9) at cost -2.220446049250313E-16.\n",
      "State NAC^g.\n",
      "State @NAC^g. Merging pair (0,1) at cost 0.0859064954250276. Merging pair (2,3) at cost -2.5866602302733706E-8.\n",
      "State WHADVP^g. Merging pair (0,1) at cost 1.2156050669018126.\n",
      "State WRB. Merging pair (0,1) at cost 3.019806626980393E-14. Merging pair (2,3) at cost 1.7985612998925403E-14.\n",
      "State $. Merging pair (0,1) at cost 0.02158617676675167.\n",
      "State PRT^g. Merging pair (4,5) at cost 2.249340578475233.\n",
      "State RP. Merging pair (0,1) at cost 1.5635732195987697. Merging pair (2,3) at cost 0.12651032415885066. Merging pair (4,5) at cost 6.661338147750938E-16.\n",
      "State NX^g. Merging pair (2,3) at cost 1.619640499748285. Merging pair (4,5) at cost 2.1064086705724945. Merging pair (6,7) at cost 2.4327906424536825. Merging pair (10,11) at cost 0.5232481437645444.\n",
      "State @FRAG^g. Merging pair (0,1) at cost 1.3170728920402976. Merging pair (6,7) at cost 1.9095425048844388.\n",
      "State WHPP^g. Merging pair (0,1) at cost 0.00863495880293563. Merging pair (2,3) at cost -8.149037084886488E-14.\n",
      "State SQ^g. Merging pair (2,3) at cost -1.8419672468166382E-9.\n",
      "State @SQ^g. Merging pair (2,3) at cost 1.9095425048844388. Merging pair (4,5) at cost -1.8438943820473289E-9. Merging pair (6,7) at cost -2.2204460505675215E-16. Merging pair (8,9) at cost 0.810930215755247. Merging pair (10,11) at cost 1.3862943611198906.\n",
      "State @NX^g. Merging pair (0,1) at cost -4.0082168168677627E-14. Merging pair (2,3) at cost 1.909542498692407. Merging pair (4,5) at cost 1.2662712177731714. Merging pair (8,9) at cost 0.48111256785930834.\n",
      "State SBARQ^g. Merging pair (0,1) at cost 1.9095425048844388.\n",
      "State @SBARQ^g. Merging pair (2,3) at cost -4.440892098500626E-16. Merging pair (8,9) at cost 2.2204460492503128E-16. Merging pair (10,11) at cost -6.66133814775094E-16. Merging pair (12,13) at cost -4.107825191113084E-15.\n",
      "State FW. Merging pair (0,1) at cost 1.3170728580681899.\n",
      "State EX. Merging pair (0,1) at cost 4.440892098500624E-16.\n",
      "State CONJP^g. Merging pair (0,1) at cost 2.249340578475233.\n",
      "State WHADJP^g. Merging pair (0,1) at cost 2.249340578475233.\n",
      "State #. Merging pair (22,23) at cost 2.2204460492503128E-16.\n",
      "State @CONJP^g. Merging pair (0,1) at cost -2.4646951146678576E-14. Merging pair (2,3) at cost -7.00550728538482E-14.\n",
      "State @WHADJP^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State INTJ^g. Merging pair (0,1) at cost 1.3862943611198906.\n",
      "State WP$. Merging pair (0,1) at cost 1.1102230246251563E-16.\n",
      "State X^g. Merging pair (18,19) at cost -1.1102230246251565E-16.\n",
      "State UH. Merging pair (4,5) at cost -2.220446049250313E-16. Merging pair (14,15) at cost -2.220446049250313E-16.\n",
      "\n",
      "State TOP had 1 substates and now has 1.\n",
      "State S^g had 34 substates and now has 31.\n",
      "State @S^g had 56 substates and now has 52.\n",
      "State PP^g had 64 substates and now has 64.\n",
      "State IN had 46 substates and now has 27.\n",
      "State NP^g had 64 substates and now has 64.\n",
      "State @NP^g had 64 substates and now has 62.\n",
      "State DT had 24 substates and now has 12.\n",
      "State NNP had 20 substates and now has 10.\n",
      "State CD had 12 substates and now has 6.\n",
      "State NN had 34 substates and now has 20.\n",
      "State `` had 2 substates and now has 1.\n",
      "State '' had 2 substates and now has 1.\n",
      "State POS had 4 substates and now has 2.\n",
      "State PRN^g had 10 substates and now has 5.\n",
      "State @PRN^g had 20 substates and now has 14.\n",
      "State -LRB- had 4 substates and now has 2.\n",
      "State JJ had 14 substates and now has 7.\n",
      "State NNS had 14 substates and now has 7.\n",
      "State VP^g had 64 substates and now has 63.\n",
      "State @VP^g had 64 substates and now has 62.\n",
      "State VBP had 10 substates and now has 5.\n",
      "State , had 2 substates and now has 1.\n",
      "State CC had 16 substates and now has 9.\n",
      "State -RRB- had 2 substates and now has 1.\n",
      "State VBN had 8 substates and now has 4.\n",
      "State VBD had 10 substates and now has 5.\n",
      "State ADVP^g had 48 substates and now has 42.\n",
      "State RB had 28 substates and now has 14.\n",
      "State TO had 2 substates and now has 1.\n",
      "State . had 4 substates and now has 2.\n",
      "State VBZ had 10 substates and now has 5.\n",
      "State NNPS had 2 substates and now has 1.\n",
      "State SBAR^g had 48 substates and now has 45.\n",
      "State PRP had 4 substates and now has 2.\n",
      "State PRP$ had 8 substates and now has 4.\n",
      "State VB had 10 substates and now has 7.\n",
      "State ADJP^g had 62 substates and now has 53.\n",
      "State QP^g had 30 substates and now has 21.\n",
      "State @PP^g had 34 substates and now has 23.\n",
      "State MD had 12 substates and now has 6.\n",
      "State UCP^g had 10 substates and now has 7.\n",
      "State @UCP^g had 16 substates and now has 9.\n",
      "State VBG had 2 substates and now has 1.\n",
      "State @SBAR^g had 16 substates and now has 12.\n",
      "State WHNP^g had 10 substates and now has 7.\n",
      "State @ADVP^g had 10 substates and now has 7.\n",
      "State RBR had 4 substates and now has 2.\n",
      "State : had 8 substates and now has 4.\n",
      "State SINV^g had 8 substates and now has 5.\n",
      "State @SINV^g had 24 substates and now has 14.\n",
      "State WP had 4 substates and now has 2.\n",
      "State WDT had 2 substates and now has 1.\n",
      "State JJR had 4 substates and now has 2.\n",
      "State PDT had 4 substates and now has 2.\n",
      "State RBS had 2 substates and now has 1.\n",
      "State @QP^g had 28 substates and now has 15.\n",
      "State @ADJP^g had 18 substates and now has 13.\n",
      "State JJS had 2 substates and now has 1.\n",
      "State FRAG^g had 10 substates and now has 7.\n",
      "State NAC^g had 4 substates and now has 4.\n",
      "State @NAC^g had 6 substates and now has 4.\n",
      "State WHADVP^g had 6 substates and now has 5.\n",
      "State WRB had 4 substates and now has 2.\n",
      "State $ had 2 substates and now has 1.\n",
      "State PRT^g had 8 substates and now has 7.\n",
      "State RP had 6 substates and now has 3.\n",
      "State NX^g had 12 substates and now has 8.\n",
      "State @FRAG^g had 8 substates and now has 6.\n",
      "State WHPP^g had 4 substates and now has 2.\n",
      "State SQ^g had 4 substates and now has 3.\n",
      "State @SQ^g had 12 substates and now has 7.\n",
      "State @NX^g had 10 substates and now has 6.\n",
      "State SBARQ^g had 2 substates and now has 1.\n",
      "State @SBARQ^g had 14 substates and now has 10.\n",
      "State FW had 2 substates and now has 1.\n",
      "State EX had 2 substates and now has 1.\n",
      "State CONJP^g had 4 substates and now has 3.\n",
      "State WHADJP^g had 2 substates and now has 1.\n",
      "State # had 42 substates and now has 41.\n",
      "State @CONJP^g had 4 substates and now has 2.\n",
      "State @WHADJP^g had 2 substates and now has 1.\n",
      "State INTJ^g had 2 substates and now has 1.\n",
      "State WP$ had 2 substates and now has 1.\n",
      "State X^g had 22 substates and now has 21.\n",
      "State UH had 24 substates and now has 22.\n",
      "Lexicon: [# : 41, IN : 27, UH : 22, NN : 20, RB : 14, DT : 12, NNP : 10, CC : 9, JJ : 7, NNS : 7, VB : 7, CD : 6, MD : 6, VBD : 5, VBZ : 5, VBP : 5, VBN : 4, PRP$ : 4, : : 4, RP : 3, PDT : 2, POS : 2, -LRB- : 2, WRB : 2, . : 2, PRP : 2, JJR : 2, RBR : 2, WP : 2, -RRB- : 1, VBG : 1, $ : 1, TO : 1, EX : 1, NNPS : 1, `` : 1, RBS : 1, JJS : 1, , : 1, WDT : 1, FW : 1, '' : 1, WP$ : 1]\n",
      "Grammar: [PP^g : 64, NP^g : 64, VP^g : 63, @VP^g : 62, @NP^g : 62, ADJP^g : 53, @S^g : 52, SBAR^g : 45, ADVP^g : 42, S^g : 31, @PP^g : 23, X^g : 21, QP^g : 21, @QP^g : 15, @PRN^g : 14, @SINV^g : 14, @ADJP^g : 13, @SBAR^g : 12, @SBARQ^g : 10, @UCP^g : 9, NX^g : 8, UCP^g : 7, WHNP^g : 7, @ADVP^g : 7, FRAG^g : 7, PRT^g : 7, @SQ^g : 7, @FRAG^g : 6, @NX^g : 6, PRN^g : 5, SINV^g : 5, WHADVP^g : 5, @NAC^g : 4, NAC^g : 4, SQ^g : 3, CONJP^g : 3, @CONJP^g : 2, WHPP^g : 2, TOP : 1, INTJ^g : 1, WHADJP^g : 1, @WHADJP^g : 1, SBARQ^g : 1]\n",
      "After merging in the 6th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -121010.12671869207\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120990.4529786629\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120971.79741975466\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120954.20468492326\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120937.21647107956\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120919.50093946268\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120900.25490264762\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120880.88721429752\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120863.49727499213\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120847.617568445\n",
      "Beginning iteration 10:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120834.54398168421\n",
      "Beginning iteration 11:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120823.1471791338\n",
      "Beginning iteration 12:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120812.70473612897\n",
      "Beginning iteration 13:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120802.14344367688\n",
      "Beginning iteration 14:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120791.47507730075\n",
      "Beginning iteration 15:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120780.81216106995\n",
      "Beginning iteration 16:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120768.81469332018\n",
      "Beginning iteration 17:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120754.69716109872\n",
      "Beginning iteration 18:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120741.29210617594\n",
      "Beginning iteration 19:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -120727.8367165519\n",
      "Saving grammar to ptb.gr_6_merging.gr.\n",
      "Saving successful.\n",
      "Setting smoother for grammar and lexicon.\n",
      "After smoothing in the 6th round, we get a validation likelihood of 0.0\n",
      "Beginning iteration 0:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122447.22771047217\n",
      "Beginning iteration 1:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122737.39807228501\n",
      "Beginning iteration 2:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122750.21691495964\n",
      "Beginning iteration 3:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122744.55279298732\n",
      "Beginning iteration 4:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122733.86655767306\n",
      "Beginning iteration 5:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122720.22623650914\n",
      "Beginning iteration 6:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122704.45409649142\n",
      "Beginning iteration 7:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122687.50372984768\n",
      "Beginning iteration 8:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122668.4631180062\n",
      "Beginning iteration 9:\n",
      "Calculating validation likelihood...done: 0.0\n",
      "Calculating training likelihood...done: -122646.85088507124\n",
      "Saving grammar to ptb.gr_6_smoothing.gr.\n",
      "Saving successful.\n",
      "Calculating last validation likelihood...done.\n",
      "  Iteration 10 (final) gives validation likelihood 0.0\n",
      "Saving grammar to ptb.gr.\n",
      "It gives a validation data log likelihood of: 0.0\n",
      "Saving successful.\n"
     ]
    }
   ],
   "source": [
    "!java -cp BerkeleyParser-1.7.jar edu.berkeley.nlp.PCFGLA.GrammarTrainer -path /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/02-21.10way_1K.clean -out ptb.gr -treebank SINGLEFILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe60e7-b6cf-4307-b989-0d4817086485",
   "metadata": {},
   "source": [
    "### PARSING \n",
    "We specify our newly generated grammar with \"-gr ptb.gr\" and parse the file \"23.auto.clean\" to output a parsed file called \"23.auto.clean.parsed\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7e7d74-f463-4fae-8a24-0ec13500a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -jar berkeleyParser-1.7.jar -gr ptb.gr < /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/23.auto.clean.txt > 23.auto.clean.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2ea6c-fde3-4dae-b9be-fe7a9dac6850",
   "metadata": {},
   "source": [
    "This is what the first few lines of ``23.auto.clean.txt`` (original text file we parsed) file looks like. Note that it's already been tokenized (broken down) for us (we can tell because contracted words are split into two parts, \"was\" + \"the clitic \"n't\", and punctuation is also separated by spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abccf2e-553b-473c-84b9-4d62912f5780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No , it was n't Black Monday . \n",
      "But while the New York Stock Exchange did n't fall apart Friday as the Dow Jones Industrial Average plunged 190.58 points -- most of it in the final hour -- it barely managed to stay this side of chaos . \n",
      "Some `` circuit breakers '' installed after the October 1987 crash failed their first test , traders say , unable to cool the selling panic in both stocks and futures . \n",
      "The 49 stock specialist firms on the Big Board floor -- the buyers and sellers of last resort who were criticized after the 1987 crash -- once again could n't handle the selling pressure . \n",
      "Big investment banks refused to step up to the plate to support the beleaguered floor traders by buying big blocks of stock , traders say . \n",
      "Heavy selling of Standard & Poor 's 500-stock index futures in Chicago relentlessly beat stocks downward . \n",
      "Seven Big Board stocks -- UAL , AMR , BankAmerica , Walt Disney , Capital Cities\\/ABC , Philip Morris and Pacific Telesis Group -- stopped trading and never resumed . \n",
      "The finger-pointing has already begun . \n",
      "`` The equity market was illiquid . \n",
      "Once again -LCB- the specialists -RCB- were not able to handle the imbalances on the floor of the New York Stock Exchange , '' said Christopher Pedersen , senior vice president at Twenty-First Securities Corp . \n"
     ]
    }
   ],
   "source": [
    "!head /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/23.auto.clean.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9306fb-da91-417c-b552-fa4b674f7c53",
   "metadata": {},
   "source": [
    "Here is an output of our newly parsed file ``23.auto.clean.parsed``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a44ef6c-efdf-4629-a226-27fd4848a81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( (S (ADVP (DT No)) (, ,) (NP (PRP it)) (VP (VBD was) (RB n't) (NP (NNP Black) (NNP Monday))) (. .)) )\n",
      "( (S (CC But) (SBAR (IN while) (S (NP (DT the) (NNP New) (NNP York) (NNP Stock) (NNP Exchange)) (VP (VBD did) (RB n't) (NP (NP (NN fall)) (ADVP (RB apart)) (VP (VP (VBN Friday) (PP (IN as) (NP (DT the) (NNP Dow) (NNP Jones) (NNP Industrial) (JJ Average) (JJ plunged) (CD 190.58) (NNS points)))) (PRN (: --) (NP (NP (JJS most)) (PP (IN of) (NP (PRP it))) (PP (IN in) (NP (DT the) (JJ final) (NN hour)))) (: --))))))) (S (NP (PRP it)) (ADVP (RB barely)) (VP (VBZ managed) (S (VP (TO to) (VP (VB stay) (NP (NP (DT this) (NN side)) (PP (IN of) (NP (NNS chaos))))))))) (. .)) )\n",
      "( (S (NP (NP (DT Some)) (SBAR (S (`` ``) (NP (NN circuit) (NNS breakers)) ('' '') (VP (VBD installed) (PP (IN after) (NP (DT the) (NNP October) (CD 1987) (NN crash))))))) (VP (VBD failed) (NP (PRP$ their) (JJ first) (NN test) (PRN (, ,) (S (NP (NNS traders)) (VP (VBP say))) (, ,)) (NN unable) (S (VP (TO to) (VP (VB cool) (NP (NP (DT the) (VBG selling) (NN panic)) (PP (IN in) (NP (DT both) (NNS stocks) (CC and) (NNS futures))))))))) (. .)) )\n",
      "( (S (NP (NP (DT The) (CD 49) (NN stock) (JJ specialist) (NN firms)) (PP (IN on) (NP (DT the) (NNP Big) (NNP Board)))) (VP (JJ floor) (PRN (: --) (NP (NP (DT the) (NNS buyers)) (CC and) (NP (NP (NNS sellers)) (PP (IN of) (NP (NP (JJ last) (NN resort)) (SBAR (WHNP (WP who)) (S (VP (VBD were) (VP (VBN criticized) (PP (IN after) (NP (DT the) (NN 1987) (NN crash))))))))))) (: --)) (ADVP (RB once)) (ADVP (RB again)) (VP (MD could) (RB n't) (VP (VB handle) (NP (DT the) (VBG selling) (NN pressure))))) (. .)) )\n",
      "( (S (S (NP (NNP Big) (NN investment) (NNS banks)) (VP (VBD refused) (S (VP (TO to) (VP (VB step) (PRT (RP up)) (PP (TO to) (NP (NP (DT the) (NN plate)) (SBAR (S (VP (TO to) (VP (VB support) (NP (DT the) (JJ beleaguered) (NN floor) (NNS traders)) (PP (IN by) (S (VP (VBG buying) (NP (NP (JJ big) (NNS blocks)) (PP (IN of) (NP (NN stock)))))))))))))))))) (, ,) (NP (NNS traders)) (VP (VBP say)) (. .)) )\n",
      "( (S (ADVP (RB Heavy)) (NP (NP (NN selling)) (PP (IN of) (NP (NNP Standard) (CC &) (NNP Poor)))) (VP (VBZ 's) (NP (NP (JJ 500-stock) (NN index) (NNS futures)) (PP (IN in) (NP (NNP Chicago) (JJ relentlessly) (NN beat) (NNS stocks) (NN downward))))) (. .)) )\n",
      "(())\n",
      "( (S (NP (DT The) (NN finger-pointing)) (VP (VBZ has) (ADVP (RB already)) (VP (VBN begun))) (. .)) )\n",
      "( (S (`` ``) (NP (DT The) (NN equity) (NN market)) (VP (VBD was) (VP (VBN illiquid))) (. .)) )\n",
      "( (SINV (S (NP (NP (NN Once) (RB again)) (PRN (-LRB- -LCB-) (NP (DT the) (NNS specialists)) (-RRB- -RCB-))) (VP (VBD were) (RB not) (ADJP (JJ able) (S (VP (TO to) (VP (VB handle) (NP (NP (DT the) (NNS imbalances)) (PP (IN on) (NP (NP (DT the) (NN floor)) (PP (IN of) (NP (DT the) (NNP New) (NNP York) (NNP Stock) (NNP Exchange)))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Christopher) (NNP Pedersen)) (, ,) (NP (NP (JJ senior) (NN vice) (NN president)) (PP (IN at) (NP (NNP Twenty-First) (NNP Securities) (NNP Corp))))) (. .)) )\n"
     ]
    }
   ],
   "source": [
    "!head /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/berkeleyparser/23.auto.clean.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05bd7b-0e75-458a-a8c6-0bf3f52cb8af",
   "metadata": {},
   "source": [
    "### EVALUATION\n",
    "We use EVALB to evaluate see how accurate the bracketing in our test file (what we just parsed) to a gold file (a file that has all the correct answers). \n",
    "\n",
    "EVALB returns recall, precision, and tagging accuracy.\n",
    "\n",
    "**Recall**: What proportion of actual positives was identified correctly?\n",
    "\n",
    "**Precision**: What proportion of positive identifications was actually correct?\n",
    "\n",
    "**Fmeasure**: Calculated using the results of precison and recall. \n",
    "\n",
    "Download EVALB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ddb3f0e-b833-4202-b3bd-6a317e9ff812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-14 16:42:28--  https://nlp.cs.nyu.edu/evalb/EVALB.tgz\n",
      "Resolving nlp.cs.nyu.edu (nlp.cs.nyu.edu)... 216.165.22.203\n",
      "Connecting to nlp.cs.nyu.edu (nlp.cs.nyu.edu)|216.165.22.203|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 38394 (37K) [application/x-gzip]\n",
      "Saving to: EVALB.tgz\n",
      "\n",
      "EVALB.tgz           100%[===================>]  37.49K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-10-14 16:42:29 (304 KB/s) - EVALB.tgz saved [38394/38394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nlp.cs.nyu.edu/evalb/EVALB.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65628cc-bc4f-4f0a-a396-a6e4a86e2373",
   "metadata": {},
   "source": [
    "Like when downloading Berkeley Parser, open the tarball to get the files from what we just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b94a2bf-095e-4742-ab47-54c6276c4aef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x EVALB/\n",
      "x EVALB/sample/\n",
      "x EVALB/sample/sample.prm\n",
      "x EVALB/sample/sample.gld\n",
      "x EVALB/sample/sample.tst\n",
      "x EVALB/sample/sample.rsl\n",
      "x EVALB/Makefile\n",
      "x EVALB/README\n",
      "x EVALB/evalb\n",
      "x EVALB/tgrep_proc.prl\n",
      "x EVALB/LICENSE\n",
      "x EVALB/new.prm\n",
      "x EVALB/bug/\n",
      "x EVALB/bug/bug.tst\n",
      "x EVALB/bug/bug.rsl-new\n",
      "x EVALB/bug/bug.rsl-old\n",
      "x EVALB/bug/bug.gld\n",
      "x EVALB/evalb.c\n",
      "x EVALB/COLLINS.prm\n"
     ]
    }
   ],
   "source": [
    "!tar xvfz EVALB.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b5376-9472-4633-b98d-f841f2af726c",
   "metadata": {},
   "source": [
    "``cd`` into EVALB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b8a14d8-0e8e-49eb-ae88-1d4e0495ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/berkeleyparser/EVALB\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/berkeleyparser/EVALB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48336e-5445-4688-98df-b417bf43a5f1",
   "metadata": {},
   "source": [
    "Download our gold file called ``23.auto.clean``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "031b5e33-1162-4f25-86f3-6de93fe2fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-15 09:46:01--  https://raw.githubusercontent.com/jhcross/span-parser/master/data/23.auto.clean\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 845041 (825K) [text/plain]\n",
      "Saving to: 23.auto.clean\n",
      "\n",
      "23.auto.clean       100%[===================>] 825.24K  --.-KB/s    in 0.09s   \n",
      "\n",
      "2021-10-15 09:46:02 (9.39 MB/s) - 23.auto.clean saved [845041/845041]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/jhcross/span-parser/master/data/23.auto.clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee69d4f-ded2-431e-bba9-271d74c8897b",
   "metadata": {},
   "source": [
    "### EVALB scorer format:\n",
    "\n",
    "_evalb -p Parameter_file Gold_file Test_file_\n",
    "\n",
    "**gold file:**\n",
    "23.auto.clean \n",
    "\n",
    "**test file:** \n",
    "23.auto.clean.parsed\n",
    "\n",
    "Using EVALB, and specifying the parameter (``-p``) as COLLINS.prm (the parameter sets options regarding the scoring method based on Collins (1997):\n",
    "- make sure a constituent has the same span and label as the constituent in the gold file\n",
    "- don't include the label on the top (the highest label)\n",
    "- remove unneeded information logged/written into the trees called 'traces'\n",
    "- remove certain punctuation\n",
    "- don't include traces when calculating the length of a sentence)\n",
    "\n",
    "Evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53ce34a-0718-47ed-adc1-2f68bc82099f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sent.                        Matched  Bracket   Cross        Correct Tag\n",
      " ID  Len.  Stat. Recal  Prec.  Bracket gold test Bracket Words  Tags Accracy\n",
      "============================================================================\n",
      "   1    8    0   80.00  66.67     4      5    6      0      8     7    87.50\n",
      "   2   40    0   74.19  74.19    23     31   31      3     40    34    85.00\n",
      "   3   31    0   80.95  73.91    17     21   23      2     31    28    90.32\n",
      "   4   35    0   66.67  51.85    14     21   27      5     35    30    85.71\n",
      "   5   26    0   91.30  80.77    21     23   26      2     26    24    92.31\n",
      "   6   17    0    8.33   8.33     1     12   12      6     17    12    70.59\n",
      "   7   30    2    0.00   0.00     0      0    0      0      0     0     0.00\n",
      "   8    6    0  100.00  83.33     5      5    6      0      6     5    83.33\n",
      "   9    7    0   75.00  60.00     3      4    5      0      7     6    85.71\n",
      "  10   36    0   95.65  84.62    22     23   26      0     36    35    97.22\n",
      "  11   25    0   63.64  60.87    14     22   23      1     25    24    96.00\n",
      "  12   16    0   91.67  73.33    11     12   15      1     16    16   100.00\n",
      "  13   17    0   87.50  73.68    14     16   19      1     17    15    88.24\n",
      "  14   28    0   87.50  63.64    14     16   22      1     28    26    92.86\n",
      "  15   42    0   44.44  41.38    12     27   29     10     42    39    92.86\n",
      "  16   15    0   81.82  81.82     9     11   11      1     15    14    93.33\n",
      "  17   13    0  100.00  83.33    10     10   12      0     13    13   100.00\n",
      "  18    8    0  100.00  83.33     5      5    6      0      8     8   100.00\n",
      "  19   23    0   87.50  77.78    14     16   18      1     23    23   100.00\n",
      "  20   33    0   82.61  82.61    19     23   23      0     33    31    93.94\n",
      "  21    9    0  100.00  75.00     6      6    8      0      9     9   100.00\n",
      "  22   37    0   82.14  82.14    23     28   28      1     37    31    83.78\n",
      "  23   28    0   80.00  72.73    16     20   22      2     28    25    89.29\n",
      "  24   24    0   80.00  70.59    12     15   17      0     24    21    87.50\n",
      "  25   26    0   38.89  35.00     7     18   20      3     26    20    76.92\n",
      "  26   13    0   84.62  78.57    11     13   14      0     13    13   100.00\n",
      "  27   28    0   54.55  66.67    12     22   18      2     28    22    78.57\n",
      "  28   22    0   66.67  58.82    10     15   17      0     22    20    90.91\n",
      "  29   12    0   62.50  55.56     5      8    9      1     12    11    91.67\n",
      "  30    4    0  100.00  75.00     3      3    4      0      4     4   100.00\n",
      "  31   22    0   77.78  73.68    14     18   19      1     22    19    86.36\n",
      "  32   47    0   54.35  65.79    25     46   38      5     47    40    85.11\n",
      "  33    5    0   75.00  60.00     3      4    5      0      5     5   100.00\n",
      "  34   24    0   80.00  84.21    16     20   19      0     24    22    91.67\n",
      "  35   28    0   77.78  80.77    21     27   26      1     28    25    89.29\n",
      "  36   24    0  100.00  95.83    23     23   24      0     24    17    70.83\n",
      "  37   17    0   72.73  61.54     8     11   13      1     17    16    94.12\n",
      "  38   17    0   76.92  66.67    10     13   15      2     17    17   100.00\n",
      "  39   38    0   60.00  57.69    15     25   26      5     38    32    84.21\n",
      "  40   21    0   93.33  87.50    14     15   16      0     21    20    95.24\n",
      "  41   33    0   67.74  72.41    21     31   29      4     33    27    81.82\n",
      "  42   15    0   66.67  46.15     6      9   13      2     15    15   100.00\n",
      "  43   34    0   48.39  55.56    15     31   27     10     34    30    88.24\n",
      "  44   12    0   71.43  55.56     5      7    9      1     12    11    91.67\n",
      "  45   12    0   87.50  77.78     7      8    9      0     12     9    75.00\n",
      "  46   36    0   64.00  53.33    16     25   30      7     36    35    97.22\n",
      "  47   30    0   90.00  81.82    18     20   22      0     30    26    86.67\n",
      "  48   31    0   84.62  81.48    22     26   27      1     31    28    90.32\n",
      "  49   18    0   55.56  55.56    10     18   18      6     18    18   100.00\n",
      "  50    5    0   60.00  60.00     3      5    5      0      5     4    80.00\n",
      "  51   15    0  100.00  90.00     9      9   10      0     15    14    93.33\n",
      "  52   22    0   75.00  64.29     9     12   14      1     22    19    86.36\n",
      "  53   26    0   84.21  88.89    16     19   18      0     26    20    76.92\n",
      "  54   16    0   40.00  36.36     4     10   11      1     16    14    87.50\n",
      "  55   25    0   58.33  50.00    14     24   28      7     25    22    88.00\n",
      "  56   48    0   84.62  70.97    22     26   31      2     48    46    95.83\n",
      "  57   28    0   79.17  86.36    19     24   22      1     28    28   100.00\n",
      "  58   28    0   68.42  54.17    13     19   24      2     28    24    85.71\n",
      "  59    8    0   83.33  71.43     5      6    7      0      8     5    62.50\n",
      "  60   23    0   84.21  84.21    16     19   19      1     23    19    82.61\n",
      "  61   24    0   47.37  40.91     9     19   22      3     24    21    87.50\n",
      "  62   18    0   76.47  76.47    13     17   17      1     18    17    94.44\n",
      "  63   18    0   86.67  86.67    13     15   15      0     18    17    94.44\n",
      "  64   25    0   90.91  86.96    20     22   23      1     25    25   100.00\n",
      "  65   34    0   84.62  73.33    22     26   30      3     34    32    94.12\n",
      "  66   19    0   68.75  64.71    11     16   17      2     19    14    73.68\n",
      "  67   27    0   36.00  36.00     9     25   25     10     27    25    92.59\n",
      "  68   28    0   47.06  47.06     8     17   17      2     28    25    89.29\n",
      "  69   34    0   80.77  77.78    21     26   27      3     34    33    97.06\n",
      "  70   38    0   80.65  83.33    25     31   30      1     38    35    92.11\n",
      "  71   13    0  100.00  92.86    13     13   14      0     13    13   100.00\n",
      "  72   14    0   81.82  69.23     9     11   13      1     14    13    92.86\n",
      "  73   23    0   38.46  38.46     5     13   13      2     23    20    86.96\n",
      "  74   28    0   86.96  80.00    20     23   25      2     28    28   100.00\n",
      "  75    6    0  100.00  80.00     4      4    5      0      6     6   100.00\n",
      "  76   26    0   59.09  54.17    13     22   24      6     26    21    80.77\n",
      "  77   16    0   71.43  76.92    10     14   13      1     16    11    68.75\n",
      "  78   33    0   73.53  73.53    25     34   34      6     33    29    87.88\n",
      "  79   14    0   72.73  66.67     8     11   12      0     14    11    78.57\n",
      "  80   26    0   63.16  70.59    12     19   17      1     26    23    88.46\n",
      "  81   16    0  100.00  90.00     9      9   10      0     16    15    93.75\n",
      "  82   16    0   63.64  63.64     7     11   11      2     16    16   100.00\n",
      "  83   25    0   84.00  84.00    21     25   25      1     25    21    84.00\n",
      "  84   20    0    7.14   6.67     1     14   15      3     20    14    70.00\n",
      "  85   41    0   90.32  80.00    28     31   35      1     41    35    85.37\n",
      "  86   22    0   60.00  57.14    12     20   21      0     22    20    90.91\n",
      "  87   26    0   84.21  80.00    16     19   20      0     26    25    96.15\n",
      "  88   30    0   50.00  45.00     9     18   20      2     30    26    86.67\n",
      "  89    8    0   90.91  83.33    10     11   12      0      8     6    75.00\n",
      "  90    2    0  100.00  50.00     1      1    2      0      2     2   100.00\n",
      "  91   19    0   84.21  76.19    16     19   21      2     19    17    89.47\n",
      "  92   25    0   73.91  68.00    17     23   25      5     25    23    92.00\n",
      "  93   33    0   89.29  89.29    25     28   28      1     33    31    93.94\n",
      "  94   20    0   73.33  57.89    11     15   19      3     20    17    85.00\n",
      "  95   32    0   95.83  82.14    23     24   28      1     32    31    96.88\n",
      "  96   28    0   90.91  83.33    20     22   24      1     28    27    96.43\n",
      "  97   32    0  100.00  95.45    21     21   22      0     32    31    96.88\n",
      "  98   33    0   61.54  61.54    16     26   26      8     33    30    90.91\n",
      "  99   33    0   86.96  83.33    20     23   24      2     33    31    93.94\n",
      " 100    9    0   71.43  55.56     5      7    9      1      9     9   100.00\n",
      " 101    8    0   50.00  33.33     3      6    9      3      8     7    87.50\n",
      " 102   23    0   88.89  88.89    16     18   18      1     23    21    91.30\n",
      " 103   21    0   80.00  75.00    12     15   16      2     21    19    90.48\n",
      " 104   39    0   84.85  73.68    28     33   38      5     39    36    92.31\n",
      " 105   26    0   80.95  80.95    17     21   21      2     26    25    96.15\n",
      " 106   20    0   54.55  50.00     6     11   12      0     20    19    95.00\n",
      " 107   37    0   90.00  81.82    18     20   22      3     37    34    91.89\n",
      " 108   25    0   84.21  84.21    16     19   19      1     25    22    88.00\n",
      " 109   53    0   76.47  70.27    26     34   37      5     53    47    88.68\n",
      " 110   23    0  100.00  94.74    18     18   19      0     23    23   100.00\n",
      " 111   34    0   88.00  81.48    22     25   27      3     34    34   100.00\n",
      " 112   11    0   85.71  66.67     6      7    9      0     11    10    90.91\n",
      " 113   46    0   74.36  76.32    29     39   38      5     46    43    93.48\n",
      " 114   24    0   78.26  85.71    18     23   21      2     24    22    91.67\n",
      " 115   27    0   68.18  65.22    15     22   23      3     27    24    88.89\n",
      " 116   55    0   69.70  69.70    23     33   33      8     55    53    96.36\n",
      " 117   26    0   90.91  86.96    20     22   23      1     26    23    88.46\n",
      " 118   31    0   77.27  73.91    17     22   23      0     31    28    90.32\n",
      " 119   26    0   81.82  90.00    18     22   20      0     26    26   100.00\n",
      " 120   14    0   80.00  72.73     8     10   11      0     14    14   100.00\n",
      " 121   21    0   89.47  85.00    17     19   20      0     21    19    90.48\n",
      " 122   21    0   66.67  60.00    12     18   20      4     21    19    90.48\n",
      " 123   17    0   54.55  75.00     6     11    8      0     17    15    88.24\n",
      " 124   36    0   90.91  86.96    20     22   23      1     36    32    88.89\n",
      " 125   15    0  100.00  83.33    10     10   12      0     15    13    86.67\n",
      " 126   17    0  100.00  83.33    10     10   12      0     17    16    94.12\n",
      " 127   30    0   57.69  53.57    15     26   28      7     30    28    93.33\n",
      " 128   15    0   81.82  81.82     9     11   11      0     15    14    93.33\n",
      " 129   11    0  100.00  90.91    10     10   11      0     11    11   100.00\n",
      " 130   20    0   76.92  71.43    10     13   14      1     20    19    95.00\n",
      " 131   31    0   84.00  80.77    21     25   26      3     31    30    96.77\n",
      " 132   17    0  100.00  91.67    11     11   12      0     17    16    94.12\n",
      " 133   19    0   93.75  88.24    15     16   17      0     19    17    89.47\n",
      " 134   35    0   44.00  47.83    11     25   23      5     35    31    88.57\n",
      " 135   18    0   85.71  85.71    12     14   14      1     18    16    88.89\n",
      " 136   28    0   94.74  94.74    18     19   19      0     28    27    96.43\n",
      " 137   36    0   85.19  88.46    23     27   26      1     36    30    83.33\n",
      " 138    9    0   66.67  50.00     4      6    8      0      9     9   100.00\n",
      " 139    6    0   75.00  60.00     3      4    5      0      6     5    83.33\n",
      " 140    6    0  100.00  83.33     5      5    6      0      6     6   100.00\n",
      " 141   14    0   70.00  46.67     7     10   15      0     14    13    92.86\n",
      " 142   25    0   85.71  78.26    18     21   23      3     25    25   100.00\n",
      " 143   21    0   62.50  55.56    10     16   18      3     21    19    90.48\n",
      " 144    8    0   87.50  77.78     7      8    9      0      8     7    87.50\n",
      " 145   16    0   71.43  66.67    10     14   15      2     16    14    87.50\n",
      " 146   19    0   73.33  61.11    11     15   18      1     19    18    94.74\n",
      " 147   32    0   64.71  52.38    11     17   21      3     32    32   100.00\n",
      " 148   32    0   85.71  81.82    18     21   22      1     32    31    96.88\n",
      " 149   26    0   75.00  68.18    15     20   22      3     26    26   100.00\n",
      " 150   26    0   50.00  53.57    15     30   28      8     26    23    88.46\n",
      " 151   11    0   50.00  44.44     4      8    9      1     11    11   100.00\n",
      " 152   27    0   57.89  52.38    11     19   21      7     27    25    92.59\n",
      " 153   19    0  100.00  93.75    15     15   16      0     19    19   100.00\n",
      " 154   16    0   92.86  86.67    13     14   15      0     16    16   100.00\n",
      " 155   19    0   64.29  64.29     9     14   14      1     19    16    84.21\n",
      " 156   20    0   82.35  70.00    14     17   20      2     20    20   100.00\n",
      " 157   22    0  100.00  83.33    15     15   18      0     22    20    90.91\n",
      " 158   30    0   87.50  77.78    14     16   18      0     30    27    90.00\n",
      " 159   12    0   61.54  66.67     8     13   12      0     12    11    91.67\n",
      " 160   27    0   47.37  50.00     9     19   18      5     27    27   100.00\n",
      " 161   29    0   68.00  58.62    17     25   29      3     29    25    86.21\n",
      " 162   21    0  100.00  93.33    14     14   15      0     21    20    95.24\n",
      " 163   21    0   78.95  68.18    15     19   22      1     21    20    95.24\n",
      " 164   28    0   90.00  84.38    27     30   32      0     28    25    89.29\n",
      " 165   16    0   63.64  53.85     7     11   13      3     16    11    68.75\n",
      " 166   11    0   85.71  75.00     6      7    8      0     11    10    90.91\n",
      " 167    9    0   50.00  33.33     4      8   12      1      9     7    77.78\n",
      " 168   10    0  100.00  85.71     6      6    7      0     10    10   100.00\n",
      " 169   20    0   83.33  83.33    15     18   18      1     20    18    90.00\n",
      " 170   13    0  100.00  81.82     9      9   11      0     13    11    84.62\n",
      " 171    9    0   85.71  75.00     6      7    8      0      9     9   100.00\n",
      " 172   20    0   75.00  64.29     9     12   14      2     20    19    95.00\n",
      " 173   16    0  100.00  92.86    13     13   14      0     16    15    93.75\n",
      " 174   16    0  100.00  85.71    12     12   14      0     16    16   100.00\n",
      " 175   27    0   64.71  61.11    11     17   18      4     27    26    96.30\n",
      " 176   21    0   68.42  56.52    13     19   23      6     21    21   100.00\n",
      " 177   19    0   92.31  75.00    12     13   16      1     19    18    94.74\n",
      " 178   32    0   85.71  78.26    18     21   23      0     32    30    93.75\n",
      " 179   10    0  100.00  75.00     6      6    8      0     10    10   100.00\n",
      " 180   13    0   50.00  55.56     5     10    9      1     13    13   100.00\n",
      " 181   23    0   86.36  79.17    19     22   24      1     23    19    82.61\n",
      " 182   20    0   84.62  68.75    11     13   16      2     20    18    90.00\n",
      " 183   37    0   79.17  67.86    19     24   28      3     37    34    91.89\n",
      " 184   30    0   60.00  50.00    15     25   30      7     30    30   100.00\n",
      " 185   12    0  100.00  87.50     7      7    8      0     12    11    91.67\n",
      " 186   18    0   81.25  72.22    13     16   18      2     18    16    88.89\n",
      " 187   29    0   89.29  80.65    25     28   31      2     29    27    93.10\n",
      " 188   17    0   80.00  80.00    12     15   15      0     17    16    94.12\n",
      " 189   21    0   88.24  83.33    15     17   18      1     21    20    95.24\n",
      " 190   26    0   80.00  69.57    16     20   23      0     26    25    96.15\n",
      " 191   43    0   91.67  81.48    22     24   27      2     43    43   100.00\n",
      " 192   15    0  100.00  91.67    11     11   12      0     15    14    93.33\n",
      " 193   31    0   59.26  53.33    16     27   30      9     31    31   100.00\n",
      " 194   17    0   87.50  93.33    14     16   15      0     17    17   100.00\n",
      " 195   41    0   88.57  86.11    31     35   36      2     41    39    95.12\n",
      " 196   42    0   72.22  68.42    26     36   38      8     42    40    95.24\n",
      " 197   66    0   87.04  82.46    47     54   57      3     66    65    98.48\n",
      " 198   55    0   41.82  44.23    23     55   52     25     55    53    96.36\n",
      " 199   12    0   50.00  50.00     5     10   10      1     12    12   100.00\n",
      " 200   23    0   52.94  40.91     9     17   22      8     23    21    91.30\n",
      " 201   11    0   88.89  66.67     8      9   12      0     11    11   100.00\n",
      " 202   39    0   71.43  74.07    20     28   27      2     39    38    97.44\n",
      " 203   26    0   71.43  75.00    15     21   20      3     26    25    96.15\n",
      " 204   15    0   92.86  81.25    13     14   16      0     15    13    86.67\n",
      " 205   36    0   81.48  81.48    22     27   27      2     36    32    88.89\n",
      " 206   14    0   90.91  76.92    10     11   13      0     14    13    92.86\n",
      " 207   29    0   59.09  56.52    13     22   23      6     29    24    82.76\n",
      " 208   34    0   76.92  80.00    20     26   25      2     34    31    91.18\n",
      " 209   25    0   77.27  85.00    17     22   20      0     25    23    92.00\n",
      " 210   24    0   86.36  90.48    19     22   21      1     24    22    91.67\n",
      " 211   25    0   50.00  57.89    11     22   19      4     25    23    92.00\n",
      " 212   22    0   90.48  79.17    19     21   24      2     22    18    81.82\n",
      " 213   27    0   58.33  63.64    14     24   22      6     27    24    88.89\n",
      " 214   37    0   61.11  62.86    22     36   35      9     37    36    97.30\n",
      " 215   40    0   82.76  66.67    24     29   36      3     40    36    90.00\n",
      " 216   29    0   91.67  88.00    22     24   25      0     29    27    93.10\n",
      " 217   14    0   78.57  84.62    11     14   13      0     14    13    92.86\n",
      " 218   37    0   88.10  86.05    37     42   43      5     37    36    97.30\n",
      " 219   14    0  100.00  80.00     8      8   10      0     14    12    85.71\n",
      " 220   32    0   68.00  68.00    17     25   25      4     32    29    90.62\n",
      " 221   45    0   75.00  68.57    24     32   35      4     45    43    95.56\n",
      " 222   22    0   80.00  75.00    12     15   16      1     22    21    95.45\n",
      " 223   36    0   57.14  58.82    20     35   34     10     36    35    97.22\n",
      " 224   16    0   87.50  82.35    14     16   17      0     16    15    93.75\n",
      " 225   12    0   62.50  55.56     5      8    9      0     12    10    83.33\n",
      " 226   40    0   61.90  52.00    13     21   25      7     40    39    97.50\n",
      " 227   33    0   47.62  45.45    10     21   22      8     33    31    93.94\n",
      " 228   24    0   63.64  63.64    14     22   22      4     24    23    95.83\n",
      " 229   24    0   56.25  56.25     9     16   16      4     24    21    87.50\n",
      " 230   13    0   70.00  63.64     7     10   11      1     13    12    92.31\n",
      " 231   18    0   86.67  72.22    13     15   18      2     18    16    88.89\n",
      " 232   46    0   82.50  78.57    33     40   42      3     46    43    93.48\n",
      " 233    5    0  100.00  80.00     4      4    5      0      5     5   100.00\n",
      " 234   29    0   87.50  80.77    21     24   26      2     29    24    82.76\n",
      " 235   21    0   83.33  76.92    10     12   13      0     21    20    95.24\n",
      " 236   11    0  100.00  87.50     7      7    8      0     11    10    90.91\n",
      " 237    7    0  100.00  85.71     6      6    7      0      7     7   100.00\n",
      " 238   30    0   81.82  75.00    18     22   24      2     30    28    93.33\n",
      " 239    7    0  100.00  83.33     5      5    6      0      7     7   100.00\n",
      " 240   35    0   69.23  69.23    18     26   26      3     35    29    82.86\n",
      " 241   59    0   65.12  62.22    28     43   45      8     59    57    96.61\n",
      " 242    6    0  100.00  80.00     4      4    5      0      6     6   100.00\n",
      " 243   13    0   88.89  88.89     8      9    9      0     13    12    92.31\n",
      " 244   24    0   88.24  78.95    15     17   19      1     24    23    95.83\n",
      " 245   21    0   86.67  86.67    13     15   15      0     21    20    95.24\n",
      " 246   16    0   72.73  66.67     8     11   12      1     16    15    93.75\n",
      " 247   46    0   78.38  78.38    29     37   37      0     46    42    91.30\n",
      " 248   32    0   54.17  50.00    13     24   26      7     32    28    87.50\n",
      " 249   29    0   75.00  68.18    15     20   22      4     29    26    89.66\n",
      " 250   31    0   65.38  56.67    17     26   30     10     31    31   100.00\n",
      " 251   30    0   77.27  73.91    17     22   23      3     30    28    93.33\n",
      " 252   31    0   72.41  72.41    21     29   29      2     31    27    87.10\n",
      " 253   33    0   82.14  82.14    23     28   28      3     33    33   100.00\n",
      " 254   20    0   68.75  73.33    11     16   15      3     20    19    95.00\n",
      " 255   42    0   77.78  77.78    21     27   27      2     42    41    97.62\n",
      " 256   34    0   58.62  58.62    17     29   29      7     34    31    91.18\n",
      " 257   27    0   95.24  86.96    20     21   23      2     27    27   100.00\n",
      " 258   37    0   90.91  86.96    20     22   23      2     37    36    97.30\n",
      " 259   18    0   84.21  80.00    16     19   20      0     18    17    94.44\n",
      " 260   14    0   75.00  75.00     9     12   12      2     14    12    85.71\n",
      " 261   13    0   57.14  40.00     4      7   10      2     13    11    84.62\n",
      " 262   12    0   90.91  76.92    10     11   13      0     12    11    91.67\n",
      " 263   28    0   59.09  50.00    13     22   26      8     28    26    92.86\n",
      " 264   15    0  100.00  83.33    10     10   12      0     15    14    93.33\n",
      " 265   22    0   76.92  71.43    10     13   14      2     22    21    95.45\n",
      " 266   25    0   81.82  81.82    18     22   22      2     25    24    96.00\n",
      " 267   55    0   84.85  82.35    28     33   34      4     55    53    96.36\n",
      " 268   16    0  100.00  90.00     9      9   10      0     16    16   100.00\n",
      " 269   36    0   65.62  63.64    21     32   33     10     36    34    94.44\n",
      " 270   51    0   83.33  77.78    35     42   45      7     51    50    98.04\n",
      " 271   21    0   65.22  60.00    15     23   25      4     21    19    90.48\n",
      " 272   38    0   68.75  73.33    22     32   30      4     38    33    86.84\n",
      " 273   10    0   83.33  71.43     5      6    7      0     10     8    80.00\n",
      " 274   36    0   73.08  76.00    19     26   25      0     36    31    86.11\n",
      " 275   29    0   80.95  77.27    17     21   22      3     29    26    89.66\n",
      " 276   31    0   75.86  78.57    22     29   28      4     31    31   100.00\n",
      " 277   19    0  100.00  94.44    17     17   18      0     19    18    94.74\n",
      " 278   32    0   65.52  65.52    19     29   29      2     32    31    96.88\n",
      " 279   17    0   64.29  69.23     9     14   13      1     17    15    88.24\n",
      " 280   22    0   40.00  50.00     8     20   16      2     22    18    81.82\n",
      " 281   12    0   81.82  75.00     9     11   12      0     12    11    91.67\n",
      " 282   41    0   59.38  54.29    19     32   35     10     41    40    97.56\n",
      " 283   34    0   59.09  65.00    13     22   20      3     34    32    94.12\n",
      " 284   24    0   52.17  44.44    12     23   27      9     24    22    91.67\n",
      " 285   22    0   50.00  52.63    10     20   19      3     22    18    81.82\n",
      " 286   14    0   75.00  69.23     9     12   13      2     14    11    78.57\n",
      " 287   21    0   76.19  76.19    16     21   21      2     21    18    85.71\n",
      " 288   20    0   86.67  86.67    13     15   15      0     20    17    85.00\n",
      " 289   12    0  100.00  90.00     9      9   10      0     12    12   100.00\n",
      " 290   23    0  100.00  95.24    20     20   21      0     23    23   100.00\n",
      " 291   37    0   84.00  77.78    21     25   27      2     37    35    94.59\n",
      " 292   46    0   80.00  77.78    28     35   36      5     46    44    95.65\n",
      " 293   30    0   45.45  43.48    10     22   23      7     30    26    86.67\n",
      " 294   17    0   70.00  70.00     7     10   10      1     17    15    88.24\n",
      " 295   31    0   55.56  50.00    10     18   20      2     31    27    87.10\n",
      " 296   31    0   57.69  60.00    15     26   25      7     31    25    80.65\n",
      " 297   22    0   76.47  68.42    13     17   19      2     22    21    95.45\n",
      " 298   27    0   70.00  66.67    14     20   21      3     27    25    92.59\n",
      " 299   21    0   71.43  58.82    10     14   17      2     21    18    85.71\n",
      " 300   19    0   78.57  68.75    11     14   16      2     19    17    89.47\n",
      " 301   22    0  100.00  94.12    16     16   17      0     22    22   100.00\n",
      " 302   16    0   94.12  88.89    16     17   18      0     16    15    93.75\n",
      " 303   33    0   74.19  74.19    23     31   31      2     33    30    90.91\n",
      " 304   30    0   83.33  78.12    25     30   32      3     30    29    96.67\n",
      " 305   11    0   66.67  66.67     6      9    9      1     11    10    90.91\n",
      " 306    8    0  100.00  90.91    10     10   11      0      8     7    87.50\n",
      " 307   19    0   64.71  64.71    11     17   17      3     19    19   100.00\n",
      " 308   21    0   68.75  64.71    11     16   17      1     21    19    90.48\n",
      " 309   20    0   92.86  86.67    13     14   15      1     20    19    95.00\n",
      " 310   20    0   71.43  75.00    15     21   20      2     20    19    95.00\n",
      " 311    4    0   75.00  60.00     3      4    5      0      4     3    75.00\n",
      " 312    5    0   75.00  60.00     3      4    5      0      5     4    80.00\n",
      " 313   20    0   66.67  60.87    14     21   23      5     20    18    90.00\n",
      " 314   14    0   81.82  69.23     9     11   13      0     14    12    85.71\n",
      " 315   19    0   85.71  80.00    12     14   15      0     19    18    94.74\n",
      " 316   42    0   51.85  42.42    14     27   33     11     42    35    83.33\n",
      " 317   32    0   73.91  70.83    17     23   24      5     32    32   100.00\n",
      " 318   14    0   45.45  45.45     5     11   11      2     14    13    92.86\n",
      " 319   52    0   57.50  56.10    23     40   41     14     52    48    92.31\n",
      " 320   23    0   57.14  63.16    12     21   19      2     23    19    82.61\n",
      " 321   16    0   76.47  76.47    13     17   17      0     16    14    87.50\n",
      " 322   25    0   81.25  72.22    13     16   18      1     25    25   100.00\n",
      " 323   18    0   84.21  94.12    16     19   17      0     18    17    94.44\n",
      " 324   27    0   88.00  91.67    22     25   24      1     27    27   100.00\n",
      " 325    6    0   33.33  25.00     1      3    4      0      6     5    83.33\n",
      " 326   10    0  100.00  90.00     9      9   10      0     10     8    80.00\n",
      " 327   18    0   84.62  78.57    11     13   14      1     18    17    94.44\n",
      " 328   20    0   69.23  69.23     9     13   13      2     20    18    90.00\n",
      " 329   17    0  100.00  84.62    11     11   13      0     17    16    94.12\n",
      " 330   25    0   45.83  45.83    11     24   24      9     25    20    80.00\n",
      " 331   20    0   52.94  50.00     9     17   18      0     20    14    70.00\n",
      " 332   43    0   97.30  92.31    36     37   39      1     43    42    97.67\n",
      " 333   10    0   71.43  55.56     5      7    9      0     10     8    80.00\n",
      " 334   24    0   61.90  65.00    13     21   20      4     24    23    95.83\n",
      " 335   23    0   80.00  66.67    12     15   18      1     23    19    82.61\n",
      " 336    7    0  100.00  85.71     6      6    7      0      7     6    85.71\n",
      " 337   24    0   78.95  78.95    15     19   19      2     24    22    91.67\n",
      " 338   17    0  100.00  91.67    11     11   12      0     17    16    94.12\n",
      " 339   17    0   42.86  50.00     6     14   12      3     17    16    94.12\n",
      " 340   30    0   65.22  65.22    15     23   23      6     30    30   100.00\n",
      " 341   10    0  100.00  87.50     7      7    8      0     10    10   100.00\n",
      " 342   12    0  100.00  81.82     9      9   11      0     12    11    91.67\n",
      " 343   12    0   41.67  33.33     5     12   15      6     12    11    91.67\n",
      " 344   12    0   60.00  60.00     6     10   10      2     12    11    91.67\n",
      " 345   22    0   85.71  90.00    18     21   20      1     22    19    86.36\n",
      " 346   34    0   56.25  60.00    18     32   30      6     34    30    88.24\n",
      " 347   32    0   68.00  62.96    17     25   27      5     32    32   100.00\n",
      " 348   55    0   68.75  61.11    22     32   36      4     55    50    90.91\n",
      " 349   22    0   86.67  81.25    13     15   16      1     22    21    95.45\n",
      " 350   44    0   91.67  84.62    33     36   39      2     44    39    88.64\n",
      " 351   30    0   91.67  95.65    22     24   23      0     30    28    93.33\n",
      " 352   28    0   76.47  72.22    13     17   18      2     28    25    89.29\n",
      " 353   32    0   83.33  76.92    20     24   26      2     32    29    90.62\n",
      " 354   30    0   92.86  86.67    26     28   30      2     30    30   100.00\n",
      " 355   25    0   80.00  66.67    16     20   24      2     25    23    92.00\n",
      " 356   35    0   92.86  81.25    26     28   32      1     35    33    94.29\n",
      " 357   20    0   81.25  86.67    13     16   15      0     20    19    95.00\n",
      " 358   18    0   58.33  43.75     7     12   16      4     18    17    94.44\n",
      " 359   32    0   66.67  58.06    18     27   31      7     32    28    87.50\n",
      " 360   30    0   84.21  84.21    16     19   19      1     30    29    96.67\n",
      " 361   36    0   43.33  44.83    13     30   29     10     36    35    97.22\n",
      " 362   26    0   68.42  65.00    13     19   20      5     26    26   100.00\n",
      " 363   24    0   94.74  85.71    18     19   21      1     24    23    95.83\n",
      " 364   35    0   62.96  65.38    17     27   26      2     35    31    88.57\n",
      " 365   26    0   66.67  57.14    12     18   21      6     26    26   100.00\n",
      " 366   20    0   80.00  76.19    16     20   21      2     20    19    95.00\n",
      " 367   25    0   81.25  65.00    13     16   20      1     25    24    96.00\n",
      " 368   36    0   65.62  61.76    21     32   34      6     36    32    88.89\n",
      " 369   23    0   92.31  80.00    12     13   15      1     23    23   100.00\n",
      " 370   38    0   84.85  90.32    28     33   31      1     38    38   100.00\n",
      " 371   24    0   95.00  95.00    19     20   20      0     24    24   100.00\n",
      " 372   22    0   42.86  35.29     6     14   17      9     22    18    81.82\n",
      " 373   21    0  100.00  95.24    20     20   21      0     21    21   100.00\n",
      " 374   23    0   76.92  62.50    10     13   16      0     23    22    95.65\n",
      " 375   33    0   80.77  77.78    21     26   27      5     33    30    90.91\n",
      " 376   22    0   77.27  77.27    17     22   22      0     22    21    95.45\n",
      " 377   28    0   72.22  65.00    13     18   20      4     28    28   100.00\n",
      " 378   13    0   54.55  60.00     6     11   10      2     13    13   100.00\n",
      " 379   19    0   86.67  72.22    13     15   18      2     19    19   100.00\n",
      " 380   27    0   63.16  63.16    12     19   19      3     27    23    85.19\n",
      " 381   17    0  100.00  92.31    12     12   13      0     17    16    94.12\n",
      " 382   23    0   68.75  57.89    11     16   19      4     23    22    95.65\n",
      " 383   24    0   85.00  85.00    17     20   20      2     24    24   100.00\n",
      " 384   29    0   75.00  72.00    18     24   25      1     29    28    96.55\n",
      " 385   43    0   68.75  70.97    22     32   31      3     43    41    95.35\n",
      " 386   31    0   76.19  72.73    16     21   22      1     31    28    90.32\n",
      " 387   29    0   77.78  73.68    14     18   19      3     29    28    96.55\n",
      " 388    6    0   60.00  60.00     3      5    5      0      6     5    83.33\n",
      " 389   36    0  100.00  96.67    29     29   30      0     36    35    97.22\n",
      " 390   26    0  100.00  94.74    18     18   19      0     26    23    88.46\n",
      " 391   27    0   85.19  85.19    23     27   27      1     27    26    96.30\n",
      " 392   18    0   76.92  66.67    10     13   15      0     18    17    94.44\n",
      " 393   34    0  100.00  92.31    24     24   26      0     34    33    97.06\n",
      " 394   18    0   58.33  46.67     7     12   15      0     18    17    94.44\n",
      " 395   21    0   72.22  59.09    13     18   22      7     21    21   100.00\n",
      " 396   28    0   60.87  50.00    14     23   28      9     28    24    85.71\n",
      " 397   23    0   50.00  47.37     9     18   19      7     23    20    86.96\n",
      " 398   34    0   88.46  85.19    23     26   27      1     34    32    94.12\n",
      " 399   24    0   57.89  55.00    11     19   20      5     24    23    95.83\n",
      " 400   27    0   88.89  84.21    16     18   19      0     27    26    96.30\n",
      " 401   35    0   74.29  68.42    26     35   38      5     35    33    94.29\n",
      " 402   25    0   90.48  90.48    19     21   21      1     25    23    92.00\n",
      " 403   33    0   62.50  55.56    15     24   27      8     33    31    93.94\n",
      " 404   13    0   90.00  75.00     9     10   12      1     13    12    92.31\n",
      " 405   23    0   76.19  76.19    16     21   21      2     23    21    91.30\n",
      " 406   19    0   68.42  72.22    13     19   18      4     19    17    89.47\n",
      " 407   25    0  100.00  94.44    17     17   18      0     25    24    96.00\n",
      " 408   33    0   89.29  75.76    25     28   33      3     33    30    90.91\n",
      " 409   16    0   91.67  84.62    11     12   13      0     16    14    87.50\n",
      " 410   32    0   56.25  62.07    18     32   29      8     32    29    90.62\n",
      " 411   13    0  100.00  91.67    11     11   12      0     13    11    84.62\n",
      " 412   15    0  100.00  94.44    17     17   18      0     15    15   100.00\n",
      " 413    8    0  100.00  85.71     6      6    7      0      8     8   100.00\n",
      " 414   16    0  100.00  92.86    13     13   14      0     16    16   100.00\n",
      " 415   26    0   85.71  78.26    18     21   23      2     26    25    96.15\n",
      " 416   18    0   93.33  87.50    14     15   16      0     18    18   100.00\n",
      " 417   42    0   88.89  84.21    32     36   38      1     42    36    85.71\n",
      " 418   37    0   79.31  74.19    23     29   31      6     37    35    94.59\n",
      " 419   45    0   64.44  61.70    29     45   47     11     45    41    91.11\n",
      " 420   24    0   90.00  85.71    18     20   21      0     24    22    91.67\n",
      " 421   25    0   90.00  85.71    18     20   21      1     25    23    92.00\n",
      " 422   30    0  100.00  82.14    23     23   28      0     30    28    93.33\n",
      " 423   21    0   91.67  88.00    22     24   25      0     21    19    90.48\n",
      " 424   20    0   64.71  61.11    11     17   18      2     20    18    90.00\n",
      " 425   22    0   88.89  84.21    16     18   19      0     22    20    90.91\n",
      " 426   16    0   66.67  66.67     8     12   12      1     16    15    93.75\n",
      " 427   24    0   95.24  90.91    20     21   22      0     24    23    95.83\n",
      " 428   18    0   66.67  61.54     8     12   13      1     18    15    83.33\n",
      " 429   17    0   77.78  70.00    14     18   20      2     17    17   100.00\n",
      " 430   30    0   92.31  85.71    24     26   28      1     30    28    93.33\n",
      " 431   41    0   87.88  87.88    29     33   33      0     41    38    92.68\n",
      " 432    9    0  100.00  77.78     7      7    9      0      9     9   100.00\n",
      " 433   17    0   75.00  75.00    12     16   16      2     17    15    88.24\n",
      " 434   17    0   86.67  76.47    13     15   17      0     17    16    94.12\n",
      " 435   25    0   72.22  76.47    13     18   17      2     25    20    80.00\n",
      " 436   21    0   85.00  77.27    17     20   22      2     21    20    95.24\n",
      " 437   26    0   68.18  68.18    15     22   22      2     26    26   100.00\n",
      " 438   30    0   89.47  77.27    17     19   22      1     30    29    96.67\n",
      " 439   22    0   90.00  90.00    18     20   20      1     22    20    90.91\n",
      " 440   22    0   61.11  57.89    11     18   19      5     22    21    95.45\n",
      " 441   47    0   70.00  80.00    28     40   35      5     47    46    97.87\n",
      " 442   33    0   65.52  70.37    19     29   27      5     33    31    93.94\n",
      " 443   13    0   69.23  75.00     9     13   12      0     13    10    76.92\n",
      " 444   19    0   86.67  72.22    13     15   18      2     19    17    89.47\n",
      " 445    9    0   90.00  81.82     9     10   11      0      9     8    88.89\n",
      " 446   10    0  100.00  60.00     6      6   10      0     10     7    70.00\n",
      " 447   18    0   94.74  90.00    18     19   20      0     18    17    94.44\n",
      " 448   23    0   83.33  83.33    20     24   24      0     23    20    86.96\n",
      " 449   45    0   88.89  88.89    32     36   36      1     45    44    97.78\n",
      " 450   29    0   76.00  61.29    19     25   31      5     29    24    82.76\n",
      " 451   21    0   86.67  72.22    13     15   18      2     21    18    85.71\n",
      " 452   20    0   65.00  65.00    13     20   20      2     20    20   100.00\n",
      " 453    7    0   80.00  57.14     4      5    7      0      7     6    85.71\n",
      " 454    9    0   60.00  33.33     3      5    9      2      9     7    77.78\n",
      " 455   14    0   64.29  75.00     9     14   12      1     14    14   100.00\n",
      " 456   48    0   70.00  66.67    28     40   42      9     48    46    95.83\n",
      " 457   12    0   81.82  90.00     9     11   10      0     12    12   100.00\n",
      " 458   17    0   66.67  57.14     8     12   14      3     17    15    88.24\n",
      " 459   21    0   72.22  65.00    13     18   20      0     21    18    85.71\n",
      " 460   19    0   76.92  66.67    10     13   15      1     19    14    73.68\n",
      " 461   26    0  100.00  89.47    17     17   19      0     26    25    96.15\n",
      " 462   22    0   47.06  38.10     8     17   21      6     22    17    77.27\n",
      " 463   30    0   66.67  72.73    16     24   22      3     30    28    93.33\n",
      " 464   16    0   83.33  71.43    10     12   14      1     16    16   100.00\n",
      " 465   28    0   90.91  83.33    20     22   24      0     28    25    89.29\n",
      " 466   24    0   61.90  65.00    13     21   20      3     24    22    91.67\n",
      " 467   11    0   55.56  71.43     5      9    7      1     11    10    90.91\n",
      " 468   16    0   68.75  61.11    11     16   18      3     16    16   100.00\n",
      " 469   25    0   87.50  87.50    21     24   24      1     25    23    92.00\n",
      " 470   25    0   54.55  54.55    12     22   22      5     25    25   100.00\n",
      " 471   24    0   95.83  95.83    23     24   24      0     24    23    95.83\n",
      " 472   24    0   76.47  65.00    13     17   20      4     24    23    95.83\n",
      " 473   10    0  100.00  75.00     6      6    8      0     10    10   100.00\n",
      " 474   25    0   94.12  88.89    16     17   18      0     25    25   100.00\n",
      " 475   25    0   92.86  72.22    13     14   18      1     25    24    96.00\n",
      " 476   20    0  100.00  95.24    20     20   21      0     20    20   100.00\n",
      " 477   36    0   78.79  81.25    26     33   32      3     36    33    91.67\n",
      " 478   28    0   92.00  85.19    23     25   27      1     28    27    96.43\n",
      " 479   48    0   75.00  75.00    30     40   40      8     48    46    95.83\n",
      " 480   20    0   90.00  81.82    18     20   22      0     20    19    95.00\n",
      " 481   11    0  100.00  90.00     9      9   10      0     11    10    90.91\n",
      " 482   15    0  100.00  92.31    12     12   13      0     15    14    93.33\n",
      " 483   23    0   66.67  66.67     8     12   12      1     23    23   100.00\n",
      " 484    5    0  100.00  80.00     4      4    5      0      5     5   100.00\n",
      " 485   37    0   67.86  67.86    19     28   28      5     37    34    91.89\n",
      " 486   16    0   73.33  64.71    11     15   17      3     16    16   100.00\n",
      " 487   10    0  100.00  75.00     6      6    8      0     10     8    80.00\n",
      " 488   15    0  100.00  90.91    10     10   11      0     15    14    93.33\n",
      " 489   36    0   57.14  55.17    16     28   29      2     36    31    86.11\n",
      " 490   32    0   51.85  53.85    14     27   26      6     32    28    87.50\n",
      " 491   32    0   68.00  70.83    17     25   24      5     32    30    93.75\n",
      " 492   21    0   66.67  66.67    10     15   15      1     21    18    85.71\n",
      " 493    8    0  100.00  85.71     6      6    7      0      8     7    87.50\n",
      " 494   25    0   95.45  87.50    21     22   24      1     25    25   100.00\n",
      " 495   18    0   41.67  45.45     5     12   11      0     18    15    83.33\n",
      " 496   23    0   50.00  50.00    10     20   20      3     23    19    82.61\n",
      " 497   14    0  100.00  92.31    12     12   13      0     14    12    85.71\n",
      " 498   17    0   84.62  78.57    11     13   14      0     17    14    82.35\n",
      " 499   11    0  100.00  87.50     7      7    8      0     11     9    81.82\n",
      " 500   19    0   46.67  50.00     7     15   14      3     19    14    73.68\n",
      " 501    5    0   60.00  60.00     3      5    5      0      5     4    80.00\n",
      " 502   23    0   58.82  52.63    10     17   19      3     23    21    91.30\n",
      " 503    7    0   85.71  75.00     6      7    8      0      7     6    85.71\n",
      " 504   34    0   95.24  86.96    20     21   23      1     34    32    94.12\n",
      " 505   23    0   52.94  47.37     9     17   19      5     23    20    86.96\n",
      " 506   11    0   85.71  75.00     6      7    8      0     11     9    81.82\n",
      " 507   18    0   64.29  75.00     9     14   12      0     18    16    88.89\n",
      " 508   32    0   72.41  67.74    21     29   31      6     32    29    90.62\n",
      " 509   15    0  100.00  66.67     6      6    9      0     15    14    93.33\n",
      " 510   19    0   87.50  87.50    14     16   16      1     19    18    94.74\n",
      " 511   27    0   35.00  28.00     7     20   25      3     27    22    81.48\n",
      " 512   17    0   87.50  77.78    14     16   18      0     17    14    82.35\n",
      " 513   21    0  100.00  87.50    14     14   16      0     21    21   100.00\n",
      " 514   30    0   61.54  64.00    16     26   25      6     30    29    96.67\n",
      " 515   16    0  100.00  93.75    15     15   16      0     16    15    93.75\n",
      " 516   17    0   75.00  80.00    12     16   15      1     17    15    88.24\n",
      " 517    6    0   75.00  60.00     3      4    5      0      6     5    83.33\n",
      " 518   28    0   78.26  72.00    18     23   25      4     28    25    89.29\n",
      " 519   14    0   66.67  60.00     6      9   10      1     14    12    85.71\n",
      " 520   23    0   93.75  83.33    15     16   18      0     23    22    95.65\n",
      " 521   19    0   69.23  64.29     9     13   14      0     19    17    89.47\n",
      " 522   23    0   50.00  41.18     7     14   17      5     23    22    95.65\n",
      " 523   40    0   53.57  53.57    15     28   28     11     40    36    90.00\n",
      " 524   43    0   66.67  66.67    22     33   33      3     43    41    95.35\n",
      " 525   51    0   71.43  68.18    30     42   44     11     51    48    94.12\n",
      " 526   22    0   61.90  72.22    13     21   18      2     22    19    86.36\n",
      " 527   28    0   72.00  64.29    18     25   28      7     28    26    92.86\n",
      " 528   37    0   91.67  89.19    33     36   37      0     37    34    91.89\n",
      " 529   45    0   77.78  70.00    21     27   30      6     45    42    93.33\n",
      " 530    9    0   77.78  77.78     7      9    9      0      9     7    77.78\n",
      " 531   26    0  100.00  95.00    19     19   20      0     26    26   100.00\n",
      " 532   15    0   54.55  66.67     6     11    9      0     15    13    86.67\n",
      " 533   18    0   33.33  28.57     4     12   14      6     18    17    94.44\n",
      " 534   22    0   84.21  72.73    16     19   22      3     22    21    95.45\n",
      " 535   34    0   92.59  92.59    25     27   27      0     34    33    97.06\n",
      " 536   31    0   75.00  69.23    18     24   26      2     31    28    90.32\n",
      " 537   20    0   78.57  68.75    11     14   16      1     20    18    90.00\n",
      " 538   37    0   92.86  89.66    26     28   29      0     37    36    97.30\n",
      " 539   28    0   73.91  70.83    17     23   24      2     28    27    96.43\n",
      " 540   17    0   92.31  85.71    12     13   14      0     17    15    88.24\n",
      " 541   26    0   75.00  71.43    15     20   21      2     26    25    96.15\n",
      " 542   25    0   95.00  95.00    19     20   20      0     25    25   100.00\n",
      " 543   20    0   75.00  70.59    12     16   17      2     20    20   100.00\n",
      " 544   42    0   79.41  72.97    27     34   37      5     42    37    88.10\n",
      " 545   27    0   78.26  78.26    18     23   23      1     27    25    92.59\n",
      " 546   19    0   75.00  75.00    12     16   16      2     19    18    94.74\n",
      " 547   25    0   95.45  91.30    21     22   23      0     25    22    88.00\n",
      " 548   30    0   68.00  77.27    17     25   22      2     30    27    90.00\n",
      " 549   24    0   70.83  77.27    17     24   22      1     24    23    95.83\n",
      " 550   37    0   68.57  66.67    24     35   36      6     37    34    91.89\n",
      " 551   38    0   72.73  68.57    24     33   35      8     38    38   100.00\n",
      " 552   44    0   82.86  76.32    29     35   38      6     44    43    97.73\n",
      " 553   29    0   84.62  84.62    22     26   26      1     29    27    93.10\n",
      " 554   36    0   78.57  73.33    22     28   30      3     36    33    91.67\n",
      " 555   19    0  100.00  94.12    16     16   17      0     19    17    89.47\n",
      " 556   16    0   75.00  70.59    12     16   17      4     16    15    93.75\n",
      " 557   19    0   93.33  93.33    14     15   15      0     19    18    94.74\n",
      " 558   21    0   85.71  75.00    12     14   16      0     21    19    90.48\n",
      " 559    7    0  100.00  83.33     5      5    6      0      7     6    85.71\n",
      " 560   36    0   75.76  73.53    25     33   34      8     36    36   100.00\n",
      " 561   33    0   80.77  72.41    21     26   29      1     33    31    93.94\n",
      " 562   10    0  100.00  87.50     7      7    8      0     10    10   100.00\n",
      " 563   30    0   66.67  59.26    16     24   27      4     30    28    93.33\n",
      " 564   45    0   86.11  79.49    31     36   39      1     45    42    93.33\n",
      " 565   44    0   75.86  78.57    22     29   28      3     44    41    93.18\n",
      " 566   20    0  100.00  92.86    13     13   14      0     20    19    95.00\n",
      " 567   16    0  100.00  93.33    14     14   15      0     16    15    93.75\n",
      " 568   14    0  100.00  90.91    10     10   11      0     14    13    92.86\n",
      " 569   14    0  100.00  90.91    10     10   11      0     14    13    92.86\n",
      " 570   14    0   88.89  80.00     8      9   10      0     14    12    85.71\n",
      " 571   12    0   91.67  68.75    11     12   16      1     12    10    83.33\n",
      " 572   21    0   86.67  72.22    13     15   18      0     21    19    90.48\n",
      " 573   16    0   72.22  68.42    13     18   19      3     16    15    93.75\n",
      " 574   33    0   50.00  48.15    13     26   27      5     33    30    90.91\n",
      " 575   32    0   46.43  46.43    13     28   28      6     32    26    81.25\n",
      " 576   20    0   64.29  64.29     9     14   14      0     20    19    95.00\n",
      " 577   37    0   75.76  75.76    25     33   33      4     37    33    89.19\n",
      " 578   11    0  100.00  88.89     8      8    9      0     11    10    90.91\n",
      " 579   12    0   80.00  72.73     8     10   11      1     12    12   100.00\n",
      " 580   40    0   69.70  69.70    23     33   33      7     40    39    97.50\n",
      " 581   18    0   85.71  92.31    12     14   13      0     18    17    94.44\n",
      " 582   30    0   69.57  66.67    16     23   24      3     30    26    86.67\n",
      " 583   25    0   85.00  85.00    17     20   20      1     25    23    92.00\n",
      " 584   19    0   81.25  76.47    13     16   17      1     19    18    94.74\n",
      " 585   21    0   44.44  50.00     8     18   16      5     21    21   100.00\n",
      " 586   34    0   88.00  91.67    22     25   24      0     34    30    88.24\n",
      " 587   28    0   75.00  64.29    18     24   28      4     28    24    85.71\n",
      " 588   24    0   72.22  68.42    13     18   19      3     24    23    95.83\n",
      " 589   41    0   83.33  83.33    35     42   42      1     41    41   100.00\n",
      " 590   13    0  100.00  92.86    13     13   14      0     13    11    84.62\n",
      " 591   49    0   60.53  63.89    23     38   36     11     49    47    95.92\n",
      " 592   20    0   71.43  55.56    10     14   18      2     20    19    95.00\n",
      " 593   16    0   73.33  64.71    11     15   17      2     16    14    87.50\n",
      " 594   37    0   76.92  76.92    20     26   26      1     37    32    86.49\n",
      " 595   30    0   68.18  60.00    15     22   25      5     30    27    90.00\n",
      " 596    9    2    0.00   0.00     0      0    0      0      0     0     0.00\n",
      " 597   22    0   59.09  54.17    13     22   24      4     22    17    77.27\n",
      " 598   31    0   70.83  58.62    17     24   29      5     31    28    90.32\n",
      " 599   23    0   47.37  47.37     9     19   19      7     23    23   100.00\n",
      " 600   35    0   51.85  46.67    14     27   30      6     35    30    85.71\n",
      " 601   36    0   66.67  51.61    16     24   31      7     36    28    77.78\n",
      " 602   14    0   75.00  64.29     9     12   14      3     14    14   100.00\n",
      " 603   28    0   95.65  88.00    22     23   25      1     28    28   100.00\n",
      " 604   18    0  100.00  95.45    21     21   22      0     18    17    94.44\n",
      " 605   25    0   95.83  88.46    23     24   26      0     25    22    88.00\n",
      " 606   22    0   94.12  84.21    16     17   19      0     22    22   100.00\n",
      " 607   17    0   53.85  50.00     7     13   14      4     17    17   100.00\n",
      " 608   40    0   73.53  67.57    25     34   37      6     40    38    95.00\n",
      " 609    1    0  100.00  50.00     1      1    2      0      1     0     0.00\n",
      " 610   30    0   76.00  76.00    19     25   25      3     30    28    93.33\n",
      " 611   32    0   80.00  69.57    16     20   23      2     32    30    93.75\n",
      " 612   17    0   72.73  80.00     8     11   10      1     17    15    88.24\n",
      " 613   28    0   81.25  72.22    13     16   18      2     28    26    92.86\n",
      " 614   21    0   66.67  62.50    10     15   16      2     21    20    95.24\n",
      " 615   24    0  100.00  94.12    16     16   17      0     24    23    95.83\n",
      " 616   21    0   71.43  71.43    10     14   14      1     21    21   100.00\n",
      " 617   15    0   80.00  80.00    12     15   15      0     15    11    73.33\n",
      " 618   24    0   42.11  34.78     8     19   23     10     24    22    91.67\n",
      " 619   36    0   74.19  69.70    23     31   33      2     36    32    88.89\n",
      " 620   25    0   90.48  90.48    19     21   21      1     25    24    96.00\n",
      " 621   31    0   57.89  52.38    11     19   21      5     31    27    87.10\n",
      " 622   26    0   59.09  59.09    13     22   22      4     26    22    84.62\n",
      " 623   34    0   86.96  80.00    20     23   25      2     34    32    94.12\n",
      " 624   29    0   80.00  72.73    16     20   22      2     29    27    93.10\n",
      " 625   37    0   92.31  82.76    24     26   29      1     37    36    97.30\n",
      " 626   11    0  100.00  90.00     9      9   10      0     11    11   100.00\n",
      " 627   44    0   76.19  80.00    32     42   40      3     44    40    90.91\n",
      " 628   16    0   69.23  64.29     9     13   14      0     16    11    68.75\n",
      " 629   30    0   77.78  72.41    21     27   29      4     30    27    90.00\n",
      " 630   24    0   72.22  72.22    13     18   18      1     24    22    91.67\n",
      " 631   22    0   88.24  68.18    15     17   22      1     22    18    81.82\n",
      " 632   30    0   95.83  92.00    23     24   25      0     30    28    93.33\n",
      " 633   33    0   74.07  64.52    20     27   31      5     33    32    96.97\n",
      " 634   37    0   72.73  66.67    16     22   24      3     37    36    97.30\n",
      " 635   37    0   88.57  93.94    31     35   33      0     37    35    94.59\n",
      " 636   11    0   80.00  72.73     8     10   11      0     11     9    81.82\n",
      " 637   21    0   88.89  80.00    16     18   20      1     21    19    90.48\n",
      " 638   33    0   84.62  81.48    22     26   27      0     33    31    93.94\n",
      " 639   42    0   65.71  62.16    23     35   37      6     42    38    90.48\n",
      " 640   15    0  100.00  92.86    13     13   14      0     15    15   100.00\n",
      " 641   25    0   68.75  61.11    11     16   18      3     25    23    92.00\n",
      " 642   19    0   81.25  76.47    13     16   17      2     19    18    94.74\n",
      " 643   29    0   37.50  36.00     9     24   25     13     29    25    86.21\n",
      " 644    4    0    0.00   0.00     0      1    4      0      4     1    25.00\n",
      " 645    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      " 646   27    0  100.00  92.86    13     13   14      0     27    27   100.00\n",
      " 647   19    0   77.78  58.33     7      9   12      1     19    19   100.00\n",
      " 648    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      " 649   21    0   81.82  50.00     9     11   18      2     21    21   100.00\n",
      " 650   17    0   72.73  57.14     8     11   14      1     17    14    82.35\n",
      " 651    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      " 652   35    0   61.90  56.52    13     21   23      5     35    32    91.43\n",
      " 653   20    0   80.00  63.16    12     15   19      2     20    19    95.00\n",
      " 654   41    0   83.33  83.33    20     24   24      1     41    38    92.68\n",
      " 655    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      " 656   18    0   81.82  81.82     9     11   11      0     18    17    94.44\n",
      " 657   31    0   80.00  66.67    20     25   30      4     31    31   100.00\n",
      " 658   14    0  100.00  88.89     8      8    9      0     14    14   100.00\n",
      " 659   17    0   71.43  76.92    10     14   13      1     17    17   100.00\n",
      " 660   29    0   65.22  68.18    15     23   22      6     29    27    93.10\n",
      " 661   34    0   92.59  89.29    25     27   28      1     34    34   100.00\n",
      " 662   11    0  100.00  90.00     9      9   10      0     11    10    90.91\n",
      " 663   32    0   71.88  67.65    23     32   34      6     32    31    96.88\n",
      " 664   18    0  100.00  94.44    17     17   18      0     18    18   100.00\n",
      " 665   24    0  100.00  94.74    18     18   19      0     24    24   100.00\n",
      " 666   20    0   63.16  66.67    12     19   18      2     20    18    90.00\n",
      " 667   32    0   94.74  81.82    18     19   22      1     32    31    96.88\n",
      " 668   11    0  100.00  90.00     9      9   10      0     11    10    90.91\n",
      " 669   29    0   90.00  75.00    18     20   24      0     29    27    93.10\n",
      " 670   21    0   53.85  50.00     7     13   14      4     21    21   100.00\n",
      " 671   33    0   72.73  59.26    16     22   27      5     33    30    90.91\n",
      " 672   38    0   80.00  62.50    20     25   32      3     38    34    89.47\n",
      " 673   17    0   84.62  78.57    11     13   14      2     17    17   100.00\n",
      " 674   20    0   86.36  82.61    19     22   23      1     20    19    95.00\n",
      " 675   30    0  100.00  96.15    25     25   26      0     30    29    96.67\n",
      " 676   23    0   68.42  65.00    13     19   20      5     23    23   100.00\n",
      " 677   19    0  100.00  93.33    14     14   15      0     19    19   100.00\n",
      " 678   27    0   90.00  85.71    18     20   21      0     27    27   100.00\n",
      " 679   18    0   88.24  78.95    15     17   19      2     18    18   100.00\n",
      " 680   33    0   92.86  89.66    26     28   29      0     33    29    87.88\n",
      " 681   27    0   90.91  90.91    20     22   22      1     27    26    96.30\n",
      " 682   16    0   66.67  57.14     8     12   14      0     16    12    75.00\n",
      " 683   22    0   78.95  83.33    15     19   18      1     22    22   100.00\n",
      " 684   24    0   65.00  65.00    13     20   20      5     24    23    95.83\n",
      " 685   28    0   75.00  68.18    15     20   22      3     28    27    96.43\n",
      " 686   31    0   61.54  55.17    16     26   29      8     31    29    93.55\n",
      " 687   22    0   78.95  68.18    15     19   22      3     22    22   100.00\n",
      " 688   32    0   64.00  64.00    16     25   25      6     32    29    90.62\n",
      " 689   27    0   72.00  72.00    18     25   25      3     27    26    96.30\n",
      " 690   27    0   61.11  61.11    11     18   18      2     27    21    77.78\n",
      " 691   29    0   72.00  72.00    18     25   25      2     29    26    89.66\n",
      " 692   48    0   68.18  51.72    15     22   29      5     48    46    95.83\n",
      " 693   24    0   70.00  66.67    14     20   21      4     24    24   100.00\n",
      " 694   28    0   73.91  77.27    17     23   22      3     28    25    89.29\n",
      " 695   18    0   92.31  85.71    12     13   14      0     18    17    94.44\n",
      " 696   40    0   78.79  78.79    26     33   33      2     40    35    87.50\n",
      " 697    8    0  100.00  85.71     6      6    7      0      8     7    87.50\n",
      " 698   38    0   79.17  76.00    19     24   25      4     38    35    92.11\n",
      " 699   19    0   61.54  80.00     8     13   10      1     19    17    89.47\n",
      " 700   37    0   69.57  57.14    16     23   28      5     37    36    97.30\n",
      " 701   32    0  100.00  95.83    23     23   24      0     32    25    78.12\n",
      " 702   44    0   51.61  45.71    16     31   35     13     44    39    88.64\n",
      " 703   33    0   76.19  80.00    16     21   20      2     33    33   100.00\n",
      " 704   13    0   60.00  60.00     6     10   10      0     13    12    92.31\n",
      " 705   17    0  100.00  88.89     8      8    9      0     17    17   100.00\n",
      " 706   24    0   88.24  83.33    15     17   18      1     24    23    95.83\n",
      " 707   18    0  100.00  92.31    12     12   13      0     18    18   100.00\n",
      " 708   13    0   60.00  60.00     6     10   10      0     13    12    92.31\n",
      " 709   24    0   64.71  61.11    11     17   18      4     24    22    91.67\n",
      " 710   13    0  100.00  81.82     9      9   11      0     13    12    92.31\n",
      " 711   11    0  100.00  57.14     4      4    7      0     11    11   100.00\n",
      " 712   41    0   68.75  66.67    22     32   33      9     41    40    97.56\n",
      " 713   29    0   83.33  80.00    20     24   25      2     29    26    89.66\n",
      " 714   28    0   91.30  84.00    21     23   25      0     28    27    96.43\n",
      " 715   38    0   76.67  65.71    23     30   35      2     38    34    89.47\n",
      " 716   21    0   88.89  88.89    16     18   18      0     21    19    90.48\n",
      " 717   36    0   86.96  86.96    20     23   23      2     36    34    94.44\n",
      " 718   26    0   66.67  70.00    14     21   20      2     26    23    88.46\n",
      " 719   39    0   46.15  44.44    12     26   27     12     39    33    84.62\n",
      " 720   39    0   74.07  66.67    20     27   30      4     39    38    97.44\n",
      " 721   30    0   61.90  68.42    13     21   19      1     30    26    86.67\n",
      " 722   15    0   92.31  85.71    12     13   14      0     15    14    93.33\n",
      " 723   18    0   72.73  72.73     8     11   11      2     18    17    94.44\n",
      " 724   37    0   84.62  75.86    22     26   29      3     37    32    86.49\n",
      " 725   27    0   62.50  50.00    10     16   20      4     27    24    88.89\n",
      " 726   41    0   63.64  70.00    21     33   30      6     41    39    95.12\n",
      " 727   46    0   52.78  59.38    19     36   32      8     46    41    89.13\n",
      " 728   33    0   63.64  53.85    14     22   26      5     33    25    75.76\n",
      " 729   26    0   95.45  91.30    21     22   23      0     26    23    88.46\n",
      " 730   28    0   76.00  79.17    19     25   24      2     28    26    92.86\n",
      " 731   29    0   57.69  62.50    15     26   24      4     29    27    93.10\n",
      " 732   22    0   85.71  85.71    18     21   21      1     22    20    90.91\n",
      " 733   32    0   72.41  61.76    21     29   34      5     32    29    90.62\n",
      " 734   29    0   83.33  83.33    20     24   24      1     29    27    93.10\n",
      " 735   21    0   47.62  45.45    10     21   22     10     21    20    95.24\n",
      " 736   37    0   89.47  82.93    34     38   41      0     37    34    91.89\n",
      " 737   37    0   96.00  88.89    24     25   27      0     37    36    97.30\n",
      " 738   44    0   71.88  79.31    23     32   29      3     44    40    90.91\n",
      " 739   28    0   86.96  74.07    20     23   27      3     28    26    92.86\n",
      " 740   30    0   73.33  78.57    22     30   28      5     30    30   100.00\n",
      " 741   16    0  100.00  92.31    12     12   13      0     16    15    93.75\n",
      " 742   30    0   92.86  81.25    13     14   16      0     30    29    96.67\n",
      " 743   22    0   47.06  53.33     8     17   15      6     22    20    90.91\n",
      " 744   40    0   64.52  66.67    20     31   30      7     40    39    97.50\n",
      " 745   26    0   90.48  86.36    19     21   22      0     26    24    92.31\n",
      " 746   16    0   53.85  58.33     7     13   12      2     16    14    87.50\n",
      " 747   21    0   73.68  70.00    14     19   20      4     21    21   100.00\n",
      " 748   41    0   71.05  72.97    27     38   37      5     41    38    92.68\n",
      " 749   50    0   64.10  65.79    25     39   38      7     50    43    86.00\n",
      " 750   16    0   75.00  83.33    15     20   18      0     16    14    87.50\n",
      " 751   32    0   78.26  81.82    18     23   22      2     32    25    78.12\n",
      " 752   29    0   66.67  66.67    16     24   24      4     29    27    93.10\n",
      " 753   11    0   75.00  66.67     6      8    9      0     11     9    81.82\n",
      " 754   17    0  100.00  84.62    11     11   13      0     17    16    94.12\n",
      " 755   31    0   87.50  84.00    21     24   25      2     31    30    96.77\n",
      " 756   34    0   93.10  87.10    27     29   31      1     34    33    97.06\n",
      " 757   12    0  100.00  88.89     8      8    9      0     12     9    75.00\n",
      " 758   22    0   50.00  57.14    12     24   21      7     22    20    90.91\n",
      " 759   12    0  100.00  36.36     4      4   11      0     12    10    83.33\n",
      " 760    7    0  100.00  83.33     5      5    6      0      7     7   100.00\n",
      " 761   43    0   86.11  88.57    31     36   35      2     43    42    97.67\n",
      " 762   25    0   60.87  53.85    14     23   26      5     25    24    96.00\n",
      " 763   38    0  100.00  96.55    28     28   29      0     38    37    97.37\n",
      " 764   13    0   70.00  63.64     7     10   11      1     13    12    92.31\n",
      " 765   36    0   71.88  67.65    23     32   34      6     36    35    97.22\n",
      " 766   13    0   72.73  72.73     8     11   11      1     13    12    92.31\n",
      " 767   27    0   76.47  72.22    13     17   18      2     27    26    96.30\n",
      " 768   26    0   92.86  72.22    13     14   18      2     26    25    96.15\n",
      " 769   30    0   75.76  75.76    25     33   33      5     30    29    96.67\n",
      " 770   28    0   56.67  54.84    17     30   31     10     28    27    96.43\n",
      " 771   11    0  100.00  90.00     9      9   10      0     11    11   100.00\n",
      " 772   32    0   92.59  96.15    25     27   26      0     32    32   100.00\n",
      " 773   38    0   68.97  76.92    20     29   26      3     38    37    97.37\n",
      " 774   23    0   85.71  81.82    18     21   22      2     23    21    91.30\n",
      " 775   10    0   87.50  87.50     7      8    8      0     10     8    80.00\n",
      " 776   35    0   66.67  62.86    22     33   35      9     35    33    94.29\n",
      " 777   25    0   91.67  95.65    22     24   23      0     25    23    92.00\n",
      " 778    7    0  100.00  83.33     5      5    6      0      7     7   100.00\n",
      " 779   13    0   91.67  84.62    11     12   13      0     13    11    84.62\n",
      " 780   23    0   83.33  75.00    15     18   20      2     23    22    95.65\n",
      " 781   37    0   96.97  91.43    32     33   35      0     37    35    94.59\n",
      " 782   32    0   96.15  89.29    25     26   28      1     32    30    93.75\n",
      " 783   39    0   53.57  53.57    15     28   28      4     39    36    92.31\n",
      " 784   11    0  100.00  90.00     9      9   10      0     11    11   100.00\n",
      " 785   10    0   50.00  44.44     4      8    9      2     10     8    80.00\n",
      " 786   34    0   77.78  72.41    21     27   29      3     34    33    97.06\n",
      " 787   29    0   80.00  76.19    16     20   21      3     29    28    96.55\n",
      " 788   40    0   80.77  75.00    21     26   28      4     40    39    97.50\n",
      " 789   31    0   66.67  66.67    18     27   27      6     31    28    90.32\n",
      " 790   42    0   73.08  67.86    19     26   28      2     42    33    78.57\n",
      " 791   27    0   94.12  88.89    16     17   18      0     27    27   100.00\n",
      " 792   28    0   80.95  65.38    17     21   26      4     28    27    96.43\n",
      " 793   38    0   65.62  67.74    21     32   31      0     38    35    92.11\n",
      " 794   54    0   61.54  61.54    24     39   39     13     54    50    92.59\n",
      " 795   29    0   95.00  82.61    19     20   23      1     29    28    96.55\n",
      " 796   19    0  100.00  93.33    14     14   15      0     19    19   100.00\n",
      " 797   17    0   76.92  62.50    10     13   16      1     17    15    88.24\n",
      " 798   28    0   63.64  63.64    14     22   22      4     28    25    89.29\n",
      " 799   20    0   87.50  87.50    14     16   16      0     20    19    95.00\n",
      " 800   16    0  100.00  92.31    12     12   13      0     16    16   100.00\n",
      " 801   19    0  100.00  92.31    12     12   13      0     19    19   100.00\n",
      " 802    7    0  100.00  85.71     6      6    7      0      7     7   100.00\n",
      " 803   36    0   59.38  57.58    19     32   33     11     36    34    94.44\n",
      " 804   23    0   57.89  55.00    11     19   20      5     23    22    95.65\n",
      " 805   24    0   55.56  66.67    10     18   15      1     24    22    91.67\n",
      " 806   21    0   81.25  72.22    13     16   18      2     21    20    95.24\n",
      " 807   23    0   88.24  88.24    15     17   17      0     23    21    91.30\n",
      " 808   54    0   71.11  68.09    32     45   47     11     54    50    92.59\n",
      " 809   12    0   87.50  77.78     7      8    9      0     12    12   100.00\n",
      " 810    5    0  100.00  85.71     6      6    7      0      5     5   100.00\n",
      " 811   43    0   56.67  51.52    17     30   33     12     43    40    93.02\n",
      " 812   33    0   70.83  68.00    17     24   25      4     33    32    96.97\n",
      " 813   39    0   81.82  79.41    27     33   34      2     39    37    94.87\n",
      " 814   26    0   95.45  95.45    21     22   22      0     26    25    96.15\n",
      " 815   28    0   65.38  62.96    17     26   27      7     28    24    85.71\n",
      " 816   26    0   61.90  68.42    13     21   19      3     26    23    88.46\n",
      " 817   18    0   70.00  46.67     7     10   15      4     18    16    88.89\n",
      " 818   19    0   75.00  75.00     9     12   12      1     19    19   100.00\n",
      " 819    9    0  100.00  85.71     6      6    7      0      9     9   100.00\n",
      " 820   39    0   36.11  36.11    13     36   36     18     39    38    97.44\n",
      " 821   16    0   81.82  75.00     9     11   12      1     16    16   100.00\n",
      " 822   29    0   79.17  79.17    19     24   24      4     29    27    93.10\n",
      " 823   48    0   94.12  86.49    32     34   37      1     48    46    95.83\n",
      " 824    9    0   62.50  62.50     5      8    8      2      9     9   100.00\n",
      " 825   37    0   74.07  62.50    20     27   32      3     37    36    97.30\n",
      " 826   22    0   81.25  81.25    13     16   16      1     22    21    95.45\n",
      " 827   13    0  100.00  92.86    13     13   14      0     13    13   100.00\n",
      " 828   19    0   86.67  76.47    13     15   17      0     19    16    84.21\n",
      " 829   21    0   85.71  75.00    12     14   16      2     21    21   100.00\n",
      " 830   28    0   94.44  89.47    17     18   19      0     28    27    96.43\n",
      " 831   22    0   78.95  78.95    15     19   19      2     22    20    90.91\n",
      " 832   26    0   73.91  68.00    17     23   25      4     26    26   100.00\n",
      " 833   15    0   72.73  61.54     8     11   13      1     15    14    93.33\n",
      " 834   13    0   90.00  81.82     9     10   11      0     13    11    84.62\n",
      " 835   20    0   84.62  78.57    11     13   14      1     20    18    90.00\n",
      " 836   12    0   88.89  72.73     8      9   11      0     12    10    83.33\n",
      " 837   25    0   94.12  88.89    16     17   18      0     25    25   100.00\n",
      " 838   30    0  100.00  82.35    14     14   17      0     30    27    90.00\n",
      " 839   44    0   72.73  72.73    24     33   33      3     44    39    88.64\n",
      " 840   18    0   72.73  66.67     8     11   12      1     18    15    83.33\n",
      " 841   52    0   82.76  80.00    24     29   30      2     52    48    92.31\n",
      " 842   18    0   75.00  81.82     9     12   11      1     18    17    94.44\n",
      " 843   42    0   54.55  54.55    18     33   33     12     42    38    90.48\n",
      " 844   49    0   51.52  48.57    17     33   35     10     49    43    87.76\n",
      " 845   37    0   41.67  35.71    10     24   28      8     37    31    83.78\n",
      " 846   28    0   65.00  61.90    13     20   21      4     28    25    89.29\n",
      " 847   17    0   50.00  53.85     7     14   13      1     17    12    70.59\n",
      " 848   39    0   80.00  75.68    28     35   37      5     39    36    92.31\n",
      " 849   25    0   85.00  73.91    17     20   23      1     25    23    92.00\n",
      " 850   27    0   92.31  85.71    24     26   28      0     27    24    88.89\n",
      " 851   36    0   59.38  63.33    19     32   30      7     36    29    80.56\n",
      " 852   18    0  100.00  92.86    13     13   14      0     18    18   100.00\n",
      " 853    8    0  100.00  75.00     6      6    8      0      8     7    87.50\n",
      " 854   33    0   92.59  86.21    25     27   29      0     33    28    84.85\n",
      " 855   21    0   75.00  57.14    12     16   21      4     21    19    90.48\n",
      " 856   18    0   50.00  50.00    10     20   20      4     18    14    77.78\n",
      " 857   20    0   68.75  57.89    11     16   19      3     20    17    85.00\n",
      " 858   15    0   66.67  60.00     6      9   10      1     15    14    93.33\n",
      " 859   61    0   59.57  65.12    28     47   43      4     61    49    80.33\n",
      " 860    7    0   83.33  62.50     5      6    8      1      7     7   100.00\n",
      " 861   32    0   61.90  61.90    13     21   21      2     32    28    87.50\n",
      " 862   25    0   54.55  50.00    12     22   24      5     25    22    88.00\n",
      " 863   25    0   86.67  68.42    13     15   19      1     25    21    84.00\n",
      " 864   23    0   88.89  80.00    16     18   20      0     23    21    91.30\n",
      " 865   29    0   84.62  64.71    11     13   17      3     29    25    86.21\n",
      " 866   23    0   86.67  86.67    13     15   15      0     23    21    91.30\n",
      " 867   24    0   47.62  50.00    10     21   20      7     24    21    87.50\n",
      " 868   34    0   83.33  83.33    25     30   30      1     34    31    91.18\n",
      " 869   10    0   80.00  80.00     4      5    5      0     10    10   100.00\n",
      " 870   42    0   59.52  71.43    25     42   35      4     42    37    88.10\n",
      " 871   41    0   60.00  53.33    24     40   45     14     41    36    87.80\n",
      " 872   13    0   60.00  42.86     6     10   14      4     13    12    92.31\n",
      " 873    5    0  100.00  80.00     4      4    5      0      5     4    80.00\n",
      " 874   38    0   87.88  82.86    29     33   35      2     38    37    97.37\n",
      " 875   34    0   65.52  65.52    19     29   29      4     34    30    88.24\n",
      " 876   13    0   88.89  80.00     8      9   10      0     13    13   100.00\n",
      " 877   32    0   59.26  61.54    16     27   26      8     32    28    87.50\n",
      " 878   31    0   80.77  75.00    21     26   28      4     31    29    93.55\n",
      " 879   42    0   57.14  57.14    20     35   35     11     42    41    97.62\n",
      " 880   15    0   66.67  40.00     6      9   15      0     15    13    86.67\n",
      " 881   34    0   68.97  64.52    20     29   31      9     34    31    91.18\n",
      " 882   24    0   92.86  68.42    13     14   19      2     24    23    95.83\n",
      " 883   18    0   84.62  68.75    11     13   16      0     18    15    83.33\n",
      " 884   37    0   71.88  71.88    23     32   32      5     37    35    94.59\n",
      " 885   30    0   81.82  75.00    18     22   24      1     30    28    93.33\n",
      " 886   15    0   80.00  66.67     8     10   12      0     15    14    93.33\n",
      " 887   24    0   95.45  95.45    21     22   22      0     24    22    91.67\n",
      " 888   22    0   87.50  93.33    14     16   15      0     22    21    95.45\n",
      " 889   44    0   94.12  88.89    32     34   36      2     44    44   100.00\n",
      " 890   35    0   92.59  89.29    25     27   28      1     35    34    97.14\n",
      " 891   20    0   93.33  87.50    14     15   16      0     20    18    90.00\n",
      " 892   33    0   75.86  73.33    22     29   30      5     33    32    96.97\n",
      " 893   39    0   85.29  80.56    29     34   36      4     39    34    87.18\n",
      " 894    6    0   20.00  20.00     1      5    5      1      6     4    66.67\n",
      " 895   15    0   18.75  17.65     3     16   17     10     15    12    80.00\n",
      " 896   29    0   58.33  51.85    14     24   27      9     29    28    96.55\n",
      " 897   52    0   55.00  47.83    22     40   46     15     52    47    90.38\n",
      " 898   17    0   73.33  64.71    11     15   17      0     17    14    82.35\n",
      " 899   33    0   79.17  86.36    19     24   22      1     33    32    96.97\n",
      " 900   27    0   90.91  68.97    20     22   29      0     27    25    92.59\n",
      " 901   19    0   86.67  86.67    13     15   15      0     19    18    94.74\n",
      " 902   38    0   81.25  81.25    26     32   32      3     38    36    94.74\n",
      " 903   31    0   62.50  65.22    15     24   23      1     31    28    90.32\n",
      " 904   40    0   50.00  39.39    13     26   33     10     40    36    90.00\n",
      " 905   64    0   54.00  52.94    27     50   51     16     64    62    96.88\n",
      " 906   28    0   66.67  77.78    14     21   18      1     28    25    89.29\n",
      " 907   18    0   47.06  42.11     8     17   19      5     18    12    66.67\n",
      " 908   35    0   63.33  59.38    19     30   32      8     35    32    91.43\n",
      " 909   25    0   81.25  81.25    13     16   16      1     25    24    96.00\n",
      " 910   19    0   86.67  86.67    13     15   15      0     19    19   100.00\n",
      " 911   10    0   50.00  57.14     4      8    7      1     10     7    70.00\n",
      " 912   15    0   64.29  52.94     9     14   17      3     15    14    93.33\n",
      " 913   10    0   77.78  87.50     7      9    8      0     10    10   100.00\n",
      " 914   12    0   58.33  63.64     7     12   11      1     12    10    83.33\n",
      " 915   26    0   88.46  69.70    23     26   33      1     26    22    84.62\n",
      " 916   31    0   71.43  78.95    15     21   19      1     31    28    90.32\n",
      " 917   13    0   87.50  58.33     7      8   12      0     13     9    69.23\n",
      " 918   24    0   62.50  58.82    10     16   17      2     24    21    87.50\n",
      " 919   22    0   77.78  82.35    14     18   17      0     22    21    95.45\n",
      " 920   12    0   45.45  41.67     5     11   12      4     12     9    75.00\n",
      " 921   32    0   48.00  52.17    12     25   23      7     32    29    90.62\n",
      " 922   26    0   57.89  57.89    11     19   19      4     26    22    84.62\n",
      " 923   16    0   72.22  76.47    13     18   17      0     16    12    75.00\n",
      " 924   28    0   41.67  45.45    10     24   22      9     28    22    78.57\n",
      " 925   19    0   50.00  52.94     9     18   17      2     19    16    84.21\n",
      " 926   29    0   62.96  60.71    17     27   28      8     29    26    89.66\n",
      " 927   30    0   91.67  88.00    22     24   25      2     30    29    96.67\n",
      " 928   27    0   86.96  80.00    20     23   25      1     27    25    92.59\n",
      " 929   35    0   74.07  62.50    20     27   32      3     35    31    88.57\n",
      " 930   14    0   84.62  84.62    11     13   13      0     14    13    92.86\n",
      " 931   16    0   80.00  66.67     8     10   12      0     16    14    87.50\n",
      " 932   27    0   38.89  35.00     7     18   20     10     27    26    96.30\n",
      " 933   24    0   31.25  31.25     5     16   16      5     24    19    79.17\n",
      " 934   24    0   77.78  70.00    14     18   20      2     24    21    87.50\n",
      " 935   19    0   50.00  50.00     6     12   12      2     19    15    78.95\n",
      " 936   14    0   81.82  75.00     9     11   12      0     14    14   100.00\n",
      " 937   16    0   71.43  83.33    10     14   12      0     16    13    81.25\n",
      " 938    9    0   66.67  75.00     6      9    8      0      9     6    66.67\n",
      " 939   31    0   66.67  63.16    12     18   19      2     31    28    90.32\n",
      " 940   13    0   45.45  45.45     5     11   11      4     13    12    92.31\n",
      " 941   10    0  100.00  87.50     7      7    8      0     10    10   100.00\n",
      " 942   21    0   66.67  72.73     8     12   11      0     21    20    95.24\n",
      " 943    5    0   66.67  66.67     4      6    6      0      5     5   100.00\n",
      " 944   13    0   63.64  70.00     7     11   10      0     13    11    84.62\n",
      " 945    7    0   66.67  66.67     4      6    6      0      7     6    85.71\n",
      " 946   15    0   40.00  36.36     4     10   11      5     15    12    80.00\n",
      " 947   18    0   80.00  88.89     8     10    9      0     18    16    88.89\n",
      " 948   29    0   69.57  66.67    16     23   24      4     29    27    93.10\n",
      " 949   28    0   82.35  77.78    14     17   18      1     28    28   100.00\n",
      " 950   27    0   72.73  50.00     8     11   16      3     27    26    96.30\n",
      " 951   32    0   59.09  52.00    13     22   25      9     32    31    96.88\n",
      " 952   27    0   56.52  56.52    13     23   23      9     27    23    85.19\n",
      " 953   17    0   81.82  60.00     9     11   15      0     17    16    94.12\n",
      " 954   24    0   83.33  71.43    15     18   21      0     24    21    87.50\n",
      " 955   37    0   90.00  87.10    27     30   31      2     37    34    91.89\n",
      " 956   23    0   94.12  88.89    16     17   18      0     23    22    95.65\n",
      " 957   23    0   64.29  52.94     9     14   17      4     23    22    95.65\n",
      " 958   41    0   83.33  75.76    25     30   33      4     41    39    95.12\n",
      " 959   23    0   85.71  70.59    12     14   17      1     23    18    78.26\n",
      " 960   19    0   76.92  66.67    10     13   15      2     19    18    94.74\n",
      " 961   32    0   76.00  65.52    19     25   29      4     32    31    96.88\n",
      " 962   31    0   77.78  77.78    21     27   27      1     31    26    83.87\n",
      " 963   33    0   75.86  73.33    22     29   30      5     33    31    93.94\n",
      " 964   39    0   75.00  70.59    24     32   34      6     39    36    92.31\n",
      " 965   30    0   80.00  80.00    20     25   25      2     30    28    93.33\n",
      " 966   23    0   84.21  80.00    16     19   20      0     23    22    95.65\n",
      " 967   18    0   90.00  69.23     9     10   13      1     18    16    88.89\n",
      " 968   28    0   64.00  66.67    16     25   24      4     28    25    89.29\n",
      " 969   19    0   91.67  84.62    11     12   13      0     19    19   100.00\n",
      " 970   18    0   86.67  76.47    13     15   17      0     18    16    88.89\n",
      " 971   31    0   73.33  73.33    22     30   30      1     31    25    80.65\n",
      " 972   24    0   73.91  68.00    17     23   25      5     24    21    87.50\n",
      " 973   11    0  100.00  88.89     8      8    9      0     11    10    90.91\n",
      " 974   22    0   84.21  80.00    16     19   20      2     22    22   100.00\n",
      " 975   39    0   32.14  34.62     9     28   26      9     39    31    79.49\n",
      " 976   48    0   43.59  42.50    17     39   40     17     48    42    87.50\n",
      " 977   33    0   95.83  88.46    23     24   26      0     33    28    84.85\n",
      " 978   44    0   78.95  81.08    30     38   37      5     44    41    93.18\n",
      " 979   32    0   82.61  82.61    19     23   23      3     32    32   100.00\n",
      " 980   39    0   78.57  70.97    22     28   31      4     39    38    97.44\n",
      " 981   29    0   65.22  65.22    15     23   23      6     29    28    96.55\n",
      " 982   17    0  100.00  90.00     9      9   10      0     17    16    94.12\n",
      " 983   15    0   87.50  70.00     7      8   10      0     15    15   100.00\n",
      " 984   25    0   62.50  47.62    10     16   21      6     25    22    88.00\n",
      " 985   19    0  100.00  93.33    14     14   15      0     19    18    94.74\n",
      " 986   26    0   33.33  37.50     9     27   24     10     26    23    88.46\n",
      " 987   23    0   77.78  70.00    14     18   20      2     23    22    95.65\n",
      " 988   15    0  100.00  91.67    11     11   12      0     15    15   100.00\n",
      " 989   12    0   90.91  90.91    10     11   11      0     12    12   100.00\n",
      " 990   30    0   95.45  91.30    21     22   23      0     30    29    96.67\n",
      " 991   31    0   73.91  62.96    17     23   27      5     31    29    93.55\n",
      " 992   21    0   93.33  82.35    14     15   17      0     21    20    95.24\n",
      " 993   42    0   67.65  65.71    23     34   35      6     42    39    92.86\n",
      " 994   11    0  100.00  87.50     7      7    8      0     11    11   100.00\n",
      " 995   18    0  100.00  88.89    16     16   18      0     18    18   100.00\n",
      " 996   21    0   87.50  77.78    14     16   18      2     21    21   100.00\n",
      " 997   34    0   96.55  96.55    28     29   29      0     34    33    97.06\n",
      " 998   22    0  100.00  94.74    18     18   19      0     22    22   100.00\n",
      " 999   18    0   87.50  77.78    14     16   18      2     18    18   100.00\n",
      "1000   24    0   66.67  66.67    16     24   24      6     24    24   100.00\n",
      "1001   28    0  100.00  95.65    22     22   23      0     28    27    96.43\n",
      "1002   17    0  100.00  94.44    17     17   18      0     17    17   100.00\n",
      "1003   21    0  100.00  94.44    17     17   18      0     21    21   100.00\n",
      "1004   35    0   92.31  92.31    24     26   26      0     35    33    94.29\n",
      "1005   17    0  100.00  93.75    15     15   16      0     17    17   100.00\n",
      "1006   21    0   78.95  68.18    15     19   22      4     21    20    95.24\n",
      "1007   13    0   42.86  37.50     3      7    8      3     13    11    84.62\n",
      "1008   16    0   62.50  50.00     5      8   10      1     16    15    93.75\n",
      "1009   16    0   58.33  63.64     7     12   11      0     16    15    93.75\n",
      "1010   40    0   69.23  50.00     9     13   18      4     40    40   100.00\n",
      "1011   56    0   37.50  31.58    12     32   38     15     56    53    94.64\n",
      "1012   29    0   57.89  57.89    11     19   19      4     29    28    96.55\n",
      "1013   17    0   45.45  50.00     5     11   10      0     17    14    82.35\n",
      "1014   39    0   80.00  75.00    24     30   32      6     39    38    97.44\n",
      "1015   67    0   67.31  66.04    35     52   53     11     67    67   100.00\n",
      "1016   40    0   85.19  82.14    23     27   28      0     40    40   100.00\n",
      "1017   31    0   31.82  23.33     7     22   30     12     31    25    80.65\n",
      "1018   35    0   57.58  57.58    19     33   33      9     35    30    85.71\n",
      "1019   43    0   76.00  76.00    19     25   25      2     43    39    90.70\n",
      "1020   28    0   38.46  41.67    10     26   24     10     28    24    85.71\n",
      "1021   21    0   93.75  88.24    15     16   17      0     21    20    95.24\n",
      "1022   16    0   61.54  61.54     8     13   13      2     16    13    81.25\n",
      "1023   14    0   77.78  70.00     7      9   10      0     14    12    85.71\n",
      "1024   11    0  100.00  85.71     6      6    7      0     11    11   100.00\n",
      "1025   20    0   73.33  68.75    11     15   16      3     20    18    90.00\n",
      "1026   30    0   44.83  44.83    13     29   29      8     30    29    96.67\n",
      "1027   11    0  100.00  88.89     8      8    9      0     11    11   100.00\n",
      "1028   25    0   47.37  52.94     9     19   17      3     25    23    92.00\n",
      "1029   28    0  100.00  90.00    18     18   20      0     28    27    96.43\n",
      "1030   13    0  100.00  90.00     9      9   10      0     13    13   100.00\n",
      "1031   29    0   76.00  65.52    19     25   29      0     29    25    86.21\n",
      "1032   11    0  100.00  88.89     8      8    9      0     11    11   100.00\n",
      "1033   21    0   95.00  90.48    19     20   21      0     21    21   100.00\n",
      "1034   40    0   73.53  69.44    25     34   36     10     40    38    95.00\n",
      "1035   18    0   69.23  52.94     9     13   17      1     18    17    94.44\n",
      "1036   37    0   85.71  90.00    18     21   20      0     37    34    91.89\n",
      "1037   18    0   62.50  58.82    10     16   17      4     18    17    94.44\n",
      "1038   25    0   94.74  90.00    18     19   20      0     25    24    96.00\n",
      "1039   14    0   50.00  45.45     5     10   11      2     14    10    71.43\n",
      "1040   29    0   76.92  76.92    20     26   26      5     29    29   100.00\n",
      "1041   21    0   73.33  64.71    11     15   17      0     21    18    85.71\n",
      "1042   19    0   92.86  76.47    13     14   17      1     19    18    94.74\n",
      "1043   12    0  100.00  87.50     7      7    8      0     12    10    83.33\n",
      "1044   15    0   76.47  81.25    13     17   16      0     15    13    86.67\n",
      "1045   34    0   57.14  47.06    16     28   34     10     34    28    82.35\n",
      "1046   36    0   84.00  75.00    21     25   28      2     36    32    88.89\n",
      "1047    9    0  100.00  85.71     6      6    7      0      9     8    88.89\n",
      "1048   38    0   89.66  78.79    26     29   33      3     38    35    92.11\n",
      "1049   35    0   60.00  60.00    15     25   25      5     35    30    85.71\n",
      "1050   32    0   72.00  81.82    18     25   22      1     32    30    93.75\n",
      "1051   38    0   71.88  71.88    23     32   32      5     38    32    84.21\n",
      "1052   17    0  100.00  92.86    13     13   14      0     17    15    88.24\n",
      "1053   18    0   80.00  75.00    12     15   16      1     18    17    94.44\n",
      "1054   18    0   83.33  76.92    10     12   13      1     18    17    94.44\n",
      "1055   47    0   69.23  65.85    27     39   41     10     47    46    97.87\n",
      "1056    7    0  100.00  83.33     5      5    6      0      7     6    85.71\n",
      "1057   20    0   63.16  66.67    12     19   18      2     20    18    90.00\n",
      "1058   26    0   31.43  36.67    11     35   30     14     26    21    80.77\n",
      "1059   20    0   72.22  81.25    13     18   16      1     20    18    90.00\n",
      "1060   26    0   60.00  57.14    12     20   21      5     26    22    84.62\n",
      "1061   37    0   92.86  83.87    26     28   31      1     37    34    91.89\n",
      "1062   21    0   85.71  75.00    12     14   16      2     21    18    85.71\n",
      "1063    9    0  100.00  88.89     8      8    9      0      9     9   100.00\n",
      "1064   38    0   64.29  56.25    18     28   32      6     38    36    94.74\n",
      "1065   15    0   83.33  76.92    10     12   13      0     15    11    73.33\n",
      "1066   26    0   36.36  38.10     8     22   21     11     26    21    80.77\n",
      "1067   11    0  100.00  88.89     8      8    9      0     11    10    90.91\n",
      "1068   15    0   91.67  91.67    11     12   12      0     15    14    93.33\n",
      "1069   28    0   50.00  46.43    13     26   28      6     28    22    78.57\n",
      "1070   37    0   61.90  56.52    13     21   23      6     37    34    91.89\n",
      "1071   10    0   87.50  77.78     7      8    9      0     10     9    90.00\n",
      "1072   25    0   88.89  94.12    16     18   17      0     25    21    84.00\n",
      "1073   37    0   48.28  48.28    14     29   29     14     37    35    94.59\n",
      "1074   32    0   48.15  59.09    13     27   22      4     32    29    90.62\n",
      "1075   19    0   69.23  69.23     9     13   13      1     19    18    94.74\n",
      "1076   16    0   77.78  77.78     7      9    9      0     16    14    87.50\n",
      "1077   28    0   56.00  60.87    14     25   23      4     28    24    85.71\n",
      "1078   34    0   42.31  35.48    11     26   31     12     34    32    94.12\n",
      "1079    7    0  100.00  87.50     7      7    8      0      7     7   100.00\n",
      "1080   48    0   65.00  60.47    26     40   43      5     48    43    89.58\n",
      "1081   18    0   71.43  71.43    10     14   14      1     18    17    94.44\n",
      "1082   20    0  100.00  92.86    13     13   14      0     20    20   100.00\n",
      "1083   26    0   72.73  69.57    16     22   23      3     26    26   100.00\n",
      "1084   32    0  100.00  92.59    25     25   27      0     32    28    87.50\n",
      "1085   35    0   55.88  59.38    19     34   32     10     35    32    91.43\n",
      "1086   35    0   80.65  75.76    25     31   33      3     35    33    94.29\n",
      "1087   19    0   76.92  71.43    10     13   14      2     19    18    94.74\n",
      "1088   24    0   65.00  61.90    13     20   21      2     24    20    83.33\n",
      "1089   18    0  100.00  94.12    16     16   17      0     18    15    83.33\n",
      "1090   16    0   80.00  80.00    12     15   15      0     16    15    93.75\n",
      "1091   17    0   81.25  86.67    13     16   15      0     17    15    88.24\n",
      "1092   13    0   28.57  30.77     4     14   13      5     13     7    53.85\n",
      "1093   45    0   82.86  82.86    29     35   35      0     45    42    93.33\n",
      "1094   47    0   44.12  51.72    15     34   29     10     47    42    89.36\n",
      "1095   28    0   74.07  64.52    20     27   31      5     28    24    85.71\n",
      "1096   30    0   76.67  92.00    23     30   25      0     30    27    90.00\n",
      "1097   11    0  100.00  88.89     8      8    9      0     11    10    90.91\n",
      "1098   14    0   77.78  63.64     7      9   11      2     14    14   100.00\n",
      "1099   18    0   90.91  71.43    10     11   14      1     18    18   100.00\n",
      "1100   18    0   94.74  90.00    18     19   20      0     18    14    77.78\n",
      "1101    3    0  100.00  50.00     1      1    2      0      3     3   100.00\n",
      "1102   29    0   72.73  66.67    16     22   24      4     29    28    96.55\n",
      "1103   46    0   78.95  78.95    30     38   38      6     46    42    91.30\n",
      "1104   22    0   90.48  76.00    19     21   25      0     22    21    95.45\n",
      "1105   25    0   68.42  72.22    13     19   18      3     25    25   100.00\n",
      "1106   30    0   96.15  92.59    25     26   27      1     30    30   100.00\n",
      "1107   37    0   92.11  87.50    35     38   40      0     37    35    94.59\n",
      "1108   16    0   92.31  92.31    12     13   13      0     16    16   100.00\n",
      "1109   17    0  100.00  91.67    11     11   12      0     17    17   100.00\n",
      "1110   18    0   69.23  52.94     9     13   17      3     18    18   100.00\n",
      "1111   13    0   16.67  18.18     2     12   11      4     13    10    76.92\n",
      "1112   28    0  100.00  75.00    21     21   28      0     28    28   100.00\n",
      "1113   42    0   78.12  83.33    25     32   30      0     42    37    88.10\n",
      "1114   25    0   68.18  62.50    15     22   24      5     25    22    88.00\n",
      "1115   38    0   42.42  42.42    14     33   33     17     38    37    97.37\n",
      "1116   34    0   81.48  78.57    22     27   28      3     34    33    97.06\n",
      "1117   45    0   90.00  84.38    27     30   32      2     45    41    91.11\n",
      "1118    6    0  100.00  83.33     5      5    6      0      6     5    83.33\n",
      "1119   44    0   62.50  67.57    25     40   37      9     44    42    95.45\n",
      "1120   23    0   82.35  77.78    14     17   18      0     23    20    86.96\n",
      "1121   26    0   68.18  71.43    15     22   21      4     26    25    96.15\n",
      "1122   47    0   82.93  77.27    34     41   44      4     47    45    95.74\n",
      "1123   29    0   82.35  77.78    14     17   18      1     29    27    93.10\n",
      "1124   25    0   85.71  75.00    12     14   16      2     25    23    92.00\n",
      "1125   32    0   66.67  64.52    20     30   31      6     32    29    90.62\n",
      "1126   26    0   66.67  64.29    18     27   28      6     26    25    96.15\n",
      "1127   15    0   75.00  46.15     6      8   13      3     15    13    86.67\n",
      "1128   22    0  100.00  95.00    19     19   20      0     22    21    95.45\n",
      "1129   29    0   57.14  61.54    16     28   26      6     29    25    86.21\n",
      "1130    7    0  100.00  80.00     4      4    5      0      7     7   100.00\n",
      "1131   13    0   71.43  83.33     5      7    6      0     13    12    92.31\n",
      "1132   31    0   65.22  57.69    15     23   26      2     31    28    90.32\n",
      "1133   13    0   69.23  64.29     9     13   14      2     13    11    84.62\n",
      "1134   33    0   87.10  81.82    27     31   33      4     33    32    96.97\n",
      "1135   22    0   80.00  80.00    12     15   15      0     22    21    95.45\n",
      "1136   15    0   84.62  84.62    11     13   13      0     15    13    86.67\n",
      "1137   12    0   87.50  77.78     7      8    9      0     12    12   100.00\n",
      "1138   45    0   70.45  73.81    31     44   42     10     45    45   100.00\n",
      "1139   16    0   90.00  81.82     9     10   11      0     16    16   100.00\n",
      "1140   30    0   61.76  61.76    21     34   34     11     30    27    90.00\n",
      "1141   15    0   61.54  61.54     8     13   13      1     15    12    80.00\n",
      "1142   21    0  100.00  88.89    16     16   18      0     21    21   100.00\n",
      "1143   18    0   76.47  76.47    13     17   17      1     18    16    88.89\n",
      "1144   23    0   42.86  50.00     9     21   18      3     23    19    82.61\n",
      "1145   20    0   88.89  84.21    16     18   19      0     20    19    95.00\n",
      "1146   24    0   90.00  85.71    18     20   21      0     24    24   100.00\n",
      "1147   25    0   85.00  85.00    17     20   20      1     25    22    88.00\n",
      "1148   24    0   58.82  58.82    10     17   17      2     24    21    87.50\n",
      "1149    5    0  100.00  80.00     4      4    5      0      5     5   100.00\n",
      "1150   19    0   61.54  61.54     8     13   13      4     19    19   100.00\n",
      "1151   25    0  100.00  95.65    22     22   23      0     25    24    96.00\n",
      "1152   35    0   72.22  83.87    26     36   31      3     35    33    94.29\n",
      "1153   26    0   57.14  48.00    12     21   25      9     26    21    80.77\n",
      "1154   25    0  100.00  95.00    19     19   20      0     25    25   100.00\n",
      "1155   30    0   62.07  66.67    18     29   27      5     30    27    90.00\n",
      "1156   14    0   50.00  41.67     5     10   12      4     14    11    78.57\n",
      "1157   14    0   60.00  75.00     9     15   12      0     14    12    85.71\n",
      "1158   32    0   82.61  76.00    19     23   25      2     32    30    93.75\n",
      "1159   20    0   69.23  56.25     9     13   16      3     20    17    85.00\n",
      "1160   17    0  100.00  93.33    14     14   15      0     17    16    94.12\n",
      "1161   11    0  100.00  81.82     9      9   11      0     11     9    81.82\n",
      "1162   28    0   77.27  77.27    17     22   22      3     28    27    96.43\n",
      "1163   27    0   56.52  56.52    13     23   23      8     27    25    92.59\n",
      "1164   29    0   53.33  55.17    16     30   29      2     29    24    82.76\n",
      "1165   18    0   66.67  66.67    10     15   15      2     18    16    88.89\n",
      "1166   25    0   57.69  60.00    15     26   25      5     25    22    88.00\n",
      "1167   25    0   86.96  95.24    20     23   21      0     25    23    92.00\n",
      "1168   21    0   77.78  70.00    14     18   20      5     21    20    95.24\n",
      "1169   39    0   62.50  58.82    20     32   34     11     39    35    89.74\n",
      "1170   10    0  100.00  88.89     8      8    9      0     10    10   100.00\n",
      "1171   26    0  100.00  94.74    18     18   19      0     26    24    92.31\n",
      "1172   28    0   59.09  72.22    13     22   18      3     28    27    96.43\n",
      "1173   54    0   73.91  72.34    34     46   47      4     54    52    96.30\n",
      "1174   21    0   76.47  68.42    13     17   19      2     21    20    95.24\n",
      "1175   26    0   81.82  78.26    18     22   23      3     26    24    92.31\n",
      "1176   42    0   78.57  78.57    22     28   28      0     42    39    92.86\n",
      "1177   34    0   74.07  76.92    20     27   26      2     34    33    97.06\n",
      "1178   37    0   71.43  74.07    20     28   27      4     37    34    91.89\n",
      "1179   39    0   93.55  85.29    29     31   34      0     39    38    97.44\n",
      "1180   34    0   51.72  46.88    15     29   32     11     34    31    91.18\n",
      "1181   38    0   82.35  82.35    28     34   34      0     38    36    94.74\n",
      "1182   25    0   82.61  82.61    19     23   23      2     25    25   100.00\n",
      "1183   45    0   86.84  86.84    33     38   38      3     45    44    97.78\n",
      "1184   17    0   92.31  85.71    12     13   14      0     17    17   100.00\n",
      "1185   47    0   82.86  82.86    29     35   35      1     47    43    91.49\n",
      "1186   32    0   77.27  73.91    17     22   23      4     32    32   100.00\n",
      "1187   19    0   76.47  76.47    13     17   17      3     19    19   100.00\n",
      "1188   12    0   71.43  62.50     5      7    8      0     12    10    83.33\n",
      "1189   23    0   86.36  79.17    19     22   24      2     23    21    91.30\n",
      "1190   29    0   70.83  77.27    17     24   22      2     29    25    86.21\n",
      "1191   18    0  100.00  93.33    14     14   15      0     18    16    88.89\n",
      "1192   25    0   93.75  83.33    15     16   18      1     25    24    96.00\n",
      "1193   30    0   55.56  50.00    15     27   30      7     30    26    86.67\n",
      "1194   28    0   86.36  79.17    19     22   24      2     28    26    92.86\n",
      "1195   22    0   40.00  42.11     8     20   19      6     22    18    81.82\n",
      "1196   34    0   86.21  86.21    25     29   29      3     34    32    94.12\n",
      "1197   36    0  100.00  96.43    27     27   28      0     36    35    97.22\n",
      "1198   18    0   76.47  72.22    13     17   18      2     18    15    83.33\n",
      "1199   34    0   91.30  84.00    21     23   25      2     34    33    97.06\n",
      "1200   38    0   48.15  50.00    13     27   26      9     38    35    92.11\n",
      "1201   24    0   57.89  68.75    11     19   16      3     24    22    91.67\n",
      "1202   19    0   66.67  58.82    10     15   17      2     19    17    89.47\n",
      "1203   21    0  100.00  92.31    12     12   13      0     21    21   100.00\n",
      "1204   22    0  100.00  94.44    17     17   18      0     22    22   100.00\n",
      "1205   13    0   90.00  75.00     9     10   12      0     13    12    92.31\n",
      "1206   20    0   85.71  80.00    12     14   15      1     20    19    95.00\n",
      "1207   17    0   85.71  80.00    12     14   15      1     17    17   100.00\n",
      "1208   28    0   88.00  84.62    22     25   26      1     28    26    92.86\n",
      "1209   18    0   92.86  86.67    13     14   15      0     18    17    94.44\n",
      "1210   28    0   75.00  66.67    18     24   27      5     28    26    92.86\n",
      "1211   30    0   50.00  45.45    10     20   22      6     30    27    90.00\n",
      "1212   25    0   82.35  70.00    14     17   20      0     25    25   100.00\n",
      "1213   18    0  100.00  91.67    11     11   12      0     18    18   100.00\n",
      "1214   19    0   80.00  92.31    12     15   13      0     19    18    94.74\n",
      "1215   21    0   80.00  63.16    12     15   19      2     21    19    90.48\n",
      "1216   14    0   55.56  41.67     5      9   12      2     14    12    85.71\n",
      "1217   24    0   75.00  57.14    12     16   21      4     24    24   100.00\n",
      "1218   37    0   96.30  89.66    26     27   29      1     37    36    97.30\n",
      "1219   12    0  100.00  90.00     9      9   10      0     12    12   100.00\n",
      "1220   31    0   79.31  79.31    23     29   29      2     31    27    87.10\n",
      "1221   20    0   93.75  83.33    15     16   18      1     20    20   100.00\n",
      "1222   36    0   75.86  78.57    22     29   28      4     36    34    94.44\n",
      "1223   26    0   73.68  77.78    14     19   18      1     26    26   100.00\n",
      "1224   54    0   58.14  55.56    25     43   45     15     54    50    92.59\n",
      "1225   33    0   96.55  96.55    28     29   29      0     33    31    93.94\n",
      "1226   32    0   91.30  87.50    21     23   24      1     32    30    93.75\n",
      "1227   12    0   83.33  83.33    10     12   12      0     12    11    91.67\n",
      "1228   37    0   78.57  81.48    22     28   27      2     37    35    94.59\n",
      "1229   14    0   87.50  82.35    14     16   17      0     14    14   100.00\n",
      "1230   24    0   90.48  86.36    19     21   22      0     24    22    91.67\n",
      "1231   24    0   61.54  57.14     8     13   14      3     24    20    83.33\n",
      "1232   26    0   66.67  63.64    14     21   22      6     26    25    96.15\n",
      "1233   28    0   85.00  77.27    17     20   22      2     28    28   100.00\n",
      "1234   23    0  100.00  95.24    20     20   21      0     23    23   100.00\n",
      "1235   20    0   92.31  75.00    12     13   16      1     20    20   100.00\n",
      "1236   23    0   87.50  77.78    14     16   18      1     23    20    86.96\n",
      "1237   30    0   81.82  66.67    18     22   27      4     30    28    93.33\n",
      "1238   16    0   83.33  83.33    10     12   12      1     16    15    93.75\n",
      "1239   44    0   68.42  68.42    26     38   38      8     44    41    93.18\n",
      "1240   33    0   55.00  42.31    11     20   26      9     33    29    87.88\n",
      "1241   18    0   91.67  68.75    11     12   16      0     18    17    94.44\n",
      "1242   20    0   70.00  70.00     7     10   10      1     20    17    85.00\n",
      "1243   40    0   76.67  82.14    23     30   28      2     40    38    95.00\n",
      "1244   17    0   81.25  81.25    13     16   16      2     17    17   100.00\n",
      "1245   18    0   90.91  71.43    10     11   14      1     18    18   100.00\n",
      "1246   40    0   79.41  75.00    27     34   36      2     40    38    95.00\n",
      "1247   35    0   75.86  66.67    22     29   33      7     35    33    94.29\n",
      "1248   24    0   54.55  54.55    12     22   22      7     24    21    87.50\n",
      "1249   15    0   92.31  70.59    12     13   17      0     15    13    86.67\n",
      "1250   19    0   40.00  42.86     6     15   14      5     19    17    89.47\n",
      "1251   32    0   88.00  84.62    22     25   26      1     32    31    96.88\n",
      "1252   41    0   67.65  63.89    23     34   36      8     41    36    87.80\n",
      "1253   22    0   88.24  78.95    15     17   19      2     22    19    86.36\n",
      "1254   22    0   73.68  66.67    14     19   21      3     22    17    77.27\n",
      "1255   31    0   93.75  90.91    30     32   33      0     31    27    87.10\n",
      "1256   40    0   80.56  76.32    29     36   38      6     40    38    95.00\n",
      "1257   40    0   77.78  67.74    21     27   31      3     40    35    87.50\n",
      "1258    6    0  100.00  80.00     4      4    5      0      6     6   100.00\n",
      "1259   43    0   65.52  70.37    19     29   27      1     43    40    93.02\n",
      "1260   46    0   42.86  46.15    12     28   26      9     46    40    86.96\n",
      "1261   23    0   92.59  89.29    25     27   28      1     23    21    91.30\n",
      "1262   37    0   90.00  84.38    27     30   32      3     37    33    89.19\n",
      "1263   15    0   83.33  76.92    10     12   13      0     15    13    86.67\n",
      "1264   20    0   40.00  40.00     6     15   15      5     20    16    80.00\n",
      "1265   23    0   52.94  52.94     9     17   17      6     23    19    82.61\n",
      "1266   30    0   65.22  57.69    15     23   26      4     30    28    93.33\n",
      "1267   20    0  100.00  93.75    15     15   16      0     20    18    90.00\n",
      "1268   15    0   50.00  54.55     6     12   11      2     15    15   100.00\n",
      "1269   51    0   68.57  58.54    24     35   41      5     51    44    86.27\n",
      "1270   42    0   42.86  37.50    12     28   32     14     42    39    92.86\n",
      "1271   31    0   68.18  57.69    15     22   26      5     31    28    90.32\n",
      "1272   34    0   54.17  52.00    13     24   25      8     34    28    82.35\n",
      "1273   29    0   76.67  79.31    23     30   29      2     29    25    86.21\n",
      "1274   19    0   72.73  72.73     8     11   11      1     19    18    94.74\n",
      "1275   24    0   57.89  52.38    11     19   21      4     24    23    95.83\n",
      "1276   13    0   81.82  69.23     9     11   13      0     13    12    92.31\n",
      "1277   34    0   85.00  80.95    17     20   21      0     34    25    73.53\n",
      "1278   28    0   86.36  79.17    19     22   24      1     28    27    96.43\n",
      "1279   14    0   54.55  60.00     6     11   10      0     14    12    85.71\n",
      "1280   17    0   42.86  54.55     6     14   11      2     17    13    76.47\n",
      "1281   34    0   70.83  68.00    17     24   25      6     34    32    94.12\n",
      "1282   10    0   85.71  66.67     6      7    9      0     10     8    80.00\n",
      "1283   21    0   69.23  56.25     9     13   16      3     21    17    80.95\n",
      "1284   26    0   71.43  65.22    15     21   23      2     26    19    73.08\n",
      "1285   12    0   66.67  60.00     6      9   10      0     12    11    91.67\n",
      "1286   11    0   33.33  40.00     2      6    5      1     11     9    81.82\n",
      "1287   40    0   64.29  58.06    18     28   31      6     40    36    90.00\n",
      "1288   36    0   73.91  70.83    17     23   24      5     36    32    88.89\n",
      "1289   35    0   80.00  76.92    20     25   26      2     35    33    94.29\n",
      "1290   20    0   81.25  68.42    13     16   19      2     20    18    90.00\n",
      "1291   19    0   84.62  91.67    11     13   12      0     19    14    73.68\n",
      "1292   37    0   68.00  62.96    17     25   27      5     37    32    86.49\n",
      "1293   13    0   57.14  57.14     4      7    7      1     13    12    92.31\n",
      "1294    8    0   60.00  42.86     3      5    7      0      8     8   100.00\n",
      "1295   22    0   45.00  52.94     9     20   17      7     22    18    81.82\n",
      "1296   40    0   64.86  63.16    24     37   38     10     40    39    97.50\n",
      "1297   32    0   96.55  90.32    28     29   31      0     32    31    96.88\n",
      "1298   20    0   68.75  64.71    11     16   17      1     20    17    85.00\n",
      "1299   29    0   56.00  58.33    14     25   24      6     29    25    86.21\n",
      "1300   27    0   68.42  76.47    13     19   17      0     27    23    85.19\n",
      "1301   27    0   93.75  78.95    15     16   19      1     27    26    96.30\n",
      "1302   26    0   77.78  66.67    14     18   21      1     26    25    96.15\n",
      "1303   11    0  100.00  88.89     8      8    9      0     11    10    90.91\n",
      "1304   40    0   52.63  46.51    20     38   43     13     40    37    92.50\n",
      "1305   27    0  100.00  90.48    19     19   21      0     27    27   100.00\n",
      "1306   17    0   35.71  29.41     5     14   17      6     17    14    82.35\n",
      "1307   50    0   57.14  50.00    20     35   40     13     50    47    94.00\n",
      "1308   24    0   47.62  55.56    10     21   18      7     24    24   100.00\n",
      "1309   29    0   56.52  59.09    13     23   22      5     29    27    93.10\n",
      "1310   38    0   82.14  74.19    23     28   31      2     38    34    89.47\n",
      "1311   24    0   78.95  68.18    15     19   22      2     24    23    95.83\n",
      "1312   10    0  100.00  88.89     8      8    9      0     10    10   100.00\n",
      "1313   25    0   77.78  73.68    14     18   19      2     25    21    84.00\n",
      "1314   22    0  100.00  93.75    15     15   16      0     22    22   100.00\n",
      "1315   22    0   58.33  63.64     7     12   11      2     22    16    72.73\n",
      "1316   33    0   95.65  81.48    22     23   27      0     33    30    90.91\n",
      "1317   31    0   77.78  58.33    14     18   24      2     31    30    96.77\n",
      "1318   27    0   23.53  25.00     4     17   16      6     27    24    88.89\n",
      "1319   25    0   57.89  55.00    11     19   20      1     25    22    88.00\n",
      "1320   32    0   75.86  81.48    22     29   27      2     32    28    87.50\n",
      "1321   34    0   91.30  91.30    21     23   23      0     34    32    94.12\n",
      "1322   20    0   33.33  35.29     6     18   17      8     20    17    85.00\n",
      "1323   39    0   58.33  58.33    21     36   36     11     39    34    87.18\n",
      "1324   45    0   88.24  78.95    30     34   38      4     45    41    91.11\n",
      "1325   21    0   80.00  70.59    12     15   17      1     21    18    85.71\n",
      "1326   30    0   96.00  92.31    24     25   26      0     30    27    90.00\n",
      "1327   17    0   53.85  50.00     7     13   14      4     17    16    94.12\n",
      "1328   23    0   68.18  71.43    15     22   21      1     23    20    86.96\n",
      "1329   24    0  100.00  93.33    14     14   15      0     24    23    95.83\n",
      "1330   47    0   55.88  55.88    19     34   34     11     47    44    93.62\n",
      "1331    9    0   50.00  40.00     4      8   10      4      9     8    88.89\n",
      "1332   16    0   35.29  50.00     6     17   12      4     16    13    81.25\n",
      "1333   38    0   66.67  64.29    18     27   28      6     38    37    97.37\n",
      "1334   34    0   75.00  84.00    21     28   25      0     34    31    91.18\n",
      "1335   19    0  100.00  93.33    14     14   15      0     19    16    84.21\n",
      "1336   19    0   83.33  71.43    10     12   14      0     19    15    78.95\n",
      "1337   15    0  100.00  80.00     8      8   10      0     15    12    80.00\n",
      "1338   20    0   75.00  54.55     6      8   11      0     20    16    80.00\n",
      "1339   34    0   92.31  92.31    24     26   26      0     34    34   100.00\n",
      "1340   46    0   70.59  68.57    24     34   35      7     46    40    86.96\n",
      "1341   24    0   64.29  50.00     9     14   18      2     24    18    75.00\n",
      "1342   52    0   47.22  42.50    17     36   40     11     52    48    92.31\n",
      "1343   30    0   62.07  60.00    18     29   30      4     30    24    80.00\n",
      "1344   19    0   92.86  81.25    13     14   16      1     19    18    94.74\n",
      "1345   32    0   81.48  81.48    22     27   27      2     32    32   100.00\n",
      "1346   62    0   67.35  68.75    33     49   48      9     62    58    93.55\n",
      "1347   25    0   89.47  80.95    17     19   21      1     25    25   100.00\n",
      "1348   27    0   30.43  33.33     7     23   21     12     27    22    81.48\n",
      "1349   46    0   66.67  61.11    22     33   36      6     46    42    91.30\n",
      "1350   39    0   61.54  66.67    16     26   24      6     39    38    97.44\n",
      "1351   19    0   64.29  64.29     9     14   14      2     19    16    84.21\n",
      "1352   33    0   77.78  77.78    21     27   27      1     33    29    87.88\n",
      "1353    9    0   80.00  50.00     4      5    8      0      9     8    88.89\n",
      "1354   17    0   88.24  88.24    15     17   17      0     17    16    94.12\n",
      "1355   38    0   79.31  74.19    23     29   31      6     38    33    86.84\n",
      "1356   38    0   78.79  76.47    26     33   34      4     38    35    92.11\n",
      "1357   13    0   81.82  75.00     9     11   12      2     13    13   100.00\n",
      "1358   30    0   76.19  61.54    16     21   26      4     30    25    83.33\n",
      "1359   43    0   71.88  67.65    23     32   34      6     43    42    97.67\n",
      "1360   30    0   57.14  60.00    12     21   20      3     30    26    86.67\n",
      "1361   33    0   73.68  73.68    14     19   19      4     33    33   100.00\n",
      "1362   21    0   58.33  53.85     7     12   13      1     21    16    76.19\n",
      "1363   30    0   88.00  78.57    22     25   28      3     30    27    90.00\n",
      "1364   12    0  100.00  90.91    10     10   11      0     12    11    91.67\n",
      "1365   39    0   83.87  83.87    26     31   31      3     39    38    97.44\n",
      "1366   14    0   81.82  69.23     9     11   13      0     14    14   100.00\n",
      "1367   18    0   33.33  33.33     4     12   12      5     18    16    88.89\n",
      "1368   40    0   77.14  81.82    27     35   33      2     40    38    95.00\n",
      "1369   41    0   61.76  60.00    21     34   35      7     41    38    92.68\n",
      "1370    9    0   66.67  44.44     4      6    9      2      9     9   100.00\n",
      "1371   20    0   78.95  71.43    15     19   21      1     20    20   100.00\n",
      "1372   19    0   50.00  38.10     8     16   21     10     19    18    94.74\n",
      "1373   24    0   71.43  83.33    15     21   18      2     24    23    95.83\n",
      "1374   26    0   91.30  91.30    21     23   23      0     26    26   100.00\n",
      "1375    7    0  100.00  66.67     4      4    6      0      7     7   100.00\n",
      "1376   36    0   62.50  68.97    20     32   29      6     36    30    83.33\n",
      "1377   27    0   68.42  61.90    13     19   21      4     27    27   100.00\n",
      "1378   12    0  100.00  90.00     9      9   10      0     12    11    91.67\n",
      "1379   18    0  100.00  87.50    14     14   16      0     18    16    88.89\n",
      "1380   12    0  100.00  87.50     7      7    8      0     12    10    83.33\n",
      "1381   43    0   72.73  61.54    24     33   39      7     43    39    90.70\n",
      "1382   22    0   88.89  76.19    16     18   21      0     22    19    86.36\n",
      "1383   25    0   68.18  68.18    15     22   22      6     25    25   100.00\n",
      "1384   23    0   75.00  75.00    15     20   20      0     23    21    91.30\n",
      "1385    8    0   66.67  60.00     6      9   10      0      8     8   100.00\n",
      "1386   27    0  100.00  89.66    26     26   29      0     27    26    96.30\n",
      "1387   28    0   40.91  50.00     9     22   18      6     28    25    89.29\n",
      "1388   35    0   78.12  80.65    25     32   31      3     35    32    91.43\n",
      "1389   13    0  100.00  75.00     9      9   12      0     13    13   100.00\n",
      "1390   26    0   92.59  92.59    25     27   27      1     26    26   100.00\n",
      "1391   12    0  100.00  91.67    11     11   12      0     12    12   100.00\n",
      "1392   40    0   74.07  64.52    20     27   31      6     40    38    95.00\n",
      "1393   24    0   95.45  95.45    21     22   22      0     24    23    95.83\n",
      "1394   22    0   70.59  80.00    12     17   15      1     22    20    90.91\n",
      "1395   24    0   89.47  89.47    17     19   19      0     24    22    91.67\n",
      "1396   40    0   64.86  63.16    24     37   38     11     40    40   100.00\n",
      "1397    9    0  100.00  87.50     7      7    8      0      9     7    77.78\n",
      "1398   17    0   92.31  85.71    12     13   14      0     17    15    88.24\n",
      "1399   10    0  100.00  87.50     7      7    8      0     10     9    90.00\n",
      "1400   30    0   63.64  60.87    14     22   23      0     30    25    83.33\n",
      "1401   23    0   92.86  81.25    13     14   16      0     23    21    91.30\n",
      "1402   25    0   76.19  69.57    16     21   23      2     25    23    92.00\n",
      "1403    9    0  100.00  87.50     7      7    8      0      9     8    88.89\n",
      "1404   19    0   92.31  92.31    12     13   13      0     19    18    94.74\n",
      "1405   13    0  100.00  90.91    10     10   11      0     13    13   100.00\n",
      "1406   12    0   85.71  66.67     6      7    9      0     12    11    91.67\n",
      "1407   16    0   92.86  92.86    13     14   14      0     16    16   100.00\n",
      "1408   30    0   92.59  92.59    25     27   27      0     30    28    93.33\n",
      "1409   26    0   64.00  66.67    16     25   24      4     26    24    92.31\n",
      "1410   16    0   92.86  92.86    13     14   14      0     16    14    87.50\n",
      "1411   33    0   76.00  70.37    19     25   27      2     33    30    90.91\n",
      "1412   20    0  100.00  89.47    17     17   19      0     20    18    90.00\n",
      "1413   27    0   80.95  94.44    17     21   18      0     27    24    88.89\n",
      "1414    8    0   87.50  87.50     7      8    8      0      8     8   100.00\n",
      "1415   33    0   80.65  71.43    25     31   35      4     33    30    90.91\n",
      "1416   15    0  100.00  81.82     9      9   11      0     15    15   100.00\n",
      "1417    6    0   40.00  40.00     2      5    5      1      6     3    50.00\n",
      "1418    6    0   60.00  60.00     3      5    5      1      6     4    66.67\n",
      "1419    8    0  100.00  80.00     4      4    5      0      8     8   100.00\n",
      "1420   25    0   75.00  70.59    12     16   17      1     25    24    96.00\n",
      "1421   11    0   87.50  77.78     7      8    9      0     11    11   100.00\n",
      "1422   27    0   82.35  73.68    14     17   19      1     27    24    88.89\n",
      "1423   21    0   88.24  68.18    15     17   22      2     21    20    95.24\n",
      "1424   24    0   72.22  65.00    13     18   20      4     24    22    91.67\n",
      "1425   26    0   73.68  70.00    14     19   20      5     26    24    92.31\n",
      "1426   12    0  100.00  80.00     8      8   10      0     12    11    91.67\n",
      "1427   26    0   86.96  71.43    20     23   28      2     26    24    92.31\n",
      "1428   18    0   84.62  78.57    11     13   14      0     18    17    94.44\n",
      "1429   19    0  100.00  90.91    10     10   11      0     19    19   100.00\n",
      "1430   28    0   22.73  29.41     5     22   17      7     28    24    85.71\n",
      "1431   29    0   57.89  64.71    11     19   17      4     29    27    93.10\n",
      "1432   16    0   75.00  69.23     9     12   13      1     16    14    87.50\n",
      "1433    5    0    0.00   0.00     0      4    2      0      5     1    20.00\n",
      "1434   12    0   30.00  30.00     3     10   10      5     12     6    50.00\n",
      "1435   15    0   76.92  76.92    10     13   13      0     15    13    86.67\n",
      "1436   34    0   84.62  73.33    22     26   30      5     34    33    97.06\n",
      "1437   14    0   50.00  46.67     7     14   15      4     14    10    71.43\n",
      "1438   11    0   88.89  72.73     8      9   11      1     11    11   100.00\n",
      "1439   24    0   87.50  87.50    21     24   24      2     24    22    91.67\n",
      "1440   25    0   68.18  71.43    15     22   21      2     25    22    88.00\n",
      "1441   10    0   44.44  33.33     4      9   12      1     10     7    70.00\n",
      "1442   29    0   66.67  66.67    16     24   24      1     29    26    89.66\n",
      "1443   17    0   63.64  63.64     7     11   11      1     17    13    76.47\n",
      "1444   25    0   52.00  56.52    13     25   23      6     25    22    88.00\n",
      "1445   19    0   83.33  78.95    15     18   19      0     19    16    84.21\n",
      "1446   16    0   23.08  18.75     3     13   16      7     16    12    75.00\n",
      "1447    6    0   50.00  50.00     3      6    6      1      6     4    66.67\n",
      "1448   11    0   75.00  75.00     6      8    8      0     11    11   100.00\n",
      "1449   19    0   20.00  15.79     3     15   19     11     19    17    89.47\n",
      "1450   34    0   57.14  52.63    20     35   38     10     34    32    94.12\n",
      "1451   17    0   50.00  60.00     9     18   15      4     17    15    88.24\n",
      "1452   14    0  100.00  90.00     9      9   10      0     14    12    85.71\n",
      "1453   20    0  100.00  93.33    14     14   15      0     20    20   100.00\n",
      "1454   18    0   78.57  78.57    11     14   14      1     18    15    83.33\n",
      "1455   18    0   87.50  77.78    14     16   18      1     18    13    72.22\n",
      "1456   27    0   71.43  74.07    20     28   27      5     27    25    92.59\n",
      "1457   32    0   83.33  83.33    20     24   24      1     32    30    93.75\n",
      "1458   12    0   80.00  66.67     8     10   12      0     12    11    91.67\n",
      "1459   12    0   80.00  66.67     8     10   12      0     12    10    83.33\n",
      "1460   13    0   46.15  46.15     6     13   13      4     13    12    92.31\n",
      "1461   22    0   73.68  60.87    14     19   23      1     22    18    81.82\n",
      "1462   27    0   69.57  69.57    16     23   23      2     27    22    81.48\n",
      "1463    3    0  100.00  50.00     1      1    2      0      3     1    33.33\n",
      "1464   25    0   72.73  55.17    16     22   29      5     25    20    80.00\n",
      "1465   28    0   75.00  65.22    15     20   23      4     28    25    89.29\n",
      "1466   17    0   61.54  53.33     8     13   15      4     17    16    94.12\n",
      "1467   21    0   64.71  61.11    11     17   18      2     21    18    85.71\n",
      "1468   28    0   60.00  54.55    12     20   22      5     28    27    96.43\n",
      "1469   17    0   38.46  33.33     5     13   15      5     17    13    76.47\n",
      "1470   24    0   47.37  50.00     9     19   18      5     24    22    91.67\n",
      "1471   13    0   70.00  63.64     7     10   11      0     13     9    69.23\n",
      "1472    8    0   80.00  57.14     4      5    7      0      8     5    62.50\n",
      "1473   16    0   37.50  46.15     6     16   13      4     16    12    75.00\n",
      "1474   36    0   76.19  69.57    16     21   23      4     36    32    88.89\n",
      "1475   31    0   94.74  81.82    18     19   22      0     31    30    96.77\n",
      "1476   28    0   96.30  89.66    26     27   29      0     28    27    96.43\n",
      "1477   31    0   81.48  81.48    22     27   27      2     31    28    90.32\n",
      "1478   22    0   69.57  80.00    16     23   20      1     22    21    95.45\n",
      "1479   27    0   86.36  86.36    19     22   22      0     27    22    81.48\n",
      "1480   23    0   65.00  68.42    13     20   19      5     23    22    95.65\n",
      "1481   24    0   76.47  76.47    13     17   17      1     24    20    83.33\n",
      "1482   30    0   79.17  76.00    19     24   25      3     30    24    80.00\n",
      "1483   19    0   92.31  92.31    12     13   13      0     19    18    94.74\n",
      "1484   13    0  100.00  88.89     8      8    9      0     13    13   100.00\n",
      "1485   13    0   54.55  60.00     6     11   10      0     13    12    92.31\n",
      "1486    9    0  100.00  88.89     8      8    9      0      9     9   100.00\n",
      "1487   11    0   81.82  69.23     9     11   13      2     11    10    90.91\n",
      "1488   40    0   85.19  85.19    23     27   27      0     40    36    90.00\n",
      "1489   21    0   88.89  84.21    16     18   19      0     21    19    90.48\n",
      "1490    6    0   25.00  20.00     1      4    5      0      6     5    83.33\n",
      "1491   19    0   82.35  77.78    14     17   18      0     19    16    84.21\n",
      "1492   15    0   75.00  64.29     9     12   14      1     15    14    93.33\n",
      "1493   43    0   67.74  72.41    21     31   29      5     43    41    95.35\n",
      "1494   21    0   69.23  69.23     9     13   13      1     21    15    71.43\n",
      "1495   22    0   61.54  53.33     8     13   15      3     22    19    86.36\n",
      "1496   16    0   85.71  60.00     6      7   10      0     16    14    87.50\n",
      "1497   34    0   35.71  31.25    10     28   32     16     34    29    85.29\n",
      "1498   17    0   90.00  81.82     9     10   11      0     17    14    82.35\n",
      "1499    2    0  100.00  50.00     1      1    2      0      2     2   100.00\n",
      "1500   16    0   30.77  28.57     4     13   14      7     16    13    81.25\n",
      "1501   16    0  100.00  90.91    10     10   11      0     16    15    93.75\n",
      "1502   29    0   55.00  52.38    11     20   21      5     29    24    82.76\n",
      "1503   40    0   80.65  78.12    25     31   32      0     40    38    95.00\n",
      "1504   46    0   47.06  48.48    16     34   33      9     46    41    89.13\n",
      "1505   19    0   68.75  61.11    11     16   18      2     19    15    78.95\n",
      "1506   22    0  100.00  94.44    17     17   18      0     22    21    95.45\n",
      "1507   17    0   62.50  58.82    10     16   17      2     17    14    82.35\n",
      "1508   11    0  100.00  87.50     7      7    8      0     11    11   100.00\n",
      "1509   30    0   78.95  75.00    15     19   20      2     30    27    90.00\n",
      "1510   31    0   86.96  86.96    20     23   23      0     31    30    96.77\n",
      "1511   31    0   76.19  59.26    16     21   27      4     31    23    74.19\n",
      "1512   36    0   69.70  58.97    23     33   39      5     36    34    94.44\n",
      "1513   24    0   95.45  91.30    21     22   23      0     24    22    91.67\n",
      "1514   21    0   92.86  86.67    13     14   15      0     21    20    95.24\n",
      "1515   12    0   84.62  84.62    11     13   13      0     12    12   100.00\n",
      "1516   39    0   36.36  32.43    12     33   37     11     39    32    82.05\n",
      "1517   39    0   79.31  67.65    23     29   34      5     39    33    84.62\n",
      "1518   24    0   94.12  84.21    16     17   19      1     24    23    95.83\n",
      "1519   17    0   78.57  91.67    11     14   12      0     17    15    88.24\n",
      "1520    3    0    0.00   0.00     0      4    3      0      3     1    33.33\n",
      "1521   37    0   43.24  50.00    16     37   32     10     37    32    86.49\n",
      "1522   26    0   58.33  70.00    14     24   20      3     26    24    92.31\n",
      "1523   34    0   80.00  71.43    20     25   28      1     34    31    91.18\n",
      "1524   40    0   41.67  38.46    15     36   39     11     40    33    82.50\n",
      "1525   35    0   35.14  35.14    13     37   37     15     35    29    82.86\n",
      "1526   33    0   30.00  33.33     9     30   27     14     33    26    78.79\n",
      "1527   10    0   80.00  72.73     8     10   11      0     10     9    90.00\n",
      "1528   48    0   64.52  68.97    20     31   29      7     48    43    89.58\n",
      "1529   11    0   72.73  80.00     8     11   10      0     11     8    72.73\n",
      "1530   16    0   54.55  50.00     6     11   12      1     16    13    81.25\n",
      "1531   19    0   85.71  80.00    12     14   15      0     19    18    94.74\n",
      "1532   25    0   72.73  76.19    16     22   21      3     25    23    92.00\n",
      "1533   56    0   66.67  56.52    26     39   46     11     56    49    87.50\n",
      "1534   41    0   74.29  74.29    26     35   35      2     41    35    85.37\n",
      "1535   26    0   75.00  65.22    15     20   23      3     26    21    80.77\n",
      "1536   12    0   62.50  55.56     5      8    9      0     12    11    91.67\n",
      "1537   26    0   71.43  62.50    15     21   24      4     26    24    92.31\n",
      "1538   21    0   70.00  73.68    14     20   19      2     21    17    80.95\n",
      "1539   33    0   68.00  62.96    17     25   27      2     33    30    90.91\n",
      "1540   16    0   63.64  63.64     7     11   11      1     16    12    75.00\n",
      "1541   46    0   62.86  56.41    22     35   39     13     46    41    89.13\n",
      "1542   30    0   90.91  80.00    20     22   25      0     30    27    90.00\n",
      "1543   24    0   54.17  59.09    13     24   22      6     24    22    91.67\n",
      "1544   26    0   80.95  73.91    17     21   23      2     26    24    92.31\n",
      "1545   36    0   60.61  55.56    20     33   36     10     36    33    91.67\n",
      "1546   22    0   80.00  84.21    16     20   19      0     22    20    90.91\n",
      "1547   23    0   75.00  63.16    12     16   19      2     23    20    86.96\n",
      "1548   28    0   77.78  82.35    14     18   17      1     28    26    92.86\n",
      "1549   21    0   85.71  75.00    12     14   16      0     21    20    95.24\n",
      "1550    3    0    0.00   0.00     0      3    3      0      3     3   100.00\n",
      "1551   18    0   53.33  61.54     8     15   13      2     18    14    77.78\n",
      "1552   15    0   61.54  61.54     8     13   13      0     15    12    80.00\n",
      "1553    4    0    0.00   0.00     0      4    3      0      4     1    25.00\n",
      "1554   25    0   73.33  68.75    11     15   16      2     25    21    84.00\n",
      "1555   25    0   60.00  50.00    12     20   24      9     25    22    88.00\n",
      "1556   32    0   76.00  79.17    19     25   24      3     32    31    96.88\n",
      "1557   22    0   87.50  73.68    14     16   19      1     22    22   100.00\n",
      "1558   15    0   70.00  87.50     7     10    8      0     15    14    93.33\n",
      "1559   29    0   47.62  41.67    10     21   24      9     29    25    86.21\n",
      "1560   38    0   34.38  31.43    11     32   35     17     38    32    84.21\n",
      "1561   20    0   26.32  23.81     5     19   21     12     20    18    90.00\n",
      "1562   32    0   95.00  82.61    19     20   23      1     32    32   100.00\n",
      "1563   36    0   68.57  68.57    24     35   35      6     36    34    94.44\n",
      "1564   17    0  100.00  78.57    11     11   14      0     17    15    88.24\n",
      "1565   14    0   69.23  60.00     9     13   15      4     14    12    85.71\n",
      "1566   28    0   77.78  66.67    14     18   21      2     28    26    92.86\n",
      "1567   22    0   83.33  75.00    15     18   20      0     22    18    81.82\n",
      "1568   28    0   73.68  73.68    14     19   19      2     28    26    92.86\n",
      "1569   18    0   87.50  87.50    14     16   16      1     18    17    94.44\n",
      "1570   38    0   59.26  51.61    16     27   31      8     38    38   100.00\n",
      "1571   24    0   72.22  65.00    13     18   20      4     24    22    91.67\n",
      "1572    8    0   75.00  75.00     6      8    8      0      8     7    87.50\n",
      "1573   32    0   95.24  90.91    20     21   22      0     32    30    93.75\n",
      "1574   40    0   82.76  75.00    24     29   32      4     40    39    97.50\n",
      "1575   31    0   31.82  31.82     7     22   22     10     31    27    87.10\n",
      "1576   12    0  100.00  90.91    10     10   11      0     12    12   100.00\n",
      "1577   15    0   69.23  60.00     9     13   15      0     15    13    86.67\n",
      "1578   26    0   66.67  60.87    14     21   23      7     26    23    88.46\n",
      "1579   20    0   77.78  63.64    14     18   22      6     20    17    85.00\n",
      "1580    9    0   87.50  63.64     7      8   11      0      9     8    88.89\n",
      "1581   22    0   88.89  84.21    16     18   19      1     22    20    90.91\n",
      "1582   49    0   87.88  82.86    29     33   35      4     49    48    97.96\n",
      "1583   13    0   75.00  69.23     9     12   13      3     13    12    92.31\n",
      "1584   17    0   83.33  83.33    10     12   12      1     17    14    82.35\n",
      "1585   35    0   60.71  62.96    17     28   27      5     35    32    91.43\n",
      "1586   25    0   88.89  72.73    16     18   22      2     25    23    92.00\n",
      "1587   18    0   50.00  70.00     7     14   10      2     18    17    94.44\n",
      "1588   34    0   51.72  60.00    15     29   25      5     34    29    85.29\n",
      "1589   44    0   83.78  81.58    31     37   38      4     44    43    97.73\n",
      "1590   13    0   92.86  92.86    13     14   14      0     13    12    92.31\n",
      "1591   28    0   86.96  83.33    20     23   24      2     28    26    92.86\n",
      "1592   23    0   61.11  55.00    11     18   20      3     23    20    86.96\n",
      "1593   33    0   56.00  56.00    14     25   25      3     33    28    84.85\n",
      "1594    8    0  100.00  85.71     6      6    7      0      8     8   100.00\n",
      "1595   12    0   81.82  81.82     9     11   11      0     12    10    83.33\n",
      "1596   18    0   47.06  61.54     8     17   13      3     18    14    77.78\n",
      "1597   28    0   76.00  73.08    19     25   26      5     28    25    89.29\n",
      "1598   21    0   75.00  63.16    12     16   19      1     21    20    95.24\n",
      "1599   31    0   96.88  86.11    31     32   36      1     31    31   100.00\n",
      "1600   23    0   69.57  69.57    16     23   23      3     23    21    91.30\n",
      "1601   27    0   77.78  66.67    14     18   21      1     27    23    85.19\n",
      "1602   16    0   85.71  85.71    12     14   14      0     16    16   100.00\n",
      "1603   19    0   93.75  78.95    15     16   19      0     19    19   100.00\n",
      "1604   56    0   76.74  73.33    33     43   45      5     56    54    96.43\n",
      "1605   23    0   75.00  70.59    12     16   17      4     23    21    91.30\n",
      "1606   11    0   77.78  63.64     7      9   11      0     11     9    81.82\n",
      "1607   34    0   45.45  46.88    15     33   32     14     34    30    88.24\n",
      "1608   36    0   32.26  34.48    10     31   29     12     36    31    86.11\n",
      "1609   27    0   61.11  55.00    11     18   20      2     27    21    77.78\n",
      "1610   37    0   62.50  57.14    20     32   35     11     37    37   100.00\n",
      "1611   23    0   41.18  38.89     7     17   18      5     23    19    82.61\n",
      "1612   19    0   92.31  80.00    12     13   15      0     19    18    94.74\n",
      "1613   17    0   72.73  50.00     8     11   16      2     17    14    82.35\n",
      "1614   29    0   45.45  37.04    10     22   27      9     29    25    86.21\n",
      "1615   16    0   69.23  60.00     9     13   15      2     16    13    81.25\n",
      "1616   17    0    8.33   6.67     1     12   15      7     17    13    76.47\n",
      "1617   26    0   60.00  55.56    15     25   27      3     26    22    84.62\n",
      "1618   29    0   72.22  65.00    13     18   20      2     29    23    79.31\n",
      "1619   12    0   70.00  77.78     7     10    9      1     12    12   100.00\n",
      "1620    4    0   33.33  33.33     1      3    3      0      4     3    75.00\n",
      "1621   24    0   57.14  52.17    12     21   23      6     24    21    87.50\n",
      "1622   13    0   87.50  63.64     7      8   11      1     13    12    92.31\n",
      "1623   23    0   57.14  44.44     8     14   18      5     23    20    86.96\n",
      "1624    9    0  100.00  83.33     5      5    6      0      9     9   100.00\n",
      "1625   42    0   46.43  46.43    13     28   28     10     42    38    90.48\n",
      "1626   12    0   33.33  18.18     2      6   11      3     12    10    83.33\n",
      "1627   19    0   71.43  58.82    10     14   17      2     19    16    84.21\n",
      "1628   32    0   47.06  34.78     8     17   23      5     32    25    78.12\n",
      "1629    8    0  100.00  83.33     5      5    6      0      8     8   100.00\n",
      "1630   33    0   54.17  48.15    13     24   27      6     33    27    81.82\n",
      "1631   23    0   86.67  76.47    13     15   17      1     23    22    95.65\n",
      "1632   20    0   81.25  72.22    13     16   18      3     20    20   100.00\n",
      "1633   40    0   73.33  66.67    22     30   33      4     40    37    92.50\n",
      "1634   49    0   49.06  49.06    26     53   53     22     49    44    89.80\n",
      "1635   25    0   61.90  56.52    13     21   23      7     25    22    88.00\n",
      "1636    4    0   66.67  33.33     2      3    6      0      4     2    50.00\n",
      "1637   21    0   55.56  52.63    10     18   19      5     21    18    85.71\n",
      "1638    8    0  100.00  57.14     4      4    7      0      8     7    87.50\n",
      "1639    2    0  100.00  50.00     1      1    2      0      2     2   100.00\n",
      "1640    4    0   66.67  50.00     2      3    4      0      4     4   100.00\n",
      "1641   16    0  100.00  87.50     7      7    8      0     16    13    81.25\n",
      "1642   13    0   80.00  72.73     8     10   11      1     13    13   100.00\n",
      "1643   36    0   79.31  76.67    23     29   30      2     36    35    97.22\n",
      "1644   29    0   91.67  84.62    22     24   26      1     29    26    89.66\n",
      "1645   11    0  100.00  87.50     7      7    8      0     11    10    90.91\n",
      "1646   19    0  100.00  88.24    15     15   17      0     19    15    78.95\n",
      "1647   12    0   88.89  80.00     8      9   10      0     12    11    91.67\n",
      "1648    9    0   66.67  80.00     4      6    5      0      9     8    88.89\n",
      "1649   28    0   76.19  69.57    16     21   23      2     28    26    92.86\n",
      "1650   38    0   57.69  55.56    15     26   27      7     38    37    97.37\n",
      "1651   22    0   93.75  88.24    15     16   17      0     22    19    86.36\n",
      "1652   12    0   45.45  55.56     5     11    9      1     12    10    83.33\n",
      "1653   20    0   80.95  80.95    17     21   21      0     20    19    95.00\n",
      "1654    9    0   37.50  42.86     3      8    7      1      9     8    88.89\n",
      "1655   21    0   57.14  44.44     8     14   18      1     21    19    90.48\n",
      "1656   25    0   23.08  27.27     6     26   22     11     25    19    76.00\n",
      "1657    3    0    0.00   0.00     0      1    4      0      3     2    66.67\n",
      "1658   40    0   79.31  79.31    23     29   29      0     40    40   100.00\n",
      "1659   17    0   93.33  73.68    14     15   19      0     17    16    94.12\n",
      "1660   18    0   76.92  62.50    10     13   16      1     18    16    88.89\n",
      "1661   11    0  100.00  90.00     9      9   10      0     11    10    90.91\n",
      "1662   15    0   78.57  78.57    11     14   14      0     15    13    86.67\n",
      "1663    8    0  100.00  87.50     7      7    8      0      8     8   100.00\n",
      "1664   12    0   90.91  76.92    10     11   13      1     12    12   100.00\n",
      "1665   30    0   50.00  40.00    12     24   30      9     30    26    86.67\n",
      "1666   20    0   64.29  52.94     9     14   17      3     20    18    90.00\n",
      "1667    3    0    0.00   0.00     0      1    3      0      3     2    66.67\n",
      "1668   27    0   73.68  63.64    14     19   22      4     27    25    92.59\n",
      "1669   14    0   88.89  80.00     8      9   10      0     14    14   100.00\n",
      "1670   15    0   57.14  47.06     8     14   17      5     15    15   100.00\n",
      "1671   15    0   75.00  60.00     6      8   10      0     15    14    93.33\n",
      "1672   11    0   77.78  53.85     7      9   13      2     11    10    90.91\n",
      "1673   20    0   78.57  73.33    11     14   15      0     20    18    90.00\n",
      "1674   16    0   90.91  76.92    10     11   13      0     16    15    93.75\n",
      "1675   23    0   82.35  73.68    14     17   19      0     23    22    95.65\n",
      "1676    7    0   83.33  83.33     5      6    6      0      7     7   100.00\n",
      "1677   18    0   84.62  73.33    11     13   15      0     18    17    94.44\n",
      "1678   26    0   60.00  54.55    12     20   22      4     26    23    88.46\n",
      "1679    3    0    0.00   0.00     0      1    3      0      3     2    66.67\n",
      "1680   22    0  100.00  94.12    16     16   17      0     22    22   100.00\n",
      "1681   20    0  100.00  94.44    17     17   18      0     20    19    95.00\n",
      "1682   13    0  100.00  81.82     9      9   11      0     13    13   100.00\n",
      "1683    9    0   83.33  83.33     5      6    6      0      9     8    88.89\n",
      "1684   10    0  100.00  87.50     7      7    8      0     10     9    90.00\n",
      "1685   21    0   78.57  73.33    11     14   15      2     21    19    90.48\n",
      "1686   12    0   60.00  50.00     6     10   12      2     12    12   100.00\n",
      "1687   11    0  100.00  87.50     7      7    8      0     11     9    81.82\n",
      "1688   23    0   73.68  73.68    14     19   19      3     23    22    95.65\n",
      "1689   14    0  100.00  91.67    11     11   12      0     14    13    92.86\n",
      "1690   16    0  100.00  93.75    15     15   16      0     16    16   100.00\n",
      "1691   15    0  100.00  83.33    10     10   12      0     15    14    93.33\n",
      "1692    8    0   25.00  12.50     1      4    8      2      8     5    62.50\n",
      "1693   19    0   50.00  40.00     6     12   15      2     19    16    84.21\n",
      "1694   13    0  100.00  88.89     8      8    9      0     13    13   100.00\n",
      "1695    9    0  100.00  88.89     8      8    9      0      9     9   100.00\n",
      "1696    4    0  100.00  50.00     1      1    2      0      4     4   100.00\n",
      "1697   14    0  100.00  84.62    11     11   13      0     14    14   100.00\n",
      "1698   32    0   82.61  73.08    19     23   26      2     32    32   100.00\n",
      "1699   25    0   76.92  80.00    20     26   25      0     25    24    96.00\n",
      "1700   19    0   75.00  66.67    12     16   18      3     19    18    94.74\n",
      "1701   13    0   63.64  70.00     7     11   10      1     13    13   100.00\n",
      "1702   11    0  100.00  88.89     8      8    9      0     11    11   100.00\n",
      "1703    9    0  100.00  87.50     7      7    8      0      9     9   100.00\n",
      "1704   17    0  100.00  93.33    14     14   15      0     17    16    94.12\n",
      "1705   24    0   66.67  66.67    12     18   18      4     24    22    91.67\n",
      "1706   10    0  100.00  71.43     5      5    7      0     10     9    90.00\n",
      "1707   20    0   47.06  40.00     8     17   20      7     20    19    95.00\n",
      "1708   25    0   85.71  78.26    18     21   23      0     25    25   100.00\n",
      "1709   26    0   80.95  70.83    17     21   24      2     26    25    96.15\n",
      "1710   17    0   36.84  35.00     7     19   20      9     17    17   100.00\n",
      "1711    4    0  100.00  50.00     1      1    2      0      4     4   100.00\n",
      "1712   25    0   94.12  84.21    16     17   19      1     25    24    96.00\n",
      "1713   18    0   91.67  84.62    11     12   13      0     18    18   100.00\n",
      "1714   42    0   50.00  45.24    19     38   42     17     42    40    95.24\n",
      "1715   13    0   45.45  55.56     5     11    9      1     13    11    84.62\n",
      "1716   11    0   90.00  81.82     9     10   11      0     11    11   100.00\n",
      "1717   19    0   55.56  55.56    10     18   18      4     19    15    78.95\n",
      "1718   29    0   63.64  51.85    14     22   27      7     29    27    93.10\n",
      "1719    3    0    0.00   0.00     0      1    3      0      3     2    66.67\n",
      "1720   22    0  100.00  93.75    15     15   16      0     22    20    90.91\n",
      "1721   16    0  100.00  87.50    14     14   16      0     16    15    93.75\n",
      "1722   15    0   50.00  53.85     7     14   13      3     15    12    80.00\n",
      "1723   25    0   73.91  70.83    17     23   24      2     25    21    84.00\n",
      "1724   28    0   65.22  65.22    15     23   23      3     28    27    96.43\n",
      "1725   24    0   70.00  56.00    14     20   25      6     24    23    95.83\n",
      "1726   28    0   88.00  88.00    22     25   25      0     28    27    96.43\n",
      "1727    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "1728   46    0   85.71  83.72    36     42   43      5     46    44    95.65\n",
      "1729   23    0   81.25  81.25    13     16   16      0     23    23   100.00\n",
      "1730   12    0   66.67  60.00     6      9   10      0     12    10    83.33\n",
      "1731   17    0   91.67  84.62    11     12   13      1     17    16    94.12\n",
      "1732   34    0   32.26  33.33    10     31   30     10     34    31    91.18\n",
      "1733   20    0   73.68  70.00    14     19   20      4     20    20   100.00\n",
      "1734   29    0   74.07  74.07    20     27   27      5     29    26    89.66\n",
      "1735    3    0    0.00   0.00     0      1    4      0      3     2    66.67\n",
      "1736   11    0  100.00  90.00     9      9   10      0     11    10    90.91\n",
      "1737   34    0   66.67  64.00    16     24   25      5     34    29    85.29\n",
      "1738   17    0   73.33  73.33    11     15   15      1     17    16    94.12\n",
      "1739   25    0   88.46  88.46    23     26   26      1     25    23    92.00\n",
      "1740   13    0   77.78  70.00     7      9   10      0     13    12    92.31\n",
      "1741    4    0    0.00   0.00     0      1    4      0      4     3    75.00\n",
      "1742   36    0   80.00  82.76    24     30   29      1     36    31    86.11\n",
      "1743   38    0   90.32  82.35    28     31   34      0     38    35    92.11\n",
      "1744   15    0   70.00  53.85     7     10   13      1     15    14    93.33\n",
      "1745   14    0   61.54  66.67     8     13   12      0     14    10    71.43\n",
      "1746   25    2    0.00   0.00     0      0    0      0      0     0     0.00\n",
      "1747   18    0   50.00  45.45     5     10   11      1     18    11    61.11\n",
      "1748   11    0  100.00  90.91    10     10   11      0     11     9    81.82\n",
      "1749   17    0   61.54  53.33     8     13   15      2     17    15    88.24\n",
      "1750    5    0   75.00  60.00     3      4    5      0      5     5   100.00\n",
      "1751   30    0   70.97  70.97    22     31   31      7     30    27    90.00\n",
      "1752   18    0   85.71  70.59    12     14   17      1     18    15    83.33\n",
      "1753   12    0   88.89  80.00     8      9   10      0     12    12   100.00\n",
      "1754   23    0   70.59  70.59    12     17   17      2     23    19    82.61\n",
      "1755   14    0   91.67  84.62    11     12   13      0     14    12    85.71\n",
      "1756   38    0   73.08  73.08    19     26   26      1     38    31    81.58\n",
      "1757   16    0  100.00  64.29     9      9   14      0     16    14    87.50\n",
      "1758   17    0   72.73  61.54     8     11   13      2     17    15    88.24\n",
      "1759   15    0   46.15  42.86     6     13   14      4     15    11    73.33\n",
      "1760    3    0    0.00   0.00     0      2    4      0      3     1    33.33\n",
      "1761   23    0   83.33  62.50    10     12   16      2     23    22    95.65\n",
      "1762    7    0   80.00  66.67     4      5    6      0      7     6    85.71\n",
      "1763    7    0   50.00  50.00     3      6    6      0      7     5    71.43\n",
      "1764   17    0   38.46  35.71     5     13   14      6     17    14    82.35\n",
      "1765   12    0   69.23  69.23     9     13   13      0     12    10    83.33\n",
      "1766   10    0   25.00  40.00     2      8    5      1     10     8    80.00\n",
      "1767   17    0   78.57  73.33    11     14   15      1     17    14    82.35\n",
      "1768    7    0   28.57  22.22     2      7    9      0      7     4    57.14\n",
      "1769   12    0   75.00  75.00     9     12   12      0     12    10    83.33\n",
      "1770   19    0   73.68  70.00    14     19   20      2     19    16    84.21\n",
      "1771   21    0   63.16  52.17    12     19   23      6     21    19    90.48\n",
      "1772   15    0   33.33  36.36     4     12   11      2     15    13    86.67\n",
      "1773   21    0   58.33  56.00    14     24   25      3     21    15    71.43\n",
      "1774   11    0   85.71  75.00     6      7    8      0     11     8    72.73\n",
      "1775   39    0   19.23  15.62     5     26   32     19     39    31    79.49\n",
      "1776   29    0   35.29  46.15     6     17   13      4     29    27    93.10\n",
      "1777   10    0  100.00  85.71     6      6    7      0     10    10   100.00\n",
      "1778   49    0   81.40  81.40    35     43   43      3     49    46    93.88\n",
      "1779   17    0   92.86  76.47    13     14   17      0     17    16    94.12\n",
      "1780   11    0   50.00  50.00     3      6    6      0     11    11   100.00\n",
      "1781    8    0  100.00  88.89     8      8    9      0      8     8   100.00\n",
      "1782   14    0   56.25  60.00     9     16   15      3     14    12    85.71\n",
      "1783   10    0   42.86  42.86     3      7    7      1     10     7    70.00\n",
      "1784   41    0   61.11  61.11    22     36   36      6     41    37    90.24\n",
      "1785   21    0   80.00  75.00    12     15   16      1     21    20    95.24\n",
      "1786    2    0  100.00  50.00     1      1    2      0      2     2   100.00\n",
      "1787    4    0   66.67  50.00     2      3    4      0      4     4   100.00\n",
      "1788   32    0   85.19  82.14    23     27   28      2     32    29    90.62\n",
      "1789   28    0   60.00  54.55    12     20   22      7     28    27    96.43\n",
      "1790   21    0   80.00  76.19    16     20   21      3     21    19    90.48\n",
      "1791   43    0   62.50  51.28    20     32   39     11     43    41    95.35\n",
      "1792   23    0  100.00  80.95    17     17   21      0     23    21    91.30\n",
      "1793   33    0   87.50  84.00    21     24   25      0     33    32    96.97\n",
      "1794   11    0   37.50  33.33     3      8    9      3     11     9    81.82\n",
      "1795   48    0   86.84  84.62    33     38   39      0     48    46    95.83\n",
      "1796   29    0   58.33  53.85    14     24   26      9     29    26    89.66\n",
      "1797   53    0   59.09  56.52    26     44   46     15     53    52    98.11\n",
      "1798   16    0   71.43  76.92    10     14   13      0     16    14    87.50\n",
      "1799   48    0   86.49  82.05    32     37   39      3     48    45    93.75\n",
      "1800   36    0   66.67  54.55    18     27   33      7     36    33    91.67\n",
      "1801   19    0   83.33  62.50    10     12   16      1     19    18    94.74\n",
      "1802    5    0    0.00   0.00     0      1    5      0      5     4    80.00\n",
      "1803    5    0  100.00  75.00     3      3    4      0      5     5   100.00\n",
      "1804   15    0   70.00  53.85     7     10   13      1     15    13    86.67\n",
      "1805    4    0  100.00  40.00     2      2    5      0      4     4   100.00\n",
      "1806   12    0   27.27  25.00     3     11   12      0     12     8    66.67\n",
      "1807   20    0   57.14  66.67     8     14   12      3     20    17    85.00\n",
      "1808   27    0   86.96  76.92    20     23   26      1     27    25    92.59\n",
      "1809   24    0  100.00  95.45    21     21   22      0     24    22    91.67\n",
      "1810   18    0   66.67  50.00     8     12   16      4     18    15    83.33\n",
      "1811   28    0   42.11  42.11     8     19   19      5     28    27    96.43\n",
      "1812   36    0   42.42  40.00    14     33   35     15     36    34    94.44\n",
      "1813   20    0   55.56  45.45     5      9   11      2     20    16    80.00\n",
      "1814   19    0   66.67  62.50    10     15   16      1     19    16    84.21\n",
      "1815   33    0   59.09  59.09    13     22   22      7     33    31    93.94\n",
      "1816   30    0   38.46  38.46    10     26   26      8     30    25    83.33\n",
      "1817   28    0   90.91  80.00    20     22   25      2     28    27    96.43\n",
      "1818   16    0   45.45  38.46     5     11   13      3     16    14    87.50\n",
      "1819   25    0   50.00  50.00     8     16   16      4     25    22    88.00\n",
      "1820   30    0   72.22  72.22    13     18   18      3     30    27    90.00\n",
      "1821   14    0  100.00  91.67    11     11   12      0     14    13    92.86\n",
      "1822   23    0  100.00  85.71    12     12   14      0     23    23   100.00\n",
      "1823   32    0   52.94  45.00     9     17   20      5     32    28    87.50\n",
      "1824   20    0   60.00  64.29     9     15   14      0     20    18    90.00\n",
      "1825   13    0  100.00  90.91    10     10   11      0     13    13   100.00\n",
      "1826   47    0   80.00  72.73    32     40   44      2     47    44    93.62\n",
      "1827   17    0   85.71  66.67    12     14   18      0     17    15    88.24\n",
      "1828   38    0   67.50  65.85    27     40   41      9     38    35    92.11\n",
      "1829   39    0   58.33  61.76    21     36   34     10     39    36    92.31\n",
      "1830   27    0   65.00  56.52    13     20   23      3     27    26    96.30\n",
      "1831   22    0   39.13  39.13     9     23   23      9     22    20    90.91\n",
      "1832   11    0   55.56  55.56     5      9    9      0     11     9    81.82\n",
      "1833   26    0   68.18  71.43    15     22   21      2     26    25    96.15\n",
      "1834   14    0  100.00  90.91    10     10   11      0     14    13    92.86\n",
      "1835   31    0   70.37  73.08    19     27   26      4     31    30    96.77\n",
      "1836   17    0   91.67  68.75    11     12   16      1     17    14    82.35\n",
      "1837   16    0   77.78  58.33    14     18   24      2     16    11    68.75\n",
      "1838   21    0   96.15  89.29    25     26   28      0     21    20    95.24\n",
      "1839   12    0   80.00  57.14     8     10   14      2     12    10    83.33\n",
      "1840   33    0   65.52  76.00    19     29   25      2     33    31    93.94\n",
      "1841   13    0   70.00  58.33     7     10   12      0     13    12    92.31\n",
      "1842   21    0   93.33  82.35    14     15   17      0     21    19    90.48\n",
      "1843   29    0   87.10  87.10    27     31   31      0     29    28    96.55\n",
      "1844   13    0   75.00  90.00     9     12   10      0     13    12    92.31\n",
      "1845   25    0   86.96  80.00    20     23   25      0     25    23    92.00\n",
      "1846   16    0  100.00  80.00    12     12   15      0     16    15    93.75\n",
      "1847   18    0   87.50  77.78    14     16   18      1     18    17    94.44\n",
      "1848   26    0   85.71  66.67    18     21   27      3     26    25    96.15\n",
      "1849   20    0   76.19  76.19    16     21   21      0     20    19    95.00\n",
      "1850   38    0   73.33  62.86    22     30   35      4     38    34    89.47\n",
      "1851   12    0  100.00  90.91    10     10   11      0     12    11    91.67\n",
      "1852   25    0   64.29  64.29     9     14   14      1     25    23    92.00\n",
      "1853   19    0  100.00  93.33    14     14   15      0     19    19   100.00\n",
      "1854   16    0  100.00  90.91    10     10   11      0     16    14    87.50\n",
      "1855   25    0   89.47  94.44    17     19   18      0     25    24    96.00\n",
      "1856    5    0   75.00  60.00     3      4    5      0      5     4    80.00\n",
      "1857   21    0   76.47  76.47    13     17   17      0     21    19    90.48\n",
      "1858   36    0   76.67  69.70    23     30   33      2     36    33    91.67\n",
      "1859   17    0  100.00  93.75    15     15   16      0     17    17   100.00\n",
      "1860   20    0   72.22  86.67    13     18   15      0     20    20   100.00\n",
      "1861   28    0   66.67  66.67    12     18   18      3     28    28   100.00\n",
      "1862   28    0   73.91  70.83    17     23   24      4     28    26    92.86\n",
      "1863   17    0   70.59  70.59    12     17   17      2     17    13    76.47\n",
      "1864   25    0   73.91  68.00    17     23   25      1     25    21    84.00\n",
      "1865   22    0   73.33  64.71    11     15   17      4     22    20    90.91\n",
      "1866   19    0  100.00  93.75    15     15   16      0     19    19   100.00\n",
      "1867   23    0   52.38  45.83    11     21   24      9     23    18    78.26\n",
      "1868   37    0   79.17  73.08    19     24   26      4     37    35    94.59\n",
      "1869    7    0  100.00  83.33     5      5    6      0      7     7   100.00\n",
      "1870   27    0  100.00  93.33    14     14   15      0     27    26    96.30\n",
      "1871   20    0  100.00  91.67    11     11   12      0     20    20   100.00\n",
      "1872   11    0  100.00  87.50     7      7    8      0     11    10    90.91\n",
      "1873    5    0  100.00  80.00     4      4    5      0      5     5   100.00\n",
      "1874   39    0   80.95  73.91    17     21   23      1     39    39   100.00\n",
      "1875   12    0   77.78  77.78     7      9    9      0     12    10    83.33\n",
      "1876   15    0   70.00  77.78     7     10    9      0     15    12    80.00\n",
      "1877    9    0   85.71  75.00     6      7    8      0      9     8    88.89\n",
      "1878   48    0  100.00  93.02    40     40   43      0     48    45    93.75\n",
      "1879    7    0  100.00  85.71     6      6    7      0      7     7   100.00\n",
      "1880   15    0   85.71  80.00    12     14   15      1     15    13    86.67\n",
      "1881   24    0   50.00  46.67     7     14   15      4     24    22    91.67\n",
      "1882   61    0   26.42  35.00    14     53   40     12     61    51    83.61\n",
      "1883    6    0  100.00  25.00     1      1    4      0      6     6   100.00\n",
      "1884   23    0  100.00  93.75    15     15   16      0     23    23   100.00\n",
      "1885    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "1886    4    0    0.00   0.00     0      2    4      1      4     3    75.00\n",
      "1887   14    0  100.00  85.71     6      6    7      0     14    14   100.00\n",
      "1888    3    0  100.00  50.00     1      1    2      0      3     0     0.00\n",
      "1889   22    0   61.11  64.71    11     18   17      1     22    22   100.00\n",
      "1890   17    0   92.86  86.67    13     14   15      0     17    17   100.00\n",
      "1891   10    0  100.00  80.00     4      4    5      0     10    10   100.00\n",
      "1892    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "1893    3    0    0.00   0.00     0      1    3      0      3     3   100.00\n",
      "1894   15    0   77.78  77.78     7      9    9      1     15    14    93.33\n",
      "1895    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "1896    7    0    0.00   0.00     0      2    5      0      7     6    85.71\n",
      "1897   11    0   77.78  77.78     7      9    9      1     11    11   100.00\n",
      "1898   10    0   16.67  14.29     1      6    7      3     10     8    80.00\n",
      "1899   56    0   78.79  74.29    26     33   35      6     56    55    98.21\n",
      "1900    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "1901   15    0   58.33  50.00     7     12   14      5     15    14    93.33\n",
      "1902   15    0  100.00  90.91    10     10   11      0     15    15   100.00\n",
      "1903    4    0   50.00  40.00     2      4    5      1      4     3    75.00\n",
      "1904   25    0  100.00  94.12    16     16   17      0     25    25   100.00\n",
      "1905   28    0   95.24  86.96    20     21   23      0     28    28   100.00\n",
      "1906    7    0  100.00  80.00     4      4    5      0      7     7   100.00\n",
      "1907    7    0   75.00  50.00     3      4    6      0      7     6    85.71\n",
      "1908   15    0   90.91  90.91    10     11   11      0     15    15   100.00\n",
      "1909    3    0  100.00  50.00     1      1    2      0      3     0     0.00\n",
      "1910   30    0  100.00  95.00    19     19   20      0     30    30   100.00\n",
      "1911   12    0   60.00  50.00     3      5    6      0     12    11    91.67\n",
      "1912    4    0  100.00  50.00     1      1    2      0      4     1    25.00\n",
      "1913   60    0   48.00  25.00    12     25   48      8     60    60   100.00\n",
      "1914    8    0   50.00  40.00     2      4    5      0      8     7    87.50\n",
      "1915   24    0   94.12  84.21    16     17   19      0     24    24   100.00\n",
      "1916   21    0   66.67  52.63    10     15   19      5     21    20    95.24\n",
      "1917    4    0  100.00  50.00     1      1    2      0      4     0     0.00\n",
      "1918   20    0  100.00  94.12    16     16   17      0     20    20   100.00\n",
      "1919   15    0  100.00  91.67    11     11   12      0     15    15   100.00\n",
      "1920    3    0    0.00   0.00     0      1    3      0      3     2    66.67\n",
      "1921   34    0   80.95  77.27    17     21   22      3     34    34   100.00\n",
      "1922   10    0  100.00  87.50     7      7    8      0     10    10   100.00\n",
      "1923   11    0   75.00  75.00     3      4    4      0     11    10    90.91\n",
      "1924   12    0   63.64  70.00     7     11   10      1     12    12   100.00\n",
      "1925   20    0   44.44  36.36     4      9   11      3     20    20   100.00\n",
      "1926    6    0  100.00  75.00     3      3    4      0      6     6   100.00\n",
      "1927    9    0   75.00  50.00     3      4    6      0      9     8    88.89\n",
      "1928   17    0   80.00  85.71    12     15   14      1     17    17   100.00\n",
      "1929   19    0   50.00  30.77     4      8   13      2     19    18    94.74\n",
      "1930    6    0  100.00  75.00     3      3    4      0      6     6   100.00\n",
      "1931    6    0  100.00  50.00     1      1    2      0      6     5    83.33\n",
      "1932    3    0    0.00   0.00     0      1    3      0      3     3   100.00\n",
      "1933   20    0   76.92  66.67    10     13   15      2     20    20   100.00\n",
      "1934   23    0   85.00  80.95    17     20   21      1     23    22    95.65\n",
      "1935    8    0   75.00  75.00     6      8    8      0      8     7    87.50\n",
      "1936   34    0   50.00  50.00    14     28   28     11     34    29    85.29\n",
      "1937   21    0   66.67  60.00    12     18   20      1     21    20    95.24\n",
      "1938   11    0   70.00  77.78     7     10    9      0     11    11   100.00\n",
      "1939   17    0   85.71  75.00    12     14   16      0     17    14    82.35\n",
      "1940   42    0   86.11  83.78    31     36   37      3     42    41    97.62\n",
      "1941   20    0   64.71  61.11    11     17   18      3     20    17    85.00\n",
      "1942   12    0   58.33  53.85     7     12   13      1     12    10    83.33\n",
      "1943   29    0   87.50  84.00    21     24   25      2     29    27    93.10\n",
      "1944   18    0   87.50  77.78    14     16   18      0     18    18   100.00\n",
      "1945    7    0  100.00  71.43     5      5    7      0      7     5    71.43\n",
      "1946   12    0  100.00  77.78     7      7    9      0     12    12   100.00\n",
      "1947    8    0   80.00  66.67     4      5    6      0      8     8   100.00\n",
      "1948   42    0   94.59  92.11    35     37   38      0     42    42   100.00\n",
      "1949   14    0   77.78  63.64     7      9   11      1     14    14   100.00\n",
      "1950   38    0   85.00  82.93    34     40   41      3     38    34    89.47\n",
      "1951   29    0   50.00  42.31    11     22   26      9     29    28    96.55\n",
      "1952   33    0   70.00  58.33    14     20   24      4     33    31    93.94\n",
      "1953   25    0   84.62  78.57    11     13   14      0     25    24    96.00\n",
      "1954   50    0   83.78  86.11    31     37   36      1     50    48    96.00\n",
      "1955   38    0   85.71  85.71    30     35   35      1     38    33    86.84\n",
      "1956   31    0   75.00  62.50    15     20   24      0     31    29    93.55\n",
      "1957   23    0   66.67  75.00    12     18   16      1     23    21    91.30\n",
      "1958   31    0   86.36  86.36    19     22   22      1     31    30    96.77\n",
      "1959   23    0   85.71  70.59    12     14   17      0     23    21    91.30\n",
      "1960   10    0  100.00  90.91    10     10   11      0     10     9    90.00\n",
      "1961   23    0   66.67  60.87    14     21   23      5     23    23   100.00\n",
      "1962   27    0   88.89  84.21    16     18   19      1     27    25    92.59\n",
      "1963   22    0   88.24  68.18    15     17   22      3     22    20    90.91\n",
      "1964   29    0   58.33  58.33    14     24   24      5     29    27    93.10\n",
      "1965   34    0   52.17  48.00    12     23   25      9     34    31    91.18\n",
      "1966   15    0   72.73  80.00     8     11   10      0     15    14    93.33\n",
      "1967   44    0   67.57  65.79    25     37   38      7     44    40    90.91\n",
      "1968   40    0   78.95  75.00    30     38   40      5     40    36    90.00\n",
      "1969   21    0   60.00  60.00    12     20   20      4     21    20    95.24\n",
      "1970   15    0  100.00  80.00    12     12   15      0     15    13    86.67\n",
      "1971   22    0   40.00  33.33     8     20   24     12     22    19    86.36\n",
      "1972   18    0   78.57  73.33    11     14   15      0     18    18   100.00\n",
      "1973   18    0   31.25  31.25     5     16   16      2     18    14    77.78\n",
      "1974   37    0   85.71  82.76    24     28   29      4     37    33    89.19\n",
      "1975    6    0   60.00  60.00     3      5    5      0      6     3    50.00\n",
      "1976   19    0   83.33  66.67    10     12   15      2     19    18    94.74\n",
      "1977   15    0  100.00  83.33    10     10   12      0     15    15   100.00\n",
      "1978   31    0   76.19  76.19    16     21   21      2     31    27    87.10\n",
      "1979   23    0   50.00  41.18     7     14   17      7     23    18    78.26\n",
      "1980   28    0   73.91  68.00    17     23   25      5     28    25    89.29\n",
      "1981   22    0   81.25  76.47    13     16   17      1     22    20    90.91\n",
      "1982   16    0  100.00  90.91    10     10   11      0     16    16   100.00\n",
      "1983   52    0   56.76  50.00    21     37   42     13     52    46    88.46\n",
      "1984   25    0   57.89  64.71    11     19   17      4     25    24    96.00\n",
      "1985   33    0   45.71  43.24    16     35   37     17     33    26    78.79\n",
      "1986   16    0  100.00  86.67    13     13   15      0     16    15    93.75\n",
      "1987   25    0   85.00  94.44    17     20   18      0     25    23    92.00\n",
      "1988   47    0   53.49  62.16    23     43   37      7     47    43    91.49\n",
      "1989   22    0   61.11  61.11    11     18   18      4     22    20    90.91\n",
      "1990   31    0   76.92  71.43    20     26   28      1     31    26    83.87\n",
      "1991   33    0   46.43  43.33    13     28   30     11     33    28    84.85\n",
      "1992   18    0   88.24  88.24    15     17   17      0     18    15    83.33\n",
      "1993   16    0   90.00  90.00    18     20   20      0     16    15    93.75\n",
      "1994   21    0   83.33  75.00    15     18   20      2     21    20    95.24\n",
      "1995   17    0   83.33  71.43    10     12   14      2     17    16    94.12\n",
      "1996   31    0   56.25  47.37     9     16   19      5     31    29    93.55\n",
      "1997   42    0   77.42  72.73    24     31   33      7     42    40    95.24\n",
      "1998   14    0  100.00  80.00    12     12   15      0     14    13    92.86\n",
      "1999   11    0   83.33  83.33     5      6    6      0     11    11   100.00\n",
      "2000   12    0  100.00  85.71     6      6    7      0     12    12   100.00\n",
      "2001   25    0   56.52  54.17    13     23   24      8     25    24    96.00\n",
      "2002   24    0   78.26  85.71    18     23   21      1     24    23    95.83\n",
      "2003    3    0    0.00   0.00     0      3    4      1      3     1    33.33\n",
      "2004   29    0   89.47  80.95    17     19   21      1     29    28    96.55\n",
      "2005   19    0   88.89  88.89    16     18   18      0     19    18    94.74\n",
      "2006   44    0   78.12  80.65    25     32   31      3     44    41    93.18\n",
      "2007   26    0   71.43  58.82    10     14   17      1     26    25    96.15\n",
      "2008   17    0   81.25  81.25    13     16   16      0     17    15    88.24\n",
      "2009   45    0   86.67  81.25    26     30   32      2     45    42    93.33\n",
      "2010   19    0   73.33  68.75    11     15   16      4     19    17    89.47\n",
      "2011   21    0   92.31  70.59    12     13   17      1     21    20    95.24\n",
      "2012   18    0   57.14  50.00     8     14   16      4     18    16    88.89\n",
      "2013   27    0   87.50  80.77    21     24   26      1     27    24    88.89\n",
      "2014   30    0   73.33  78.57    22     30   28      4     30    27    90.00\n",
      "2015   23    0   93.75  88.24    15     16   17      0     23    21    91.30\n",
      "2016   22    0   26.32  38.46     5     19   13      5     22    18    81.82\n",
      "2017   28    0   50.00  41.67    10     20   24      9     28    28   100.00\n",
      "2018   29    0   52.38  52.38    11     21   21      4     29    26    89.66\n",
      "2019   50    0   87.10  75.00    27     31   36      4     50    49    98.00\n",
      "2020   21    0   83.33  62.50    10     12   16      0     21    20    95.24\n",
      "2021   53    0   66.67  68.09    32     48   47      9     53    47    88.68\n",
      "2022   35    0   70.97  66.67    22     31   33      4     35    31    88.57\n",
      "2023   29    0   88.89  92.31    24     27   26      0     29    27    93.10\n",
      "2024    6    0  100.00  80.00     4      4    5      0      6     5    83.33\n",
      "2025   11    0  100.00  91.67    11     11   12      0     11    11   100.00\n",
      "2026   36    0   43.75  46.67    14     32   30     12     36    30    83.33\n",
      "2027   14    0  100.00  94.12    16     16   17      0     14    14   100.00\n",
      "2028   61    0   62.75  60.38    32     51   53     15     61    56    91.80\n",
      "2029   34    0   92.59  83.33    25     27   30      2     34    33    97.06\n",
      "2030   32    0   92.00  85.19    23     25   27      1     32    30    93.75\n",
      "2031   51    0   63.89  74.19    23     36   31      5     51    49    96.08\n",
      "2032   27    0   95.00  90.48    19     20   21      0     27    26    96.30\n",
      "2033   38    0   75.76  86.21    25     33   29      0     38    35    92.11\n",
      "2034   32    0  100.00  95.45    21     21   22      0     32    31    96.88\n",
      "2035   21    0   65.00  68.42    13     20   19      3     21    19    90.48\n",
      "2036   33    0   80.00  75.00    24     30   32      3     33    31    93.94\n",
      "2037   39    0   72.97  75.00    27     37   36      5     39    35    89.74\n",
      "2038   50    0   52.50  45.65    21     40   46     19     50    48    96.00\n",
      "2039   50    0   80.00  75.68    28     35   37      5     50    47    94.00\n",
      "2040   32    0   57.69  57.69    15     26   26      5     32    30    93.75\n",
      "2041   20    0   70.00  70.00    14     20   20      4     20    19    95.00\n",
      "2042   10    0   87.50  77.78     7      8    9      0     10    10   100.00\n",
      "2043   42    0   88.24  85.71    30     34   35      2     42    42   100.00\n",
      "2044   25    0   80.77  84.00    21     26   25      3     25    24    96.00\n",
      "2045   38    0   75.00  68.57    24     32   35      4     38    36    94.74\n",
      "2046   25    0   43.75  41.18     7     16   17      7     25    21    84.00\n",
      "2047    9    0  100.00  85.71     6      6    7      0      9     9   100.00\n",
      "2048   12    0   75.00  66.67     6      8    9      0     12    10    83.33\n",
      "2049    7    0  100.00  83.33     5      5    6      0      7     7   100.00\n",
      "2050    6    0  100.00  50.00     1      1    2      0      6     5    83.33\n",
      "2051   12    0   33.33  30.00     3      9   10      3     12    11    91.67\n",
      "2052    5    0  100.00  50.00     1      1    2      0      5     4    80.00\n",
      "2053   10    0   60.00  60.00     3      5    5      0     10     8    80.00\n",
      "2054    4    0  100.00  50.00     1      1    2      0      4     3    75.00\n",
      "2055   14    0   20.00  16.67     1      5    6      0     14    11    78.57\n",
      "2056    4    0  100.00  50.00     1      1    2      0      4     3    75.00\n",
      "2057   18    0   71.43  62.50     5      7    8      0     18    12    66.67\n",
      "2058    4    0  100.00  50.00     1      1    2      0      4     3    75.00\n",
      "2059   12    0   60.00  42.86     3      5    7      1     12    11    91.67\n",
      "2060    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "2061   10    0   16.67  14.29     1      6    7      2     10     8    80.00\n",
      "2062    3    0  100.00  50.00     1      1    2      0      3     1    33.33\n",
      "2063    9    0   60.00  60.00     3      5    5      0      9     8    88.89\n",
      "2064    4    0  100.00  50.00     1      1    2      0      4     3    75.00\n",
      "2065    9    0   60.00  60.00     3      5    5      0      9     8    88.89\n",
      "2066    5    0  100.00  50.00     1      1    2      0      5     3    60.00\n",
      "2067   11    0   60.00  60.00     3      5    5      0     11    10    90.91\n",
      "2068    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "2069    8    0   50.00  50.00     2      4    4      0      8     7    87.50\n",
      "2070    3    0  100.00  50.00     1      1    2      0      3     2    66.67\n",
      "2071    9    0   60.00  60.00     3      5    5      0      9     8    88.89\n",
      "2072    2    0  100.00  50.00     1      1    2      0      2     1    50.00\n",
      "2073   18    0   54.55  50.00     6     11   12      2     18    15    83.33\n",
      "2074    4    0  100.00  75.00     3      3    4      0      4     4   100.00\n",
      "2075   19    0   70.00  53.85     7     10   13      0     19    17    89.47\n",
      "2076    5    0  100.00  50.00     1      1    2      0      5     4    80.00\n",
      "2077   19    0   45.45  55.56     5     11    9      2     19    16    84.21\n",
      "2078    4    0  100.00  75.00     3      3    4      0      4     4   100.00\n",
      "2079   39    0   44.44  40.00     8     18   20      5     39    36    92.31\n",
      "2080    6    0  100.00  50.00     1      1    2      0      6     4    66.67\n",
      "2081   14    0   37.50  30.00     3      8   10      1     14    13    92.86\n",
      "2082    2    0  100.00  50.00     1      1    2      0      2     1    50.00\n",
      "2083   25    0   30.00  25.00     3     10   12      2     25    22    88.00\n",
      "2084    6    0  100.00  50.00     1      1    2      0      6     5    83.33\n",
      "2085   19    0   66.67  66.67     8     12   12      3     19    18    94.74\n",
      "2086    4    0  100.00  50.00     1      1    2      0      4     3    75.00\n",
      "2087   11    0   37.50  37.50     3      8    8      2     11     8    72.73\n",
      "2088    9    0   50.00  37.50     3      6    8      2      9     7    77.78\n",
      "2089   13    0   75.00  60.00     6      8   10      0     13    11    84.62\n",
      "2090   10    2    0.00   0.00     0      0    0      0      0     0     0.00\n",
      "2091   16    0   50.00  45.45     5     10   11      2     16    13    81.25\n",
      "2092    5    2    0.00   0.00     0      0    0      0      0     0     0.00\n",
      "2093   17    0   33.33  21.43     3      9   14      2     17    12    70.59\n",
      "2094    8    0  100.00  50.00     1      1    2      0      8     7    87.50\n",
      "2095   22    0   37.50  21.43     3      8   14      1     22    20    90.91\n",
      "2096   38    0   93.75  88.24    30     32   34      0     38    35    92.11\n",
      "2097   33    0   69.23  72.00    18     26   25      5     33    32    96.97\n",
      "2098   10    0   75.00  75.00     6      8    8      0     10     8    80.00\n",
      "2099   36    0   84.62  81.48    22     26   27      0     36    31    86.11\n",
      "2100   13    0   35.71  35.71     5     14   14      5     13    10    76.92\n",
      "2101    7    0  100.00  88.89     8      8    9      0      7     7   100.00\n",
      "2102   13    0  100.00  90.91    10     10   11      0     13    12    92.31\n",
      "2103   18    0  100.00  90.91    20     20   22      0     18    18   100.00\n",
      "2104   28    0   69.57  61.54    16     23   26      5     28    26    92.86\n",
      "2105   38    0   46.15  37.50    12     26   32     12     38    33    86.84\n",
      "2106   24    0   52.94  47.37     9     17   19      7     24    23    95.83\n",
      "2107   20    0   45.00  39.13     9     20   23      7     20    20   100.00\n",
      "2108   25    0   85.00  85.00    17     20   20      1     25    24    96.00\n",
      "2109   21    0   93.75  88.24    15     16   17      0     21    20    95.24\n",
      "2110   24    0   94.44  85.00    17     18   20      0     24    24   100.00\n",
      "2111   18    0   59.09  68.42    13     22   19      2     18    17    94.44\n",
      "2112   47    0   66.67  68.18    30     45   44      8     47    42    89.36\n",
      "2113   32    0   86.36  79.17    19     22   24      0     32    29    90.62\n",
      "2114   15    0   85.71  75.00    12     14   16      2     15    15   100.00\n",
      "2115   34    0   60.00  55.56    15     25   27      8     34    32    94.12\n",
      "2116   28    0   91.30  84.00    21     23   25      0     28    26    92.86\n",
      "2117   30    0   57.14  64.00    16     28   25      3     30    28    93.33\n",
      "2118   26    0   85.00  77.27    17     20   22      1     26    24    92.31\n",
      "2119   40    0   51.35  52.78    19     37   36      9     40    36    90.00\n",
      "2120   14    0   61.54  47.06     8     13   17      4     14    13    92.86\n",
      "2121   19    0   72.73  57.14     8     11   14      4     19    18    94.74\n",
      "2122   19    0   44.44  47.06     8     18   17      5     19    17    89.47\n",
      "2123    7    0   83.33  71.43     5      6    7      0      7     6    85.71\n",
      "2124   24    0   64.71  57.89    11     17   19      2     24    23    95.83\n",
      "2125   16    0   73.33  68.75    11     15   16      2     16    14    87.50\n",
      "2126   18    0   53.33  61.54     8     15   13      3     18    17    94.44\n",
      "2127   13    0   70.00  70.00     7     10   10      1     13     9    69.23\n",
      "2128   11    0  100.00  85.71     6      6    7      0     11    11   100.00\n",
      "2129   18    0   69.23  60.00     9     13   15      2     18    17    94.44\n",
      "2130   37    0   70.83  65.38    17     24   26      3     37    34    91.89\n",
      "2131   25    0   82.35  66.67    14     17   21      4     25    23    92.00\n",
      "2132   13    0   90.00  81.82     9     10   11      0     13    12    92.31\n",
      "2133   32    0   69.57  76.19    16     23   21      0     32    29    90.62\n",
      "2134   15    0   81.82  60.00     9     11   15      2     15    13    86.67\n",
      "2135   33    0   86.96  83.33    20     23   24      2     33    33   100.00\n",
      "2136   36    0   85.71  85.71    24     28   28      0     36    33    91.67\n",
      "2137   26    0   85.71  81.82    18     21   22      1     26    25    96.15\n",
      "2138    9    0  100.00  62.50     5      5    8      0      9     8    88.89\n",
      "2139    7    0   83.33  71.43     5      6    7      0      7     7   100.00\n",
      "2140   28    0   85.71  85.71    18     21   21      1     28    24    85.71\n",
      "2141   15    0   73.33  68.75    11     15   16      0     15    13    86.67\n",
      "2142    8    0   50.00  33.33     3      6    9      0      8     7    87.50\n",
      "2143    5    0   33.33  20.00     1      3    5      0      5     3    60.00\n",
      "2144   13    0   38.46  38.46     5     13   13      4     13    11    84.62\n",
      "2145   15    0   53.85  50.00     7     13   14      6     15    14    93.33\n",
      "2146   41    0   75.00  70.00    21     28   30      4     41    39    95.12\n",
      "2147   16    0   92.31  80.00    12     13   15      1     16    15    93.75\n",
      "2148   23    0   88.24  78.95    15     17   19      0     23    23   100.00\n",
      "2149   20    0   63.64  70.00    14     22   20      3     20    18    90.00\n",
      "2150   26    0   85.71  85.71    18     21   21      0     26    23    88.46\n",
      "2151   31    0   64.52  66.67    20     31   30      5     31    27    87.10\n",
      "2152   19    0   75.00  71.43    15     20   21      4     19    18    94.74\n",
      "2153   37    0   76.67  69.70    23     30   33      4     37    34    91.89\n",
      "2154   20    0   66.67  62.50    10     15   16      0     20    17    85.00\n",
      "2155   18    0   66.67  66.67    10     15   15      3     18    15    83.33\n",
      "2156   26    0   84.21  80.00    16     19   20      2     26    23    88.46\n",
      "2157   24    0   69.23  56.25     9     13   16      1     24    21    87.50\n",
      "2158   27    0   88.46  82.14    23     26   28      0     27    23    85.19\n",
      "2159    6    0   75.00  50.00     3      4    6      0      6     5    83.33\n",
      "2160   50    0   57.58  46.34    19     33   41     11     50    45    90.00\n",
      "2161   19    0   71.43  62.50    10     14   16      3     19    17    89.47\n",
      "2162   31    0   47.62  45.45    10     21   22      6     31    29    93.55\n",
      "2163   45    0   44.74  51.52    17     38   33     13     45    43    95.56\n",
      "2164   15    0   75.00  80.00    12     16   15      2     15    14    93.33\n",
      "2165   32    0   69.44  71.43    25     36   35      6     32    30    93.75\n",
      "2166   17    0   92.31  85.71    12     13   14      0     17    16    94.12\n",
      "2167    5    0   75.00  60.00     3      4    5      0      5     4    80.00\n",
      "2168   17    0   87.50  82.35    14     16   17      0     17    15    88.24\n",
      "2169   22    0   81.25  68.42    13     16   19      1     22    21    95.45\n",
      "2170   15    0   84.62  84.62    11     13   13      0     15    15   100.00\n",
      "2171    8    0   45.45  55.56     5     11    9      1      8     7    87.50\n",
      "2172   20    0   58.82  58.82    10     17   17      4     20    17    85.00\n",
      "2173   10    0   83.33  71.43     5      6    7      0     10     6    60.00\n",
      "2174   10    0   85.71  66.67     6      7    9      0     10     8    80.00\n",
      "2175   23    0   82.35  73.68    14     17   19      0     23    23   100.00\n",
      "2176   33    0   42.86  45.45    15     35   33     12     33    28    84.85\n",
      "2177   28    0   87.50  87.50    14     16   16      0     28    28   100.00\n",
      "2178   20    0   84.21  84.21    16     19   19      2     20    19    95.00\n",
      "2179   23    0  100.00  94.12    16     16   17      0     23    22    95.65\n",
      "2180   40    0   87.88  93.55    29     33   31      0     40    39    97.50\n",
      "2181   15    0   90.00  75.00     9     10   12      0     15    12    80.00\n",
      "2182   40    0   65.52  59.38    19     29   32     10     40    38    95.00\n",
      "2183   30    0   88.46  79.31    23     26   29      3     30    29    96.67\n",
      "2184   11    0   88.89  80.00     8      9   10      0     11    10    90.91\n",
      "2185   41    0   76.00  76.00    19     25   25      1     41    37    90.24\n",
      "2186   33    0   77.78  77.78    21     27   27      0     33    31    93.94\n",
      "2187   26    0   52.38  57.89    11     21   19      7     26    23    88.46\n",
      "2188    8    0  100.00  85.71     6      6    7      0      8     8   100.00\n",
      "2189   40    0   67.50  71.05    27     40   38      8     40    38    95.00\n",
      "2190   27    0   60.00  54.55    12     20   22      4     27    24    88.89\n",
      "2191   21    0  100.00  96.15    25     25   26      0     21    19    90.48\n",
      "2192   42    0   55.56  55.56    15     27   27     10     42    41    97.62\n",
      "2193   20    0   88.89  84.21    16     18   19      1     20    19    95.00\n",
      "2194   54    0   50.00  48.89    22     44   45     14     54    49    90.74\n",
      "2195   41    0   91.43  88.89    32     35   36      0     41    38    92.68\n",
      "2196    5    0   20.00  20.00     1      5    5      1      5     4    80.00\n",
      "2197   32    0   90.00  87.10    27     30   31      2     32    29    90.62\n",
      "2198   20    0   88.89  88.89    16     18   18      0     20    20   100.00\n",
      "2199   15    0   90.91  76.92    10     11   13      1     15    13    86.67\n",
      "2200   19    0   71.43  76.92    10     14   13      1     19    18    94.74\n",
      "2201   16    0  100.00  90.00     9      9   10      0     16    14    87.50\n",
      "2202   14    0  100.00  92.31    12     12   13      0     14    12    85.71\n",
      "2203   13    0   88.89  88.89     8      9    9      0     13    11    84.62\n",
      "2204   43    0   63.64  52.50    21     33   40     11     43    38    88.37\n",
      "2205   13    0   75.00  75.00     6      8    8      1     13    12    92.31\n",
      "2206   26    0   84.00  80.77    21     25   26      2     26    25    96.15\n",
      "2207   42    0   61.54  57.14    16     26   28      8     42    41    97.62\n",
      "2208   30    0   69.57  72.73    16     23   22      3     30    29    96.67\n",
      "2209   16    0  100.00  91.67    11     11   12      0     16    15    93.75\n",
      "2210    2    0  100.00  66.67     2      2    3      0      2     1    50.00\n",
      "2211    3    0   50.00  33.33     1      2    3      0      3     3   100.00\n",
      "2212   24    0  100.00  90.91    10     10   11      0     24    21    87.50\n",
      "2213   15    0   76.92  62.50    10     13   16      2     15    13    86.67\n",
      "2214   17    0   40.00  44.44     4     10    9      1     17    17   100.00\n",
      "2215   26    0   69.23  69.23     9     13   13      1     26    26   100.00\n",
      "2216   13    0  100.00  90.00     9      9   10      0     13    11    84.62\n",
      "2217   26    0   85.71  81.82    18     21   22      2     26    23    88.46\n",
      "2218   10    0  100.00  87.50     7      7    8      0     10    10   100.00\n",
      "2219   26    0   94.44  89.47    17     18   19      0     26    26   100.00\n",
      "2220   20    0   81.82  69.23     9     11   13      1     20    19    95.00\n",
      "2221   50    0   62.86  66.67    22     35   33      7     50    45    90.00\n",
      "2222   15    0  100.00  93.33    14     14   15      0     15    15   100.00\n",
      "2223   24    0  100.00  86.67    13     13   15      0     24    23    95.83\n",
      "2224   29    0   82.61  82.61    19     23   23      1     29    29   100.00\n",
      "2225   34    0   83.33  90.91    20     24   22      1     34    31    91.18\n",
      "2226   21    0   54.55  63.16    12     22   19      2     21    19    90.48\n",
      "2227   14    0  100.00  93.75    15     15   16      0     14    14   100.00\n",
      "2228   28    0   64.00  50.00    16     25   32      6     28    24    85.71\n",
      "2229   25    0   92.31  92.31    24     26   26      0     25    23    92.00\n",
      "2230   21    0   93.33  87.50    14     15   16      0     21    20    95.24\n",
      "2231   21    0   70.59  63.16    12     17   19      3     21    18    85.71\n",
      "2232   24    0   80.00  80.00    16     20   20      2     24    23    95.83\n",
      "2233   19    0   93.33  93.33    14     15   15      0     19    19   100.00\n",
      "2234   24    0   55.56  47.62    10     18   21      5     24    21    87.50\n",
      "2235   37    0   68.00  51.52    17     25   33      9     37    33    89.19\n",
      "2236   33    0   77.27  77.27    17     22   22      3     33    31    93.94\n",
      "2237   17    0   82.35  77.78    14     17   18      2     17    14    82.35\n",
      "2238   13    0   91.67  73.33    11     12   15      0     13    12    92.31\n",
      "2239   22    0   77.78  77.78    14     18   18      2     22    21    95.45\n",
      "2240   41    0  100.00  92.00    23     23   25      0     41    39    95.12\n",
      "2241   18    0   75.00  81.82     9     12   11      0     18    14    77.78\n",
      "2242   21    0   72.73  50.00     8     11   16      2     21    20    95.24\n",
      "2243   28    0   84.00  87.50    21     25   24      2     28    25    89.29\n",
      "2244   29    0   85.00  70.83    17     20   24      1     29    27    93.10\n",
      "2245   29    0   58.06  69.23    18     31   26      5     29    24    82.76\n",
      "2246   32    0   95.65  95.65    22     23   23      0     32    30    93.75\n",
      "2247   15    0   81.25  86.67    13     16   15      1     15    14    93.33\n",
      "2248   24    0   40.00  37.50     6     15   16      5     24    21    87.50\n",
      "2249   63    0   67.39  70.45    31     46   44      6     63    58    92.06\n",
      "2250   29    0   88.00  78.57    22     25   28      2     29    26    89.66\n",
      "2251   13    0   88.89  80.00     8      9   10      0     13    11    84.62\n",
      "2252   14    0   90.91  76.92    10     11   13      0     14    13    92.86\n",
      "2253   30    0   85.00  65.38    17     20   26      2     30    27    90.00\n",
      "2254   25    0   66.67  55.56    10     15   18      3     25    24    96.00\n",
      "2255   26    0   76.00  79.17    19     25   24      3     26    25    96.15\n",
      "2256   20    0   70.00  58.33     7     10   12      1     20    20   100.00\n",
      "2257   28    0   95.65  88.00    22     23   25      1     28    26    92.86\n",
      "2258   42    0   60.98  65.79    25     41   38     11     42    40    95.24\n",
      "2259   12    0  100.00  88.89     8      8    9      0     12    12   100.00\n",
      "2260   13    0   57.14  66.67     8     14   12      2     13    11    84.62\n",
      "2261   19    0   91.67  78.57    11     12   14      1     19    17    89.47\n",
      "2262   52    0   73.68  73.68    28     38   38      7     52    49    94.23\n",
      "2263   22    0   71.43  66.67    10     14   15      0     22    21    95.45\n",
      "2264   38    0   65.52  70.37    19     29   27      4     38    35    92.11\n",
      "2265   23    0   66.67  66.67    16     24   24      5     23    20    86.96\n",
      "2266   33    0   87.50  87.50    21     24   24      1     33    32    96.97\n",
      "2267   27    0   85.00  80.95    17     20   21      2     27    27   100.00\n",
      "2268   13    0   90.91  76.92    10     11   13      0     13    12    92.31\n",
      "2269   32    0   87.50  80.77    21     24   26      4     32    31    96.88\n",
      "2270   43    0   80.56  80.56    29     36   36      5     43    42    97.67\n",
      "2271   20    0   92.31  85.71    12     13   14      0     20    20   100.00\n",
      "2272   28    0   66.67  73.68    14     21   19      2     28    25    89.29\n",
      "2273   30    0   93.10  93.10    27     29   29      0     30    27    90.00\n",
      "2274    9    0  100.00  87.50     7      7    8      0      9     8    88.89\n",
      "2275   21    0  100.00  94.12    16     16   17      0     21    21   100.00\n",
      "2276   22    0   47.37  45.00     9     19   20      9     22    22   100.00\n",
      "2277   32    0   86.36  67.86    19     22   28      4     32    31    96.88\n",
      "2278    7    0  100.00  85.71     6      6    7      0      7     7   100.00\n",
      "2279   31    0   76.19  64.00    16     21   25      1     31    29    93.55\n",
      "2280   31    0   46.88  45.45    15     32   33     12     31    29    93.55\n",
      "2281   16    0   75.00  69.23     9     12   13      0     16    13    81.25\n",
      "2282   33    0   87.50  90.32    28     32   31      0     33    29    87.88\n",
      "2283   16    0   66.67  50.00     6      9   12      2     16    15    93.75\n",
      "2284   27    0   79.17  73.08    19     24   26      3     27    24    88.89\n",
      "2285   24    0   65.00  56.52    13     20   23      4     24    23    95.83\n",
      "2286   13    0   88.89  80.00     8      9   10      0     13    12    92.31\n",
      "2287    5    0    0.00   0.00     0      4    5      1      5     4    80.00\n",
      "2288   16    0   84.62  84.62    11     13   13      0     16    16   100.00\n",
      "2289   27    0   87.50  84.00    21     24   25      1     27    25    92.59\n",
      "2290   24    0   90.48  82.61    19     21   23      0     24    24   100.00\n",
      "2291   23    0   75.00  70.59    12     16   17      2     23    22    95.65\n",
      "2292    6    0   80.00  66.67     4      5    6      0      6     5    83.33\n",
      "2293   22    0   64.29  64.29     9     14   14      3     22    22   100.00\n",
      "2294   13    0   72.73  66.67     8     11   12      2     13    13   100.00\n",
      "2295   21    0   76.47  68.42    13     17   19      1     21    20    95.24\n",
      "2296   22    0   68.75  61.11    11     16   18      3     22    18    81.82\n",
      "2297   12    0   88.89  72.73     8      9   11      0     12    12   100.00\n",
      "2298   23    0   83.33  75.00    15     18   20      0     23    20    86.96\n",
      "2299   25    0   43.75  38.89     7     16   18      5     25    23    92.00\n",
      "2300   12    0   72.73  72.73     8     11   11      0     12    11    91.67\n",
      "2301   20    0   77.78  73.68    14     18   19      1     20    17    85.00\n",
      "2302   27    0   52.38  50.00    11     21   22      3     27    22    81.48\n",
      "2303   10    0  100.00  85.71     6      6    7      0     10     9    90.00\n",
      "2304   24    0   40.00  38.10     8     20   21      8     24    20    83.33\n",
      "2305    4    0   75.00  60.00     3      4    5      0      4     2    50.00\n",
      "2306    4    0  100.00  80.00     4      4    5      0      4     3    75.00\n",
      "2307    5    0  100.00  80.00     4      4    5      0      5     3    60.00\n",
      "2308   26    0  100.00  94.74    18     18   19      0     26    25    96.15\n",
      "2309   30    0   91.18  93.94    31     34   33      0     30    29    96.67\n",
      "2310   18    0   92.86  86.67    13     14   15      0     18    18   100.00\n",
      "2311   25    0   40.91  50.00     9     22   18      5     25    21    84.00\n",
      "2312   33    0   73.91  77.27    17     23   22      1     33    30    90.91\n",
      "2313   33    0   46.88  57.69    15     32   26      5     33    28    84.85\n",
      "2314   26    0   73.91  70.83    17     23   24      1     26    25    96.15\n",
      "2315   34    0   81.82  77.14    27     33   35      5     34    31    91.18\n",
      "2316   19    0   92.86  86.67    13     14   15      0     19    18    94.74\n",
      "2317   22    0   75.00  75.00    12     16   16      1     22    20    90.91\n",
      "2318   43    0   63.41  68.42    26     41   38      8     43    41    95.35\n",
      "2319   12    0   57.14  36.36     4      7   11      2     12    12   100.00\n",
      "2320   19    0  100.00  92.86    13     13   14      0     19    19   100.00\n",
      "2321   27    0   70.83  68.00    17     24   25      5     27    26    96.30\n",
      "2322   37    0   88.89  88.89    24     27   27      1     37    35    94.59\n",
      "2323   10    0  100.00  87.50     7      7    8      0     10    10   100.00\n",
      "2324   36    0   64.00  61.54    16     25   26      7     36    33    91.67\n",
      "2325    8    0   75.00  85.71     6      8    7      0      8     7    87.50\n",
      "2326   18    2    0.00   0.00     0      0    0      0      0     0     0.00\n",
      "2327   32    0   51.72  57.69    15     29   26      8     32    27    84.38\n",
      "2328   17    0   72.73  61.54     8     11   13      3     17    17   100.00\n",
      "2329   28    0   84.00  75.00    21     25   28      3     28    27    96.43\n",
      "2330   18    0   25.00  26.67     4     16   15      5     18    15    83.33\n",
      "2331   24    0  100.00  94.44    17     17   18      0     24    22    91.67\n",
      "2332   23    0   47.06  36.36     8     17   22      7     23    20    86.96\n",
      "2333   12    0   62.50  55.56     5      8    9      0     12     9    75.00\n",
      "2334   46    0   48.57  50.00    17     35   34     10     46    41    89.13\n",
      "2335   24    0   68.42  65.00    13     19   20      2     24    22    91.67\n",
      "2336   20    0   86.67  86.67    13     15   15      1     20    20   100.00\n",
      "2337   18    0   84.62  84.62    11     13   13      0     18    17    94.44\n",
      "2338   11    0   88.89  80.00     8      9   10      0     11    10    90.91\n",
      "2339   10    0  100.00  90.91    10     10   11      0     10     9    90.00\n",
      "2340   26    0   50.00  45.83    11     22   24      7     26    23    88.46\n",
      "2341   32    0   72.00  69.23    18     25   26      6     32    31    96.88\n",
      "2342   25    0   44.44  44.44     8     18   18      6     25    22    88.00\n",
      "2343   22    0   94.12  88.89    16     17   18      0     22    21    95.45\n",
      "2344   19    0   72.73  61.54     8     11   13      1     19    16    84.21\n",
      "2345    7    0  100.00  80.00     4      4    5      0      7     6    85.71\n",
      "2346   13    0   83.33  76.92    10     12   13      0     13    12    92.31\n",
      "2347   22    0   72.22  81.25    13     18   16      2     22    17    77.27\n",
      "2348   21    0   85.71  85.71    12     14   14      0     21    20    95.24\n",
      "2349    7    0   80.00  57.14     4      5    7      1      7     6    85.71\n",
      "2350   26    0   71.43  71.43    15     21   21      4     26    24    92.31\n",
      "2351   24    0   63.16  54.55    12     19   22      5     24    22    91.67\n",
      "2352   28    0   52.63  45.45    10     19   22      6     28    23    82.14\n",
      "2353   32    0  100.00  95.45    21     21   22      0     32    32   100.00\n",
      "2354   14    0   66.67  50.00     6      9   12      2     14    13    92.86\n",
      "2355   42    0   58.82  60.61    20     34   33      4     42    34    80.95\n",
      "2356   29    0   92.31  96.00    24     26   25      0     29    27    93.10\n",
      "2357   44    0   80.56  76.32    29     36   38      6     44    44   100.00\n",
      "2358   10    0  100.00  88.89     8      8    9      0     10    10   100.00\n",
      "2359   37    0   78.26  72.00    18     23   25      3     37    35    94.59\n",
      "2360   31    0   50.00  55.00    11     22   20      4     31    26    83.87\n",
      "2361   17    0   82.35  77.78    14     17   18      2     17    15    88.24\n",
      "2362    9    0  100.00  87.50     7      7    8      0      9     8    88.89\n",
      "2363   24    0   78.95  71.43    15     19   21      1     24    23    95.83\n",
      "2364   19    0   93.33  93.33    14     15   15      0     19    18    94.74\n",
      "2365   29    0   50.00  54.55    12     24   22      5     29    24    82.76\n",
      "2366   24    0   75.00  71.43    15     20   21      3     24    24   100.00\n",
      "2367   15    0   72.73  57.14     8     11   14      3     15    14    93.33\n",
      "2368   26    0   94.12  88.89    16     17   18      0     26    25    96.15\n",
      "2369    6    0  100.00  85.71     6      6    7      0      6     6   100.00\n",
      "2370   36    0   85.71  77.42    24     28   31      2     36    31    86.11\n",
      "2371   22    0   83.33  83.33    15     18   18      1     22    20    90.91\n",
      "2372   31    0   90.91  88.24    30     33   34      1     31    29    93.55\n",
      "2373   14    0   72.73  66.67     8     11   12      2     14    13    92.86\n",
      "2374   27    0   80.95  80.95    17     21   21      2     27    27   100.00\n",
      "2375    5    0  100.00  85.71     6      6    7      0      5     5   100.00\n",
      "2376   14    0  100.00  90.00     9      9   10      0     14    13    92.86\n",
      "2377   25    0   84.21  80.00    16     19   20      1     25    23    92.00\n",
      "2378   16    0   92.31  80.00    12     13   15      1     16    16   100.00\n",
      "2379   15    0  100.00  91.67    11     11   12      0     15    13    86.67\n",
      "2380   24    0   61.11  57.89    11     18   19      2     24    22    91.67\n",
      "2381   40    0   72.22  70.27    26     36   37      7     40    39    97.50\n",
      "2382   43    0   79.41  79.41    27     34   34      3     43    41    95.35\n",
      "2383   34    0   90.00  84.38    27     30   32      0     34    32    94.12\n",
      "2384   31    0   71.43  65.22    15     21   23      4     31    28    90.32\n",
      "2385   22    0   90.00  94.74    18     20   19      0     22    20    90.91\n",
      "2386   12    0   50.00  55.56     5     10    9      3     12    10    83.33\n",
      "2387   25    0   94.12  88.89    16     17   18      0     25    24    96.00\n",
      "2388   48    0   70.73  74.36    29     41   39      8     48    47    97.92\n",
      "2389   11    0   66.67  85.71     6      9    7      0     11    11   100.00\n",
      "2390   32    0   63.16  48.00    12     19   25      9     32    30    93.75\n",
      "2391    4    0  100.00  50.00     1      1    2      0      4     3    75.00\n",
      "2392   18    0   83.33  71.43    10     12   14      1     18    17    94.44\n",
      "2393   34    0   66.67  53.33    16     24   30      8     34    33    97.06\n",
      "2394   32    0   54.17  54.17    13     24   24      6     32    29    90.62\n",
      "2395    4    0  100.00  50.00     1      1    2      0      4     3    75.00\n",
      "2396   21    0   43.75  38.89     7     16   18      3     21    19    90.48\n",
      "2397   28    0   90.48  82.61    19     21   23      0     28    27    96.43\n",
      "2398   24    0   63.64  63.64    14     22   22      4     24    21    87.50\n",
      "2399    6    0  100.00  50.00     1      1    2      0      6     5    83.33\n",
      "2400   16    0   81.82  69.23     9     11   13      1     16    16   100.00\n",
      "2401   35    0   66.67  53.85    14     21   26      5     35    33    94.29\n",
      "2402   35    0   69.23  66.67    18     26   27      4     35    32    91.43\n",
      "2403    6    0  100.00  50.00     1      1    2      0      6     5    83.33\n",
      "2404   14    0   87.50  70.00     7      8   10      0     14    12    85.71\n",
      "2405   16    0   55.56  45.45     5      9   11      2     16    15    93.75\n",
      "2406    7    0   75.00  42.86     3      4    7      0      7     6    85.71\n",
      "2407    6    0  100.00  50.00     1      1    2      0      6     5    83.33\n",
      "2408   13    0   66.67  60.00     6      9   10      2     13    12    92.31\n",
      "2409   32    0   52.38  50.00    11     21   22      5     32    29    90.62\n",
      "2410   10    0  100.00  87.50     7      7    8      0     10    10   100.00\n",
      "2411   24    0   94.12  88.89    16     17   18      0     24    23    95.83\n",
      "2412   11    0  100.00  88.89     8      8    9      0     11    10    90.91\n",
      "2413   23    0   91.67  84.62    11     12   13      0     23    18    78.26\n",
      "2414   34    0   60.71  68.00    17     28   25      4     34    32    94.12\n",
      "2415   13    0   36.36  50.00     4     11    8      2     13    12    92.31\n",
      "2416   13    0   57.14  36.36     4      7   11      1     13    13   100.00\n",
      "============================================================================\n",
      "                 74.19  70.00  32802 44215 46858   5844  56587 51908    91.73\n",
      "=== Summary ===\n",
      "\n",
      "-- All --\n",
      "Number of sentence        =   2416\n",
      "Number of Error sentence  =      0\n",
      "Number of Skip  sentence  =      6\n",
      "Number of Valid sentence  =   2410\n",
      "Bracketing Recall         =  74.19\n",
      "Bracketing Precision      =  70.00\n",
      "Bracketing FMeasure       =  72.03\n",
      "Complete match            =   0.00\n",
      "Average crossing          =   2.42\n",
      "No crossing               =  38.13\n",
      "2 or less crossing        =  66.14\n",
      "Tagging accuracy          =  91.73\n",
      "\n",
      "-- len<=40 --\n",
      "Number of sentence        =   2245\n",
      "Number of Error sentence  =      0\n",
      "Number of Skip  sentence  =      6\n",
      "Number of Valid sentence  =   2239\n",
      "Bracketing Recall         =  74.91\n",
      "Bracketing Precision      =  70.36\n",
      "Bracketing FMeasure       =  72.56\n",
      "Complete match            =   0.00\n",
      "Average crossing          =   2.10\n",
      "No crossing               =  40.60\n",
      "2 or less crossing        =  69.54\n",
      "Tagging accuracy          =  91.50\n"
     ]
    }
   ],
   "source": [
    "!./evalb -p COLLINS.prm 23.auto.clean ../23.auto.clean.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a28bb-c147-4021-abfb-3a30d0f70cce",
   "metadata": {},
   "source": [
    "#### From these results, we see\n",
    "\n",
    "for all sentences:\n",
    "\n",
    "- Bracketing Recall         =  74.91\n",
    "- Bracketing Precision      =  70.36\n",
    "- Bracketing FMeasure       =  72.56\n",
    "\n",
    "for sentences that have forty, or less than forty words:\n",
    "\n",
    "- Bracketing Recall         =  74.91\n",
    "- Bracketing Precision      =  70.36\n",
    "- Bracketing FMeasure       =  72.56\n",
    "\n",
    "We will just focus on sentences with less than forty words.\n",
    "\n",
    "A perfect FMeasure (100) would indicate perfect precison and recall. With a score of 72.56, we understand that our parser is 72.56 in its recall and precison. Both our **recall** and **precison** are around 70-74, meaning our algorithm returns 70% relevant results than irrelevant ones (precison) and that our algorhitm returns 74% of the relevant results (recall). \n",
    "\n",
    "These are both precise and able to recall to a similar degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-scene",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dependency parsing (UDPipe)\n",
    "**Dependency Parsing:** links words together in a sentence to show relationships between words and their constitutes\n",
    "\n",
    "We can use UDPipe, which is a Universal Dependency Pipeline toolkit that can help with \n",
    "- tokenization\n",
    "- tagging\n",
    "- lemmatization\n",
    "- dependency parsing\n",
    "\n",
    "We ``mkdir`` (make a directory/folder) to put our downloads in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "falling-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f029b7-3bb8-4f9a-858b-54b9b88860bd",
   "metadata": {},
   "source": [
    "``cd`` into this newly made folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a5eee3-e181-4f70-8a36-5213b1ecab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ed0da-7248-47e5-a983-8599b60cefb0",
   "metadata": {},
   "source": [
    "Download UDPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6bc771b-f946-4dcb-9a33-16f7d9b0ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-15 22:42:21--  https://github.com/ufal/udpipe/releases/download/v1.2.0/udpipe-1.2.0-bin.zip\n",
      "Resolving github.com (github.com)... 140.82.112.3\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/50672597/a24cacd8-77c6-11e7-8f6e-e9de8ca37f48?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211016T054221Z&X-Amz-Expires=300&X-Amz-Signature=ffd4a193d5457a90a7f862dc6c6270e379431b5fae07d1c389086d092f58477a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50672597&response-content-disposition=attachment%3B%20filename%3Dudpipe-1.2.0-bin.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-10-15 22:42:21--  https://github-releases.githubusercontent.com/50672597/a24cacd8-77c6-11e7-8f6e-e9de8ca37f48?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211016T054221Z&X-Amz-Expires=300&X-Amz-Signature=ffd4a193d5457a90a7f862dc6c6270e379431b5fae07d1c389086d092f58477a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50672597&response-content-disposition=attachment%3B%20filename%3Dudpipe-1.2.0-bin.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.111.154, 185.199.108.154, 185.199.109.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.111.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12644197 (12M) [application/octet-stream]\n",
      "Saving to: udpipe-1.2.0-bin.zip\n",
      "\n",
      "udpipe-1.2.0-bin.zi 100%[===================>]  12.06M  13.5MB/s    in 0.9s    \n",
      "\n",
      "2021-10-15 22:42:22 (13.5 MB/s) - udpipe-1.2.0-bin.zip saved [12644197/12644197]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/ufal/udpipe/releases/download/v1.2.0/udpipe-1.2.0-bin.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192943b1-0def-4cfd-8c59-c018c83c0a50",
   "metadata": {},
   "source": [
    "Get its contents with ``tar``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4578061c-8776-4f28-b764-52e3147b4833",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x udpipe-1.2.0-bin/\n",
      "x udpipe-1.2.0-bin/bin-linux32/\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Trainer.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Evaluator.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/InputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Comments.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/EmptyNodes.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/MultiwordToken.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Sentences.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/udpipe_csharp.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Pipeline.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Words.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Version.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Children.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/MultiwordTokens.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/EmptyNode.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Model.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Word.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Sentence.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/ProcessingError.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Token.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/OutputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-linux32/csharp/libudpipe_csharp.so\n",
      "x udpipe-1.2.0-bin/bin-linux32/java/\n",
      "x udpipe-1.2.0-bin/bin-linux32/java/libudpipe_java.so\n",
      "x udpipe-1.2.0-bin/bin-linux32/java/udpipe.jar\n",
      "x udpipe-1.2.0-bin/bin-linux32/udpipe\n",
      "x udpipe-1.2.0-bin/MANUAL.html\n",
      "x udpipe-1.2.0-bin/MANUAL\n",
      "x udpipe-1.2.0-bin/INSTALL\n",
      "x udpipe-1.2.0-bin/bin-linux64/\n",
      "x udpipe-1.2.0-bin/bin-linux64/udpipe\n",
      "x udpipe-1.2.0-bin/bin-linux64/java/\n",
      "x udpipe-1.2.0-bin/bin-linux64/java/udpipe.jar\n",
      "x udpipe-1.2.0-bin/bin-linux64/java/libudpipe_java.so\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Sentence.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/MultiwordTokens.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/InputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Word.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/EmptyNode.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Children.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Version.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/ProcessingError.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/EmptyNodes.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Words.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Evaluator.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/MultiwordToken.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Model.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Pipeline.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/udpipe_csharp.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Comments.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/OutputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Trainer.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Token.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Sentences.cs\n",
      "x udpipe-1.2.0-bin/bin-linux64/csharp/libudpipe_csharp.so\n",
      "x udpipe-1.2.0-bin/bin-osx/\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/libudpipe_csharp.dylib\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/EmptyNodes.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/EmptyNode.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Trainer.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/InputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Children.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Word.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Sentence.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Words.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/ProcessingError.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Version.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/udpipe_csharp.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/MultiwordToken.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Evaluator.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Model.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Comments.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/MultiwordTokens.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Sentences.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/OutputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Pipeline.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Token.cs\n",
      "x udpipe-1.2.0-bin/bin-osx/udpipe\n",
      "x udpipe-1.2.0-bin/bin-osx/java/\n",
      "x udpipe-1.2.0-bin/bin-osx/java/libudpipe_java.dylib\n",
      "x udpipe-1.2.0-bin/bin-osx/java/udpipe.jar\n",
      "x udpipe-1.2.0-bin/MANUAL.pdf\n",
      "x udpipe-1.2.0-bin/bindings/\n",
      "x udpipe-1.2.0-bin/bindings/README.PERL\n",
      "x udpipe-1.2.0-bin/bindings/perl/\n",
      "x udpipe-1.2.0-bin/bindings/perl/std_common.i\n",
      "x udpipe-1.2.0-bin/bindings/perl/perlstrings.swg\n",
      "x udpipe-1.2.0-bin/bindings/perl/Makefile\n",
      "x udpipe-1.2.0-bin/bindings/perl/examples/\n",
      "x udpipe-1.2.0-bin/bindings/perl/examples/run_udpipe.pl\n",
      "x udpipe-1.2.0-bin/bindings/perl/udpipe_perl.i\n",
      "x udpipe-1.2.0-bin/bindings/README.CS\n",
      "x udpipe-1.2.0-bin/bindings/README.PYTHON\n",
      "x udpipe-1.2.0-bin/bindings/README.JAVA\n",
      "x udpipe-1.2.0-bin/bindings/common/\n",
      "x udpipe-1.2.0-bin/bindings/common/udpipe.i\n",
      "x udpipe-1.2.0-bin/bindings/common/udpipe_stl.i\n",
      "x udpipe-1.2.0-bin/bindings/common/Makefile.common\n",
      "x udpipe-1.2.0-bin/bindings/java/\n",
      "x udpipe-1.2.0-bin/bindings/java/udpipe_java.i\n",
      "x udpipe-1.2.0-bin/bindings/java/examples/\n",
      "x udpipe-1.2.0-bin/bindings/java/examples/RunUDPipe.java\n",
      "x udpipe-1.2.0-bin/bindings/java/examples/Makefile\n",
      "x udpipe-1.2.0-bin/bindings/java/Makefile\n",
      "x udpipe-1.2.0-bin/bindings/csharp/\n",
      "x udpipe-1.2.0-bin/bindings/csharp/udpipe_csharp.i\n",
      "x udpipe-1.2.0-bin/bindings/csharp/Makefile\n",
      "x udpipe-1.2.0-bin/bindings/csharp/examples/\n",
      "x udpipe-1.2.0-bin/bindings/csharp/examples/RunUDPipe.cs\n",
      "x udpipe-1.2.0-bin/bindings/csharp/examples/Makefile\n",
      "x udpipe-1.2.0-bin/bindings/python/\n",
      "x udpipe-1.2.0-bin/bindings/python/Makefile\n",
      "x udpipe-1.2.0-bin/bindings/python/udpipe_python.i\n",
      "x udpipe-1.2.0-bin/bindings/python/examples/\n",
      "x udpipe-1.2.0-bin/bindings/python/examples/run_udpipe.py\n",
      "x udpipe-1.2.0-bin/bindings/python/examples/udpipe_model.py\n",
      "x udpipe-1.2.0-bin/bindings/python/pystrings.swg\n",
      "x udpipe-1.2.0-bin/bin-win32/\n",
      "x udpipe-1.2.0-bin/bin-win32/udpipe.exe\n",
      "x udpipe-1.2.0-bin/bin-win32/java/\n",
      "x udpipe-1.2.0-bin/bin-win32/java/udpipe.jar\n",
      "x udpipe-1.2.0-bin/bin-win32/java/udpipe_java.dll\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/udpipe_csharp.dll\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/MultiwordTokens.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Version.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/MultiwordToken.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Token.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Sentences.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Children.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Model.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Sentence.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/ProcessingError.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Evaluator.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Words.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Trainer.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/InputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/EmptyNodes.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Comments.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/OutputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/udpipe_csharp.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Word.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/EmptyNode.cs\n",
      "x udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Pipeline.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/\n",
      "x udpipe-1.2.0-bin/bin-win64/udpipe.exe\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/ProcessingError.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Version.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Evaluator.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Children.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Sentence.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Sentences.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/MultiwordTokens.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/udpipe_csharp.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Model.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/EmptyNode.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/EmptyNodes.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Trainer.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Word.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Words.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Comments.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Token.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Pipeline.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/MultiwordToken.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/OutputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/InputFormat.cs\n",
      "x udpipe-1.2.0-bin/bin-win64/csharp/udpipe_csharp.dll\n",
      "x udpipe-1.2.0-bin/bin-win64/java/\n",
      "x udpipe-1.2.0-bin/bin-win64/java/udpipe.jar\n",
      "x udpipe-1.2.0-bin/bin-win64/java/udpipe_java.dll\n",
      "x udpipe-1.2.0-bin/LICENSE\n",
      "x udpipe-1.2.0-bin/AUTHORS\n",
      "x udpipe-1.2.0-bin/README\n",
      "x udpipe-1.2.0-bin/src/\n",
      "x udpipe-1.2.0-bin/src/Makefile.builtem\n",
      "x udpipe-1.2.0-bin/src/tokenizer/\n",
      "x udpipe-1.2.0-bin/src/tokenizer/detokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/tokenizer/morphodita_tokenizer_wrapper.h\n",
      "x udpipe-1.2.0-bin/src/tokenizer/detokenizer.h\n",
      "x udpipe-1.2.0-bin/src/tokenizer/morphodita_tokenizer_wrapper.cpp\n",
      "x udpipe-1.2.0-bin/src/tokenizer/multiword_splitter.cpp\n",
      "x udpipe-1.2.0-bin/src/tokenizer/multiword_splitter.h\n",
      "x udpipe-1.2.0-bin/src/tokenizer/multiword_splitter_trainer.cpp\n",
      "x udpipe-1.2.0-bin/src/tokenizer/multiword_splitter_trainer.h\n",
      "x udpipe-1.2.0-bin/src/sentence/\n",
      "x udpipe-1.2.0-bin/src/sentence/empty_node.h\n",
      "x udpipe-1.2.0-bin/src/sentence/sentence.cpp\n",
      "x udpipe-1.2.0-bin/src/sentence/output_format.cpp\n",
      "x udpipe-1.2.0-bin/src/sentence/token.cpp\n",
      "x udpipe-1.2.0-bin/src/sentence/multiword_token.h\n",
      "x udpipe-1.2.0-bin/src/sentence/word.h\n",
      "x udpipe-1.2.0-bin/src/sentence/input_format.h\n",
      "x udpipe-1.2.0-bin/src/sentence/input_format.cpp\n",
      "x udpipe-1.2.0-bin/src/sentence/output_format.h\n",
      "x udpipe-1.2.0-bin/src/sentence/token.h\n",
      "x udpipe-1.2.0-bin/src/sentence/sentence.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/\n",
      "x udpipe-1.2.0-bin/src/rest_server/udpipe_service.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_request.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/version.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_builder.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_server.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_response_generator.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_response_generator.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_builder.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_service.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_server.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_builder.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_response_generator.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/response_generator.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_response_generator.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/version.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_builder.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/string_piece.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/AUTHORS\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/CHANGES\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/README\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/Makefile.include\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/microrestd.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/connection.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/microhttpd.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/internal.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/autoinit_funcs.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/platform.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/README\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/w32functions.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/AUTHORS\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/memorypool.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/MHD_config.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/daemon.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/internal.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/postprocessor.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/reason_phrase.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/COPYING\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/response.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/reason_phrase.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/tsearch.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/connection.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/response.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/memorypool.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/w32functions.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/platform_interface.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/LICENSE\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/pugixml.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/pugixml.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/README\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/AUTHORS\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/pugiconfig.h\n",
      "x udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/LICENSE\n",
      "x udpipe-1.2.0-bin/src/rest_server/udpipe_service.cpp\n",
      "x udpipe-1.2.0-bin/src/rest_server/udpipe_server.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/\n",
      "x udpipe-1.2.0-bin/src/parsito/Makefile.include\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/tree_format_conllu.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/tree.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/tree_format.h\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/tree_format.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/tree.h\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/node.h\n",
      "x udpipe-1.2.0-bin/src/parsito/tree/tree_format_conllu.h\n",
      "x udpipe-1.2.0-bin/src/parsito/AUTHORS\n",
      "x udpipe-1.2.0-bin/src/parsito/embedding/\n",
      "x udpipe-1.2.0-bin/src/parsito/embedding/embedding_encode.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/embedding/embedding.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/embedding/embedding.h\n",
      "x udpipe-1.2.0-bin/src/parsito/CHANGES\n",
      "x udpipe-1.2.0-bin/src/parsito/version/\n",
      "x udpipe-1.2.0-bin/src/parsito/version/version.h\n",
      "x udpipe-1.2.0-bin/src/parsito/version/version.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/configuration/\n",
      "x udpipe-1.2.0-bin/src/parsito/configuration/value_extractor.h\n",
      "x udpipe-1.2.0-bin/src/parsito/configuration/node_extractor.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/configuration/configuration.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/configuration/value_extractor.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/configuration/configuration.h\n",
      "x udpipe-1.2.0-bin/src/parsito/configuration/node_extractor.h\n",
      "x udpipe-1.2.0-bin/src/parsito/network/\n",
      "x udpipe-1.2.0-bin/src/parsito/network/activation_function.h\n",
      "x udpipe-1.2.0-bin/src/parsito/network/network_parameters.h\n",
      "x udpipe-1.2.0-bin/src/parsito/network/neural_network_trainer.h\n",
      "x udpipe-1.2.0-bin/src/parsito/network/neural_network_trainer.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/network/neural_network.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/network/neural_network.h\n",
      "x udpipe-1.2.0-bin/src/parsito/LICENSE\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system_projective.h\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system_swap.h\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system_link2.h\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system_link2.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system_projective.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system.h\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_system_swap.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition_oracle.h\n",
      "x udpipe-1.2.0-bin/src/parsito/transition/transition.h\n",
      "x udpipe-1.2.0-bin/src/parsito/parser/\n",
      "x udpipe-1.2.0-bin/src/parsito/parser/parser_nn_trainer.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/parser/parser.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/parser/parser.h\n",
      "x udpipe-1.2.0-bin/src/parsito/parser/parser_nn.cpp\n",
      "x udpipe-1.2.0-bin/src/parsito/parser/parser_nn.h\n",
      "x udpipe-1.2.0-bin/src/parsito/parser/parser_nn_trainer.h\n",
      "x udpipe-1.2.0-bin/src/parsito/README\n",
      "x udpipe-1.2.0-bin/src/Makefile.include\n",
      "x udpipe-1.2.0-bin/src/Makefile\n",
      "x udpipe-1.2.0-bin/src/trainer/\n",
      "x udpipe-1.2.0-bin/src/trainer/trainer_morphodita_parsito.h\n",
      "x udpipe-1.2.0-bin/src/trainer/trainer_morphodita_parsito.cpp\n",
      "x udpipe-1.2.0-bin/src/trainer/trainer.h\n",
      "x udpipe-1.2.0-bin/src/trainer/training_failure.cpp\n",
      "x udpipe-1.2.0-bin/src/trainer/training_failure.h\n",
      "x udpipe-1.2.0-bin/src/trainer/trainer.cpp\n",
      "x udpipe-1.2.0-bin/src/.clang_complete\n",
      "x udpipe-1.2.0-bin/src/common.h\n",
      "x udpipe-1.2.0-bin/src/.editorconfig\n",
      "x udpipe-1.2.0-bin/src/model/\n",
      "x udpipe-1.2.0-bin/src/model/model_morphodita_parsito.cpp\n",
      "x udpipe-1.2.0-bin/src/model/model_morphodita_parsito.h\n",
      "x udpipe-1.2.0-bin/src/model/pipeline.cpp\n",
      "x udpipe-1.2.0-bin/src/model/evaluator.cpp\n",
      "x udpipe-1.2.0-bin/src/model/model.cpp\n",
      "x udpipe-1.2.0-bin/src/model/evaluator.h\n",
      "x udpipe-1.2.0-bin/src/model/model.h\n",
      "x udpipe-1.2.0-bin/src/model/pipeline.h\n",
      "x udpipe-1.2.0-bin/src/udpipe.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/\n",
      "x udpipe-1.2.0-bin/src/morphodita/LICENSE\n",
      "x udpipe-1.2.0-bin/src/morphodita/Makefile.include\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_prefix_guesser_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/small_stringops.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/czech_lemma_addinfo.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/persistent_unordered_map.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/raw_morpho_dictionary_reader.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/tag_filter.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/Makefile\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_dictionary.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/raw_morpho_dictionary_reader.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser.rl\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/persistent_unordered_map_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_prefix_guesser.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_trainer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_dictionary_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_ids.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_trainer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_prefix_guesser_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/tag_filter.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/casing_variants.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/english_lemma_addinfo.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/generic_lemma_addinfo.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/derivator.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/derivation_formatter.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/derivator/derivation_formatter.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/CHANGES\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/unicode_tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/vertical_tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/czech_tokenizer.rl\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_network_trainer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/english_tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_factory.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/ragel_tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer_factory.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/czech_tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_network.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_network.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer_ids.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer.rl\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/unicode_tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory_encoder.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/Makefile\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/ragel_tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_trainer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer_factory.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/english_tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/vertical_tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_trainer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/ragel_tokenizer.rl\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/czech_tokenizer.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_factory.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tokenizer/english_tokenizer.rl\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/tagset_converter.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_id_tagset_converter.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/tagset_converter.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/pdt_to_conll2009_tagset_converter.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/pdt_to_conll2009_tagset_converter.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/identity_tagset_converter.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_comment_tagset_converter.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_comment_tagset_converter.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_id_tagset_converter.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagset_converter/identity_tagset_converter.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/version/\n",
      "x udpipe-1.2.0-bin/src/morphodita/version/version.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/version/version.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/README\n",
      "x udpipe-1.2.0-bin/src/morphodita/AUTHORS\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/generic_elementary_features.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/czech_elementary_features.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/perceptron_tagger_trainer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/feature_sequences_optimizer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/elementary_features_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/feature_sequences_encoder.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/training_maps.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/vli.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/tagger_trainer.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/tagger.cpp\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/feature_sequences.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/viterbi.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/elementary_features.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/tagger.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/tagger_ids.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/perceptron_tagger.h\n",
      "x udpipe-1.2.0-bin/src/morphodita/tagger/conllu_elementary_features.h\n",
      "x udpipe-1.2.0-bin/src/unilib/\n",
      "x udpipe-1.2.0-bin/src/unilib/CHANGES\n",
      "x udpipe-1.2.0-bin/src/unilib/utf8.h\n",
      "x udpipe-1.2.0-bin/src/unilib/README\n",
      "x udpipe-1.2.0-bin/src/unilib/version.cpp\n",
      "x udpipe-1.2.0-bin/src/unilib/unicode.cpp\n",
      "x udpipe-1.2.0-bin/src/unilib/AUTHORS\n",
      "x udpipe-1.2.0-bin/src/unilib/utf8.cpp\n",
      "x udpipe-1.2.0-bin/src/unilib/utf16.h\n",
      "x udpipe-1.2.0-bin/src/unilib/uninorms.cpp\n",
      "x udpipe-1.2.0-bin/src/unilib/utf16.cpp\n",
      "x udpipe-1.2.0-bin/src/unilib/uninorms.h\n",
      "x udpipe-1.2.0-bin/src/unilib/LICENSE\n",
      "x udpipe-1.2.0-bin/src/unilib/unicode.h\n",
      "x udpipe-1.2.0-bin/src/unilib/unistrip.cpp\n",
      "x udpipe-1.2.0-bin/src/unilib/unistrip.h\n",
      "x udpipe-1.2.0-bin/src/unilib/Makefile.include\n",
      "x udpipe-1.2.0-bin/src/unilib/version.h\n",
      "x udpipe-1.2.0-bin/src/utils/\n",
      "x udpipe-1.2.0-bin/src/utils/getwhole.h\n",
      "x udpipe-1.2.0-bin/src/utils/string_piece.h\n",
      "x udpipe-1.2.0-bin/src/utils/threadsafe_stack.h\n",
      "x udpipe-1.2.0-bin/src/utils/compressor.h\n",
      "x udpipe-1.2.0-bin/src/utils/compressor_save.cpp\n",
      "x udpipe-1.2.0-bin/src/utils/AUTHORS\n",
      "x udpipe-1.2.0-bin/src/utils/options.h\n",
      "x udpipe-1.2.0-bin/src/utils/parse_int.h\n",
      "x udpipe-1.2.0-bin/src/utils/url_detector.cpp\n",
      "x udpipe-1.2.0-bin/src/utils/CHANGES\n",
      "x udpipe-1.2.0-bin/src/utils/compressor_load.cpp\n",
      "x udpipe-1.2.0-bin/src/utils/getpara.h\n",
      "x udpipe-1.2.0-bin/src/utils/parse_double.h\n",
      "x udpipe-1.2.0-bin/src/utils/new_unique_ptr.h\n",
      "x udpipe-1.2.0-bin/src/utils/xml_encoded.h\n",
      "x udpipe-1.2.0-bin/src/utils/README\n",
      "x udpipe-1.2.0-bin/src/utils/named_values.h\n",
      "x udpipe-1.2.0-bin/src/utils/process_args.h\n",
      "x udpipe-1.2.0-bin/src/utils/pointer_decoder.h\n",
      "x udpipe-1.2.0-bin/src/utils/iostreams.h\n",
      "x udpipe-1.2.0-bin/src/utils/binary_decoder.h\n",
      "x udpipe-1.2.0-bin/src/utils/binary_encoder.h\n",
      "x udpipe-1.2.0-bin/src/utils/common.h\n",
      "x udpipe-1.2.0-bin/src/utils/LICENSE\n",
      "x udpipe-1.2.0-bin/src/utils/threadsafe_resource_loader.h\n",
      "x udpipe-1.2.0-bin/src/utils/url_detector.h\n",
      "x udpipe-1.2.0-bin/src/utils/split.h\n",
      "x udpipe-1.2.0-bin/src/utils/options.cpp\n",
      "x udpipe-1.2.0-bin/src/version/\n",
      "x udpipe-1.2.0-bin/src/version/version.cpp\n",
      "x udpipe-1.2.0-bin/src/version/version.h\n",
      "x udpipe-1.2.0-bin/CHANGES\n",
      "x udpipe-1.2.0-bin/src_lib_only/\n",
      "x udpipe-1.2.0-bin/src_lib_only/udpipe.cpp\n",
      "x udpipe-1.2.0-bin/src_lib_only/udpipe.h\n"
     ]
    }
   ],
   "source": [
    "!tar xvfz ./udpipe-1.2.0-bin.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f367124-7111-4035-a5a7-3d47058b4ec4",
   "metadata": {},
   "source": [
    "``ls`` (list) the files in our current directory. Make sure we have bin-osx and ``cd`` into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad27180-e8ca-44e0-a450-c7d6dc62fadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1280\n",
      "-rw-r--r--   1 annabellepurnomo  staff      82  2 Aug  2017 AUTHORS\n",
      "-rw-r--r--   1 annabellepurnomo  staff    1555  2 Aug  2017 CHANGES\n",
      "-rw-r--r--   1 annabellepurnomo  staff    3985  2 Aug  2017 INSTALL\n",
      "-rw-r--r--   1 annabellepurnomo  staff   16725  2 Aug  2017 LICENSE\n",
      "-rw-r--r--   1 annabellepurnomo  staff  116594  2 Aug  2017 MANUAL\n",
      "-rw-r--r--   1 annabellepurnomo  staff  190921  2 Aug  2017 MANUAL.html\n",
      "-rw-r--r--   1 annabellepurnomo  staff  306431  2 Aug  2017 MANUAL.pdf\n",
      "-rw-r--r--   1 annabellepurnomo  staff    1309  2 Aug  2017 README\n",
      "drwxr-xr-x@  5 annabellepurnomo  staff     160 15 Oct 22:43 \u001b[34mbin-linux32\u001b[m\u001b[m\n",
      "drwxr-xr-x@  5 annabellepurnomo  staff     160 15 Oct 22:43 \u001b[34mbin-linux64\u001b[m\u001b[m\n",
      "drwxr-xr-x@  6 annabellepurnomo  staff     192 16 Oct 14:37 \u001b[34mbin-osx\u001b[m\u001b[m\n",
      "drwxr-xr-x@  5 annabellepurnomo  staff     160 15 Oct 22:43 \u001b[34mbin-win32\u001b[m\u001b[m\n",
      "drwxr-xr-x@  5 annabellepurnomo  staff     160 15 Oct 22:43 \u001b[34mbin-win64\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 11 annabellepurnomo  staff     352 15 Oct 22:43 \u001b[34mbindings\u001b[m\u001b[m\n",
      "drwxr-xr-x@  6 annabellepurnomo  staff     192 15 Oct 23:01 \u001b[34mcomputational-tools-for-linguistic-analysis-ubc\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 19 annabellepurnomo  staff     608 15 Oct 22:43 \u001b[34msrc\u001b[m\u001b[m\n",
      "drwxr-xr-x@  4 annabellepurnomo  staff     128 15 Oct 22:43 \u001b[34msrc_lib_only\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -l /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing/udpipe-1.2.0-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3207283f-6992-4573-b07f-2e032650d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing/udpipe-1.2.0-bin/bin-osx\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing/udpipe-1.2.0-bin/bin-osx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6bb7b-99f0-451c-9bcf-720e705cd511",
   "metadata": {},
   "source": [
    "Check that we have udpipe in our cur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da6b5c15-8836-4f23-b5ec-274a800ad6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcsharp\u001b[m\u001b[m                \u001b[34mjava\u001b[m\u001b[m\n",
      "en_ewt-ud-test.parsed \u001b[31mudpipe\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0e6a2-111b-430e-9e11-df214ea3fce2",
   "metadata": {},
   "source": [
    "### CoNLLU format\n",
    "HEAD and DEPREL fields are used to encode a dependency tree over words\n",
    "\n",
    "- (6th column) **HEAD**: \"head\" of the current word with its word index or 0\n",
    "\n",
    "- (7th column) **DEPREL**: \"universal dependency relation\" to the HEAD (root if HEAD is 0)\n",
    "\n",
    "Here is our training file in the CoNLL-U Format.\n",
    "Note the part that indicates its constituents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca7c295-f4fa-40e2-beb1-dcd2db2eb1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# newdoc id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713\n",
      "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0001\n",
      "# newpar id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-p0001\n",
      "# text = From the AP comes this story :\n",
      "1\tFrom\tfrom\tADP\tIN\t_\t3\tcase\t3:case\t_\n",
      "2\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t3\tdet\t3:det\t_\n",
      "3\tAP\tAP\tPROPN\tNNP\tNumber=Sing\t4\tobl\t4:obl:from\t_\n",
      "4\tcomes\tcome\tVERB\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t0:root\t_\n",
      "5\tthis\tthis\tDET\tDT\tNumber=Sing|PronType=Dem\t6\tdet\t6:det\t_\n",
      "6\tstory\tstory\tNOUN\tNN\tNumber=Sing\t4\tnsubj\t4:nsubj\t_\n"
     ]
    }
   ],
   "source": [
    "!head /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/UD_English-EWT/en_ewt-ud-dev.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0826f77-5f8f-403b-aaa2-51e92f25adeb",
   "metadata": {},
   "source": [
    "Train our model ``ud_english-ewt.model`` (what we want to output) using our heldout (testing) file ``en_ewt-ud-dev.conllu`` and ``en_ewt-ud-train.conllu`` (training) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ab44b4b-0464-4dbe-9ef4-ef9304579ecf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: done.\n",
      "Training the UDPipe model.\n",
      "Training tokenizer with the following options: tokenize_url=1, allow_spaces=0, dimension=24\n",
      "  epochs=100, batch_size=50, learning_rate=0.0050, dropout=0.1000, early_stopping=1\n",
      "Epoch 1, logprob: -5.8952e+04, training acc: 96.04%, heldout tokens: 97.52%P/97.02%R/97.27%, sentences: 79.44%P/75.67%R/77.51%\n",
      "Epoch 2, logprob: -1.2823e+04, training acc: 99.13%, heldout tokens: 98.50%P/98.11%R/98.30%, sentences: 83.42%P/78.42%R/80.84%\n",
      "Epoch 3, logprob: -1.1254e+04, training acc: 99.23%, heldout tokens: 98.77%P/97.99%R/98.38%, sentences: 85.85%P/79.37%R/82.48%\n",
      "Epoch 4, logprob: -9.8629e+03, training acc: 99.31%, heldout tokens: 98.86%P/98.65%R/98.75%, sentences: 87.20%P/78.92%R/82.85%\n",
      "Epoch 5, logprob: -9.2433e+03, training acc: 99.33%, heldout tokens: 98.97%P/98.53%R/98.75%, sentences: 87.00%P/79.22%R/82.93%\n",
      "Epoch 6, logprob: -8.7021e+03, training acc: 99.39%, heldout tokens: 98.87%P/98.77%R/98.82%, sentences: 86.64%P/80.02%R/83.20%\n",
      "Epoch 7, logprob: -8.4403e+03, training acc: 99.38%, heldout tokens: 99.10%P/98.79%R/98.94%, sentences: 82.90%P/80.37%R/81.61%\n",
      "Epoch 8, logprob: -8.0925e+03, training acc: 99.43%, heldout tokens: 98.96%P/98.81%R/98.88%, sentences: 87.53%P/80.97%R/84.12%\n",
      "Epoch 9, logprob: -8.0702e+03, training acc: 99.42%, heldout tokens: 99.10%P/98.93%R/99.01%, sentences: 87.57%P/80.97%R/84.14%\n",
      "Epoch 10, logprob: -7.4018e+03, training acc: 99.47%, heldout tokens: 98.99%P/98.89%R/98.94%, sentences: 89.13%P/80.27%R/84.47%\n",
      "Epoch 11, logprob: -7.6167e+03, training acc: 99.45%, heldout tokens: 99.19%P/98.85%R/99.02%, sentences: 88.82%P/80.92%R/84.68%\n",
      "Epoch 12, logprob: -7.0991e+03, training acc: 99.49%, heldout tokens: 99.14%P/98.92%R/99.03%, sentences: 85.97%P/81.72%R/83.79%\n",
      "Epoch 13, logprob: -7.1763e+03, training acc: 99.48%, heldout tokens: 99.07%P/98.84%R/98.96%, sentences: 87.94%P/81.62%R/84.66%\n",
      "Epoch 14, logprob: -7.1208e+03, training acc: 99.50%, heldout tokens: 99.16%P/99.01%R/99.09%, sentences: 88.49%P/81.42%R/84.81%\n",
      "Epoch 15, logprob: -6.9578e+03, training acc: 99.51%, heldout tokens: 99.13%P/98.83%R/98.98%, sentences: 87.42%P/81.22%R/84.21%\n",
      "Epoch 16, logprob: -6.8870e+03, training acc: 99.52%, heldout tokens: 99.21%P/98.90%R/99.06%, sentences: 89.08%P/81.47%R/85.10%\n",
      "Epoch 17, logprob: -6.7304e+03, training acc: 99.52%, heldout tokens: 99.18%P/98.98%R/99.08%, sentences: 88.88%P/81.87%R/85.23%\n",
      "Epoch 18, logprob: -6.6146e+03, training acc: 99.52%, heldout tokens: 99.19%P/98.76%R/98.97%, sentences: 89.14%P/81.22%R/85.00%\n",
      "Epoch 19, logprob: -6.7191e+03, training acc: 99.52%, heldout tokens: 99.16%P/98.99%R/99.07%, sentences: 87.48%P/82.37%R/84.85%\n",
      "Epoch 20, logprob: -6.4354e+03, training acc: 99.53%, heldout tokens: 99.20%P/98.92%R/99.06%, sentences: 88.31%P/81.52%R/84.78%\n",
      "Epoch 21, logprob: -6.6231e+03, training acc: 99.53%, heldout tokens: 99.17%P/98.90%R/99.04%, sentences: 87.95%P/82.42%R/85.10%\n",
      "Epoch 22, logprob: -6.6706e+03, training acc: 99.52%, heldout tokens: 99.13%P/98.92%R/99.03%, sentences: 87.18%P/81.52%R/84.25%\n",
      "Epoch 23, logprob: -6.2420e+03, training acc: 99.56%, heldout tokens: 99.24%P/98.97%R/99.11%, sentences: 88.56%P/81.57%R/84.92%\n",
      "Epoch 24, logprob: -6.2782e+03, training acc: 99.53%, heldout tokens: 99.24%P/98.98%R/99.11%, sentences: 87.19%P/81.27%R/84.13%\n",
      "Epoch 25, logprob: -6.1383e+03, training acc: 99.56%, heldout tokens: 99.11%P/98.40%R/98.75%, sentences: 88.84%P/82.72%R/85.67%\n",
      "Epoch 26, logprob: -6.4519e+03, training acc: 99.55%, heldout tokens: 99.35%P/99.01%R/99.18%, sentences: 88.20%P/82.52%R/85.26%\n",
      "Epoch 27, logprob: -6.1875e+03, training acc: 99.56%, heldout tokens: 99.20%P/98.97%R/99.08%, sentences: 87.99%P/82.37%R/85.09%\n",
      "Epoch 28, logprob: -6.2592e+03, training acc: 99.54%, heldout tokens: 99.22%P/99.00%R/99.11%, sentences: 88.64%P/81.87%R/85.12%\n",
      "Epoch 29, logprob: -6.4524e+03, training acc: 99.54%, heldout tokens: 99.24%P/98.80%R/99.02%, sentences: 88.65%P/81.92%R/85.15%\n",
      "Epoch 30, logprob: -5.9436e+03, training acc: 99.57%, heldout tokens: 99.24%P/99.00%R/99.12%, sentences: 87.98%P/83.02%R/85.43%\n",
      "Epoch 31, logprob: -5.9581e+03, training acc: 99.58%, heldout tokens: 99.16%P/99.02%R/99.09%, sentences: 89.18%P/82.32%R/85.61%\n",
      "Epoch 32, logprob: -6.0723e+03, training acc: 99.56%, heldout tokens: 99.22%P/98.98%R/99.10%, sentences: 88.63%P/82.97%R/85.71%\n",
      "Epoch 33, logprob: -6.2015e+03, training acc: 99.56%, heldout tokens: 99.14%P/98.85%R/98.99%, sentences: 88.70%P/82.32%R/85.39%\n",
      "Epoch 34, logprob: -6.2984e+03, training acc: 99.56%, heldout tokens: 99.17%P/99.05%R/99.11%, sentences: 88.49%P/82.57%R/85.43%\n",
      "Epoch 35, logprob: -5.7250e+03, training acc: 99.58%, heldout tokens: 99.14%P/99.03%R/99.08%, sentences: 88.61%P/83.17%R/85.80%\n",
      "Epoch 36, logprob: -6.0764e+03, training acc: 99.56%, heldout tokens: 99.18%P/98.97%R/99.07%, sentences: 88.55%P/82.67%R/85.51%\n",
      "Epoch 37, logprob: -6.1018e+03, training acc: 99.57%, heldout tokens: 99.16%P/99.01%R/99.08%, sentences: 86.70%P/82.37%R/84.48%\n",
      "Epoch 38, logprob: -5.7743e+03, training acc: 99.58%, heldout tokens: 99.10%P/98.94%R/99.02%, sentences: 88.76%P/82.07%R/85.28%\n",
      "Epoch 39, logprob: -5.9595e+03, training acc: 99.57%, heldout tokens: 99.19%P/99.00%R/99.09%, sentences: 88.39%P/81.37%R/84.73%\n",
      "Epoch 40, logprob: -5.8647e+03, training acc: 99.59%, heldout tokens: 99.26%P/99.06%R/99.16%, sentences: 88.26%P/81.87%R/84.94%\n",
      "Epoch 41, logprob: -5.7008e+03, training acc: 99.60%, heldout tokens: 99.24%P/99.03%R/99.14%, sentences: 88.52%P/81.67%R/84.96%\n",
      "Epoch 42, logprob: -5.8144e+03, training acc: 99.59%, heldout tokens: 99.19%P/99.03%R/99.11%, sentences: 88.33%P/83.17%R/85.67%\n",
      "Epoch 43, logprob: -5.7875e+03, training acc: 99.58%, heldout tokens: 99.24%P/99.04%R/99.14%, sentences: 87.99%P/81.62%R/84.69%\n",
      "Epoch 44, logprob: -5.9373e+03, training acc: 99.58%, heldout tokens: 99.28%P/99.08%R/99.18%, sentences: 88.98%P/83.07%R/85.92%\n",
      "Epoch 45, logprob: -5.7039e+03, training acc: 99.60%, heldout tokens: 99.18%P/99.07%R/99.12%, sentences: 88.87%P/82.57%R/85.60%\n",
      "Epoch 46, logprob: -5.6162e+03, training acc: 99.59%, heldout tokens: 99.24%P/99.00%R/99.12%, sentences: 89.31%P/82.62%R/85.83%\n",
      "Epoch 47, logprob: -5.5298e+03, training acc: 99.61%, heldout tokens: 99.19%P/99.12%R/99.15%, sentences: 87.34%P/82.72%R/84.97%\n",
      "Epoch 48, logprob: -5.7541e+03, training acc: 99.59%, heldout tokens: 99.26%P/99.07%R/99.16%, sentences: 88.33%P/81.67%R/84.87%\n",
      "Epoch 49, logprob: -5.8132e+03, training acc: 99.58%, heldout tokens: 99.27%P/99.13%R/99.20%, sentences: 87.30%P/82.77%R/84.97%\n",
      "Epoch 50, logprob: -5.6241e+03, training acc: 99.60%, heldout tokens: 99.25%P/99.10%R/99.18%, sentences: 88.97%P/83.42%R/86.10%\n",
      "Epoch 51, logprob: -5.6853e+03, training acc: 99.59%, heldout tokens: 99.22%P/98.96%R/99.09%, sentences: 88.79%P/83.12%R/85.86%\n",
      "Epoch 52, logprob: -5.7497e+03, training acc: 99.59%, heldout tokens: 99.29%P/99.05%R/99.17%, sentences: 88.66%P/82.37%R/85.40%\n",
      "Epoch 53, logprob: -5.4768e+03, training acc: 99.61%, heldout tokens: 99.25%P/99.15%R/99.20%, sentences: 88.36%P/82.27%R/85.20%\n",
      "Epoch 54, logprob: -5.6770e+03, training acc: 99.59%, heldout tokens: 99.26%P/98.94%R/99.10%, sentences: 88.42%P/82.77%R/85.50%\n",
      "Epoch 55, logprob: -5.4420e+03, training acc: 99.60%, heldout tokens: 99.24%P/98.95%R/99.10%, sentences: 89.16%P/84.22%R/86.62%\n",
      "Epoch 56, logprob: -5.5797e+03, training acc: 99.60%, heldout tokens: 99.25%P/99.06%R/99.16%, sentences: 88.67%P/83.27%R/85.88%\n",
      "Epoch 57, logprob: -5.3237e+03, training acc: 99.61%, heldout tokens: 99.22%P/99.07%R/99.14%, sentences: 88.41%P/83.47%R/85.87%\n",
      "Epoch 58, logprob: -5.7636e+03, training acc: 99.59%, heldout tokens: 99.29%P/99.05%R/99.16%, sentences: 88.33%P/83.17%R/85.67%\n",
      "Epoch 59, logprob: -5.4485e+03, training acc: 99.62%, heldout tokens: 99.17%P/99.07%R/99.12%, sentences: 85.78%P/82.87%R/84.30%\n",
      "Epoch 60, logprob: -5.4722e+03, training acc: 99.61%, heldout tokens: 99.28%P/99.02%R/99.15%, sentences: 87.44%P/82.77%R/85.04%\n",
      "Epoch 61, logprob: -5.4085e+03, training acc: 99.61%, heldout tokens: 99.21%P/99.07%R/99.14%, sentences: 88.10%P/83.97%R/85.98%\n",
      "Epoch 62, logprob: -5.5194e+03, training acc: 99.61%, heldout tokens: 99.20%P/99.05%R/99.13%, sentences: 89.28%P/82.82%R/85.93%\n",
      "Epoch 63, logprob: -5.6964e+03, training acc: 99.59%, heldout tokens: 99.23%P/99.02%R/99.12%, sentences: 89.50%P/83.47%R/86.38%\n",
      "Epoch 64, logprob: -5.2013e+03, training acc: 99.63%, heldout tokens: 99.24%P/99.02%R/99.13%, sentences: 88.36%P/83.42%R/85.82%\n",
      "Epoch 65, logprob: -5.3340e+03, training acc: 99.62%, heldout tokens: 99.21%P/99.05%R/99.13%, sentences: 88.60%P/83.47%R/85.96%\n",
      "Epoch 66, logprob: -5.4847e+03, training acc: 99.61%, heldout tokens: 99.26%P/99.07%R/99.17%, sentences: 88.98%P/82.72%R/85.74%\n",
      "Epoch 67, logprob: -5.4316e+03, training acc: 99.62%, heldout tokens: 99.29%P/99.14%R/99.21%, sentences: 89.37%P/82.77%R/85.94%\n",
      "Epoch 68, logprob: -5.6818e+03, training acc: 99.60%, heldout tokens: 99.23%P/99.11%R/99.17%, sentences: 88.94%P/82.32%R/85.50%\n",
      "Epoch 69, logprob: -5.2790e+03, training acc: 99.62%, heldout tokens: 99.29%P/99.07%R/99.18%, sentences: 87.58%P/83.47%R/85.47%\n",
      "Epoch 70, logprob: -5.4135e+03, training acc: 99.61%, heldout tokens: 99.32%P/99.04%R/99.18%, sentences: 89.87%P/83.27%R/86.44%\n",
      "Epoch 71, logprob: -5.5161e+03, training acc: 99.61%, heldout tokens: 99.19%P/98.97%R/99.08%, sentences: 88.90%P/82.42%R/85.54%\n",
      "Epoch 72, logprob: -5.4368e+03, training acc: 99.60%, heldout tokens: 99.32%P/98.98%R/99.15%, sentences: 88.80%P/82.37%R/85.46%\n",
      "Epoch 73, logprob: -5.3992e+03, training acc: 99.62%, heldout tokens: 99.26%P/99.11%R/99.19%, sentences: 89.27%P/82.72%R/85.87%\n",
      "Epoch 74, logprob: -5.1892e+03, training acc: 99.64%, heldout tokens: 99.29%P/99.03%R/99.16%, sentences: 89.87%P/83.32%R/86.47%\n",
      "Epoch 75, logprob: -5.3388e+03, training acc: 99.62%, heldout tokens: 99.31%P/99.07%R/99.19%, sentences: 89.16%P/82.57%R/85.74%\n",
      "Epoch 76, logprob: -5.5301e+03, training acc: 99.61%, heldout tokens: 99.21%P/99.06%R/99.14%, sentences: 88.27%P/82.72%R/85.40%\n",
      "Epoch 77, logprob: -5.3693e+03, training acc: 99.62%, heldout tokens: 99.19%P/99.02%R/99.10%, sentences: 88.15%P/82.87%R/85.43%\n",
      "Epoch 78, logprob: -5.3057e+03, training acc: 99.62%, heldout tokens: 99.24%P/99.08%R/99.16%, sentences: 89.16%P/82.97%R/85.95%\n",
      "Epoch 79, logprob: -5.2628e+03, training acc: 99.62%, heldout tokens: 99.26%P/99.05%R/99.16%, sentences: 88.36%P/82.67%R/85.42%\n",
      "Epoch 80, logprob: -5.3988e+03, training acc: 99.62%, heldout tokens: 99.27%P/98.96%R/99.12%, sentences: 89.54%P/83.82%R/86.58%\n",
      "Epoch 81, logprob: -5.2389e+03, training acc: 99.63%, heldout tokens: 99.30%P/99.10%R/99.20%, sentences: 89.36%P/83.52%R/86.34%\n",
      "Epoch 82, logprob: -5.2151e+03, training acc: 99.63%, heldout tokens: 99.19%P/99.05%R/99.12%, sentences: 89.13%P/83.12%R/86.02%\n",
      "Epoch 83, logprob: -5.3527e+03, training acc: 99.61%, heldout tokens: 99.23%P/99.13%R/99.18%, sentences: 88.58%P/82.52%R/85.44%\n",
      "Epoch 84, logprob: -5.4008e+03, training acc: 99.62%, heldout tokens: 99.27%P/98.92%R/99.10%, sentences: 87.57%P/82.72%R/85.08%\n",
      "Epoch 85, logprob: -5.3121e+03, training acc: 99.62%, heldout tokens: 99.23%P/99.05%R/99.14%, sentences: 89.43%P/81.97%R/85.54%\n",
      "Epoch 86, logprob: -5.2898e+03, training acc: 99.63%, heldout tokens: 99.22%P/98.96%R/99.09%, sentences: 88.80%P/82.77%R/85.68%\n",
      "Stopping after 30 iterations of not improving sum of sentence and token f1.\n",
      "Choosing parameters from epoch 55.\n",
      "Tagger model 1 columns: lemma use=1/provide=1, xpostag use=1/provide=1, feats use=1/provide=1\n",
      "Creating morphological dictionary for tagger model 1.\n",
      "Tagger model 1 dictionary options: max_form_analyses=0, custom dictionary_file=none\n",
      "Tagger model 1 guesser options: suffix_rules=8, prefixes_max=4, prefix_min_count=10, enrich_dictionary=6\n",
      "Tagger model 1 options: iterations=20, early_stopping=1, templates=tagger\n",
      "Training tagger model 1.\n",
      "Iteration 1: done, accuracy 74.40%, heldout accuracy 79.07%t/93.18%l/77.15%b\n",
      "Iteration 2: done, accuracy 84.40%, heldout accuracy 80.26%t/93.48%l/78.29%b\n",
      "Iteration 3: done, accuracy 88.22%, heldout accuracy 80.79%t/93.59%l/78.82%b\n",
      "Iteration 4: done, accuracy 90.29%, heldout accuracy 81.00%t/93.69%l/79.06%b\n",
      "Iteration 5: done, accuracy 91.77%, heldout accuracy 81.27%t/93.78%l/79.33%b\n",
      "Iteration 6: done, accuracy 92.83%, heldout accuracy 81.47%t/93.83%l/79.54%b\n",
      "Iteration 7: done, accuracy 93.71%, heldout accuracy 81.60%t/93.86%l/79.66%b\n",
      "Iteration 8: done, accuracy 94.48%, heldout accuracy 81.71%t/93.90%l/79.78%b\n",
      "Iteration 9: done, accuracy 94.98%, heldout accuracy 81.78%t/93.95%l/79.86%b\n",
      "Iteration 10: done, accuracy 95.47%, heldout accuracy 81.82%t/93.97%l/79.87%b\n",
      "Iteration 11: done, accuracy 95.88%, heldout accuracy 81.84%t/93.96%l/79.86%b\n",
      "Iteration 12: done, accuracy 96.28%, heldout accuracy 81.85%t/93.95%l/79.85%b\n",
      "Iteration 13: done, accuracy 96.58%, heldout accuracy 81.83%t/93.91%l/79.83%b\n",
      "Iteration 14: done, accuracy 96.84%, heldout accuracy 81.77%t/93.90%l/79.76%b\n",
      "Iteration 15: done, accuracy 97.03%, heldout accuracy 81.74%t/93.89%l/79.72%b\n",
      "Iteration 16: done, accuracy 97.27%, heldout accuracy 81.80%t/93.90%l/79.77%b\n",
      "Iteration 17: done, accuracy 97.49%, heldout accuracy 81.79%t/93.88%l/79.74%b\n",
      "Iteration 18: done, accuracy 97.63%, heldout accuracy 81.78%t/93.84%l/79.73%b\n",
      "Iteration 19: done, accuracy 97.83%, heldout accuracy 81.75%t/93.87%l/79.71%b\n",
      "Iteration 20: done, accuracy 97.92%, heldout accuracy 81.76%t/93.87%l/79.73%b\n",
      "Chosen tagger model from iteration 10\n",
      "Parser transition options: system=projective, oracle=dynamic, structured_interval=8, single_root=1\n",
      "Parser uses lemmas/upos/xpos/feats: automatically generated by tagger\n",
      "Parser embeddings options: upostag=20, feats=20, xpostag=0, form=50, lemma=0, deprel=20\n",
      "  form mincount=2, precomputed form embeddings=none\n",
      "  lemma mincount=2, precomputed lemma embeddings=none\n",
      "Parser network options: iterations=10, hidden_layer=200, batch_size=10,\n",
      "  learning_rate=0.0200, learning_rate_final=0.0010, l2=0.5000, early_stopping=1\n",
      "Initialized 'universal_tag' embedding with 0,17 words and 0.0%,100.0% coverage.\n",
      "Initialized 'feats' embedding with 0,95 words and 0.0%,100.0% coverage.\n",
      "Initialized 'form' embedding with 0,9873 words and 0.0%,96.1% coverage.\n",
      "Initialized 'deprel' embedding with 0,49 words and 0.0%,100.0% coverage.\n",
      "Iteration 1: training logprob -3.0347e+05, heldout UAS 66.89%, LAS 60.78%\n",
      "Iteration 2: training logprob -4.8026e+05, heldout UAS 67.77%, LAS 61.16%\n",
      "Iteration 3: training logprob -3.8797e+05, heldout UAS 69.87%, LAS 64.06%\n",
      "Iteration 4: training logprob -3.3033e+05, heldout UAS 73.02%, LAS 67.78%\n",
      "Iteration 5: training logprob -2.8972e+05, heldout UAS 75.32%, LAS 69.78%\n",
      "Iteration 6: training logprob -2.6235e+05, heldout UAS 73.85%, LAS 68.83%\n",
      "Iteration 7: training logprob -2.4008e+05, heldout UAS 76.55%, LAS 71.61%\n",
      "Iteration 8: training logprob -2.2490e+05, heldout UAS 77.81%, LAS 72.94%\n",
      "Iteration 9: training logprob -2.1170e+05, heldout UAS 77.34%, LAS 72.70%\n",
      "Iteration 10: training logprob -2.0477e+05, heldout UAS 78.29%, LAS 73.39%\n",
      "Using early stopping -- choosing network from iteration 10\n",
      "The trained UDPipe model was saved.\n"
     ]
    }
   ],
   "source": [
    "!./udpipe --train ud_english_ewt.model --heldout=/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/UD_English-EWT/en_ewt-ud-dev.conllu /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/UD_English-EWT/en_ewt-ud-train.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7722dd-75ac-42ca-a74d-4c6c4a5de157",
   "metadata": {},
   "source": [
    "Evaluate the accuracy of your UDPipe model on test data ``en_ewt-ud-test.conllu``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a1badbc-4c42-4b2d-8f7a-141cc4f94a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./udpipe --accuracy ./ud_english_ewt.model /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/UD_English-EWT/en_ewt-ud-test.conllu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc338f-14d8-4cb9-b540-d7d2acc1441f",
   "metadata": {},
   "source": [
    "Test the accuracy of our model ``ud_english_ewt.model`` using ``en_ewt-ud-test.conllu`` as test data. \n",
    "\n",
    "- \\-tokenize : tokenize our input\n",
    "- \\-tag : perform tagging on our input \n",
    "- \\-parse : perform parsing on our input \n",
    "- \\--input=horizontal : specifies that our input data has each sentence on a separate line, with tokens separated by spaces \n",
    "\n",
    "We are outputting our newly parsed file into ``en_ewt-ud-test.parsed``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6a4ce43-6052-4e0f-97ab-07f0639acbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n"
     ]
    }
   ],
   "source": [
    "!./udpipe -tokenize -tag --parse --input=horizontal ud_english_ewt.model /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/UD_English-EWT/en_ewt-ud-test.txt > en_ewt-ud-test.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee9583-ad96-438d-80e1-dfb56db30194",
   "metadata": {},
   "source": [
    "``cd`` back into our dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cfb91a4-539e-42e5-a018-f3afd616a202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03683f59-4441-4537-95cb-d71e6c00f8ca",
   "metadata": {},
   "source": [
    "### EVALUTATION\n",
    "\n",
    "Download ud eval to evaluate our parser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a9dfb-d553-4135-9159-86254a2ccbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://universaldependencies.org/conll18/conll18_ud_eval.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac465c2-e523-4af5-a968-f94ac6331210",
   "metadata": {},
   "source": [
    "We use the ``conll18_ud_eval.py`` file we just downloaded on our gold data ``en_ewt-ud-test.conllu`` and compare it with ``en_ewt-ud-test.parsed``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd41a66c-8ec8-4984-883d-12eccf1a7879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS F1 Score: 74.30\n",
      "MLAS Score: 63.36\n",
      "BLEX Score: 65.38\n"
     ]
    }
   ],
   "source": [
    "!/Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing/conll18_ud_eval.py /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/computational-tools-for-linguistic-analysis-ubc/labs/lab5_6/UD_English-EWT/en_ewt-ud-test.conllu /Users/annabellepurnomo/Desktop/LING242/LING242_assignments/LING242_assignment-2/dependency-parsing/udpipe-1.2.0-bin/bin-osx/en_ewt-ud-test.parsed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f3f86-00da-4b3f-bc3b-d172521f1a00",
   "metadata": {},
   "source": [
    "Our output shows three different metrics that reflect word segmentation and the relations between content words. \n",
    "\n",
    "We fill focus on LAS F1 Score, which is \"labeled attachment F1 score\". This score is an indication of how well our words are assigned to their syntactic head and dependency label. This is a percentage of the words correctly assigned to these labels. \n",
    "\n",
    "**Our score of 74.30 means 74.30% of our words were correctly assigned to their syntactic head and dependency label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff61ef9-1c0f-4bc7-8045-02fe2af561ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
